{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Settings and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pprint import pprint\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "#Associated Wallets imports\n",
    "from collections import deque\n",
    "\n",
    "#Ofac imports\n",
    "import csv\n",
    "import requests\n",
    "import xmltodict\n",
    "from collections import defaultdict\n",
    "\n",
    "#Dark Web imports\n",
    "import dask.dataframe as dd\n",
    "import yaml\n",
    "\n",
    "#Flipside imports\n",
    "#for flipside.xyz (SQL Databse)\n",
    "#from flipside import Flipside\n",
    "\n",
    "#Graphsense imports\n",
    "import graphsense\n",
    "from graphsense.api import addresses_api, bulk_api, entities_api, general_api, tags_api\n",
    "from graphsense.model.neighbor_addresses import NeighborAddresses\n",
    "\n",
    "#Coinbase imports\n",
    "import hmac, hashlib, time\n",
    "from requests.auth import AuthBase\n",
    "\n",
    "#Visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import calendar\n",
    "\n",
    "#Mixer/Bridges imports\n",
    "from collections import namedtuple\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('config.json')\n",
    "config = json.load(f)\n",
    "f.close()\n",
    "\n",
    "CURRENCY = 'eth'\n",
    "ADDRESS = '0x690B9A9E9aa1C9dB991C7721a92d351Db4FaC990'\n",
    "\n",
    "configuration = graphsense.Configuration(\n",
    "    host = config['graphsense']['host'],\n",
    "    api_key = {'api_key': config['graphsense']['api_key']})\n",
    "\n",
    "#with graphsense.ApiClient(configuration) as api_client:\n",
    "    #api_instance = general_api.GeneralApi(api_client)\n",
    "    #api_response = api_instance.get_statistics()\n",
    "    #pprint(api_response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Associated Wallets Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssociatedWallets():\n",
    "\n",
    "\n",
    "    def __init__(self, currency, depth):\n",
    "        self.currency = currency\n",
    "\n",
    "    \n",
    "    def simple_neighbors(self, address, direction):\n",
    "        with graphsense.ApiClient(configuration) as api_client:\n",
    "            # Create an instance of the API class\n",
    "            api_instance = addresses_api.AddressesApi(api_client)\n",
    "            #currency = CURRENCY # str | The cryptocurrency code (e.g., eth)\n",
    "            #address = ADDRESS # str | The cryptocurrency address\n",
    "            #direction = \"out\" # str | Incoming or outgoing neighbors\n",
    "            #only_ids = [\n",
    "                #\"only_ids_example\",\n",
    "            #] # [str] | Restrict result to given set of comma separated addresses (optional)\n",
    "            #include_labels = False # bool | Whether to include labels of first page of address tags (optional) if omitted the server will use the default value of False\n",
    "            #page = \"page_example\" # str | Resumption token for retrieving the next page (optional)\n",
    "            #pagesize = 10 # int | Number of items returned in a single page (optional)\n",
    "\n",
    "            # example passing only required values which don't have defaults set\n",
    "            try:\n",
    "                # Get an address's neighbors in the address graph\n",
    "                api_response = api_instance.list_address_neighbors(self.currency, address, direction)\n",
    "                return api_response\n",
    "            except graphsense.ApiException as e:\n",
    "                print(\"Exception when calling AddressesApi->list_address_neighbors: %s\\n\" % e)\n",
    "                \n",
    "\n",
    "    #Utility function to get neighbors of address        \n",
    "    def get_addr_neighbors(self, address, direction):\n",
    "\n",
    "        if (direction == 'out'):\n",
    "            degree = 'out_degree'\n",
    "            address_degree = 'address_out_degree'\n",
    "        else:\n",
    "            degree = 'in_degree'\n",
    "            address_degree = 'address_in_degree'\n",
    "\n",
    "        with graphsense.ApiClient(configuration) as api_client:\n",
    "            try:\n",
    "                api_instance = bulk_api.BulkApi(api_client)\n",
    "                print(f\"get_addr_neighbors of {address}\")\n",
    "                operation = \"list_address_neighbors\"\n",
    "                body = {'address': [address], 'direction': direction}\n",
    "\n",
    "                df_address_neighbors = pd.read_csv(api_instance.bulk_csv(self.currency, operation, body=body,\n",
    "                                                                    num_pages=1, _preload_content=False))\n",
    "                \n",
    "                df_address_neighbors = df_address_neighbors \\\n",
    "                    .loc[(df_address_neighbors['_error'] != 'not found') &\n",
    "                        (df_address_neighbors['_info'] != 'no data')].reset_index(drop=True)\n",
    "                \n",
    "                if df_address_neighbors.empty:\n",
    "                    df_address_neighbors.columns = ['address', 'entity', degree]\n",
    "                    return df_address_neighbors\n",
    "                \n",
    "                print(df_address_neighbors.columns)  # Print column names\n",
    "                \n",
    "                df_address_neighbors = df_address_neighbors \\\n",
    "                    .rename(columns={'address_address': 'address', \n",
    "                                    'address_entity': 'entity',\n",
    "                                    address_degree: degree})\n",
    "\n",
    "                return df_address_neighbors[['address', 'entity', degree]]\n",
    "                \n",
    "            except graphsense.ApiException as e:\n",
    "                print(\"Exception when calling Bulk Api: %s\\n\" % e)\n",
    "\n",
    "\n",
    "    # The Breadth-First Search algorithm:\n",
    "    def bfs_neighbors(self, seed_address, max_depth, max_degree, verbose, direction):\n",
    "\n",
    "        if (direction == 'out'):\n",
    "            degree = 'out_degree'\n",
    "        else:\n",
    "            degree = 'in_degree'\n",
    "        \n",
    "        # collect neighbors\n",
    "        neighbors = []\n",
    "        for i in range (0, max_depth):\n",
    "            neighbors.insert(i, [])\n",
    "        neighbors[0].append(seed_address)\n",
    "\n",
    "        #keep track of depth\n",
    "        levels = {seed_address: 0}\n",
    "                \n",
    "        # record visited addresses and entities\n",
    "        visited_addresses = set([seed_address])\n",
    "        \n",
    "        # maintain a queue of addresses\n",
    "        queue = deque([(seed_address, 0)])\n",
    "\n",
    "        while(queue):\n",
    "\n",
    "            # get first address from the queue\n",
    "            address, level = queue.popleft()            \n",
    "\n",
    "            # retrieve address neighbors\n",
    "            df_neighbors = self.get_addr_neighbors(address, direction)\n",
    "\n",
    "            # continue with neighbors out_degree < max_outdegree\n",
    "            for index, neighbor in df_neighbors.iterrows():\n",
    "\n",
    "                 # stop if address has already been visited\n",
    "                if(neighbor['address'] in visited_addresses):\n",
    "                    if verbose:\n",
    "                        print(address, end=' ') \n",
    "                        print(\"STOP | same address\")\n",
    "                    continue\n",
    "                                \n",
    "                # stop if max depth is reached\n",
    "                if level + 1 == max_depth:\n",
    "                    print(level)\n",
    "                    if verbose:\n",
    "                        print(address, end=' ') \n",
    "                        print(\"STOP | max depth\")\n",
    "                    continue\n",
    "\n",
    "                neighbors[level+1].append(neighbor['address'])\n",
    "\n",
    "                # stop if address out_degree exceeds threshold\n",
    "                if(neighbor[degree] > max_degree):\n",
    "                    if verbose:\n",
    "                        print(address, end=' ') \n",
    "                        print(\"STOP | max degree\")\n",
    "                    continue\n",
    "                \n",
    "                queue.append((neighbor['address'], level + 1))\n",
    "                visited_addresses.add(neighbor['address'])\n",
    "                levels[neighbor['address']] = level + 1\n",
    "                    \n",
    "            if len(queue) == 0:\n",
    "                return neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blacklist Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Blacklist():\n",
    "    \n",
    "\n",
    "    def scrape_ofac(self):\n",
    "\n",
    "        coins = []\n",
    "        myCoins = {}\n",
    "        sdn = defaultdict(list)\n",
    "        filename = 'sdn2.xml'\n",
    "        URL = \"https://www.treasury.gov/ofac/downloads/sanctions/1.0/sdn_advanced.xml\"\n",
    "\n",
    "        response = requests.get(URL)\n",
    "        with open(filename, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "\n",
    "        xml_data = open(filename, 'r').read()  # Read file\n",
    "        d = xmltodict.parse(xml_data)\n",
    "\n",
    "        for i in d['Sanctions']['ReferenceValueSets']['FeatureTypeValues']['FeatureType']:\n",
    "            if 'Digital Currency Address' in i['#text']:\n",
    "                coins.append(i['@ID'])\n",
    "                myCoins[i['@ID']] =  i['#text'].replace('Digital Currency Address - ','')\n",
    "            #   print(i['@ID'],'-',i['#text'])\n",
    "\n",
    "        for i in d['Sanctions']['DistinctParties']['DistinctParty']:\n",
    "            if 'Feature' in i['Profile'].keys():\n",
    "                for j in i['Profile']['Feature']:\n",
    "                    if '@FeatureTypeID' in j:\n",
    "                        if type(j) is not str:\n",
    "                            if str(j['@FeatureTypeID']) in coins:\n",
    "                            #   print(j)\n",
    "                            #   print(j['FeatureVersion']['VersionDetail']['#text'])\n",
    "                                sdn[myCoins[j['@FeatureTypeID']]].append(j['FeatureVersion']['VersionDetail']['#text'])            \n",
    "                            #    break\n",
    "            \n",
    "        with open('results/sdn.json', 'w') as fp:\n",
    "            json.dump(sdn, fp)\n",
    "        fp.close()\n",
    "\n",
    "\n",
    "    def check_ofac(self, currency, address, path):\n",
    "        \n",
    "        file_ext = os.path.splitext(path)[1].lower()\n",
    "        with open(path, \"r\") as file:\n",
    "            if file_ext in [\".json\"]:\n",
    "                data = json.load(file)\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported file format\")\n",
    "\n",
    "        currency_set = set(data[currency])\n",
    "        \n",
    "        return address in currency_set\n",
    "    \n",
    "\n",
    "    def check_dark_web(self, address, parent_directory):\n",
    "\n",
    "        #pd.set_option('display.max_colwidth', None)\n",
    "    \n",
    "        def scan_directory(directory):\n",
    "\n",
    "            #Recursively scans a directory for Parquet files and checks them\n",
    "\n",
    "            for item in os.listdir(directory):\n",
    "\n",
    "                item_path = os.path.join(directory, item)\n",
    "                \n",
    "                # If item is a directory, recursively scan it\n",
    "                if os.path.isdir(item_path):\n",
    "                    if scan_directory(item_path):\n",
    "                        return True\n",
    "\n",
    "                # If item is a parquet file, read and check it\n",
    "                elif item.endswith(\".parquet\"):\n",
    "                    ddf = dd.read_parquet(item_path, blocksize=\"400mb\")\n",
    "                    print(ddf.head())\n",
    "\n",
    "                    check = ddf['address'].isin([address]).compute()\n",
    "                    if check.any():\n",
    "                        return True\n",
    "                    \n",
    "            return False\n",
    "\n",
    "        return scan_directory(parent_directory)\n",
    "    \n",
    "    \n",
    "    def check_phishing_hack(self, address, path):\n",
    "\n",
    "        file_ext = os.path.splitext(path)[1].lower()\n",
    "        with open(path, \"r\") as file:\n",
    "            if file_ext in [\".json\"]:\n",
    "                data = json.load(file)\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported file format\")\n",
    "        \n",
    "        phishing_hack_addresses = [entry['address'] for entry in data]\n",
    "\n",
    "        return address in phishing_hack_addresses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exchanges Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exchange():\n",
    "    \n",
    "\n",
    "    def __init__(self, currency, depth):\n",
    "        self.currency = currency\n",
    "        self.depth = depth\n",
    "\n",
    "\n",
    "    def get_ex_tags(self, address, type):\n",
    "\n",
    "        # Enter a context with an instance of the API client\n",
    "        with graphsense.ApiClient(configuration) as api_client:\n",
    "            # Create an instance of the API class\n",
    "            api_instance = addresses_api.AddressesApi(api_client)\n",
    "\n",
    "            #currency = CURRENCY # str | The cryptocurrency code (e.g., btc)\n",
    "            #address = ADDRESS # str | The cryptocurrency address\n",
    "            #page = \"page_example\" # str | Resumption token for retrieving the next page (optional)\n",
    "            #pagesize = 10 # int | Number of items returned in a single page (optional)\n",
    "            #include_tags = True\n",
    "\n",
    "            try:\n",
    "                # Get attribution tags for a given address\n",
    "                api_response = api_instance.list_tags_by_address(self.currency, address.lower())\n",
    "                exchange_data = api_response\n",
    "                \n",
    "                exchange_tags = []\n",
    "\n",
    "                for entry in exchange_data['address_tags']:\n",
    "                    actor = entry.get('actor', '')\n",
    "                    category = entry.get('category', '')\n",
    "                    label = entry.get('label', '')\n",
    "                    if ((actor or label) and (type == 'cex' and (category == 'exchange' or category == 'market'))) or ((actor or label) and type == 'dex' and category == 'defi_dex'):\n",
    "                        exchange_tags.append({\n",
    "                            'actor': actor,\n",
    "                            'category': category,\n",
    "                            'currency': entry.get('currency', ''),\n",
    "                            'label': label,\n",
    "                            'address': entry.get('address', '')\n",
    "                        })\n",
    "\n",
    "                return exchange_tags\n",
    "                \n",
    "            except graphsense.ApiException as e:\n",
    "               print(\"Exception when calling AddressesApi->list_tags_by_address: %s\\n\" % e)\n",
    "    \n",
    "    \n",
    "    def get_ex_used(self, address, type, direction, max_degree=7, verbose=True):\n",
    "        \n",
    "        ass_wallets = AssociatedWallets()\n",
    "        neighbors = ass_wallets.bfs_neighbors(address, self.depth, max_degree, verbose, direction)\n",
    "\n",
    "        exchanges_used = []\n",
    "\n",
    "        for arr_level in neighbors:\n",
    "            for address in arr_level:\n",
    "                temp_exchange_tags = self.get_ex_tags(address, type)\n",
    "                if temp_exchange_tags:\n",
    "                    exchanges_used.append(temp_exchange_tags)\n",
    "\n",
    "        return exchanges_used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proof of Funds Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom authentication for Coinbase API\n",
    "class CoinbaseWalletAuth(AuthBase):\n",
    "    def __init__(self, api_key, secret_key):\n",
    "        self.api_key = api_key\n",
    "        self.secret_key = secret_key\n",
    "\n",
    "    def __call__(self, request):\n",
    "        timestamp = str(int(time.time()))\n",
    "        message = timestamp + request.method + request.path_url + (request.body or '')\n",
    "        signature = hmac.new(self.secret_key, message, hashlib.sha256).hexdigest()\n",
    "\n",
    "        request.headers.update({\n",
    "            'CB-ACCESS-SIGN': signature,\n",
    "            'CB-ACCESS-TIMESTAMP': timestamp,\n",
    "            'CB-ACCESS-KEY': self.api_key,\n",
    "        })\n",
    "        return request\n",
    "\n",
    "\n",
    "class PoF():\n",
    "    \n",
    "\n",
    "    def __init__(self, currency):\n",
    "        self.currency = currency\n",
    "\n",
    "    #Candles data Coinbase\n",
    "\n",
    "    \"\"\"Each bucket is an array of the following information:\n",
    "\n",
    "    time: bucket start time\n",
    "    low: lowest price during the bucket interval\n",
    "    high: highest price during the bucket interval\n",
    "    open: opening price (first trade) in the bucket interval\n",
    "    close: closing price (last trade) in the bucket interval\n",
    "    volume: volume of trading activity during the bucket interval\"\"\"\n",
    "    def coinbase_data(self, type, symbol='ETH-USD', start_date=datetime.today().strftime('%Y-%m-%d'), end_date=datetime.today().strftime('%Y-%m-%d')):\n",
    "\n",
    "        # Before implementation, set environmental variables with the names API_KEY and API_SECRET\n",
    "        #API_KEY = config['coinbase']['api_key']\n",
    "        #API_SECRET = config['coinbase']['api_secret']\n",
    "        #auth = CoinbaseWalletAuth(API_KEY, API_SECRET)\n",
    "\n",
    "        # Convert the start date string to a datetime object\n",
    "        #start_date_datetime = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "\n",
    "        # Calculate the end date by adding one day to the start date\n",
    "        #end_date_datetime = start_date_datetime + datetime.timedelta(days=1)\n",
    "\n",
    "        # Convert the end date to a string in the same format\n",
    "        #end_date = end_date_datetime.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        # Parameters for the API request Exchange\n",
    "        params_exchange = {\n",
    "            \"currency\": symbol\n",
    "        }\n",
    "\n",
    "        # Parameters for the API request Spot\n",
    "        params_spot = {\n",
    "            \"date\": start_date\n",
    "        }\n",
    "\n",
    "        # Parameters for the API request Candles\n",
    "        params_candles = {\n",
    "            \"granularity\": 86400,  # Daily interval\n",
    "            \"start\": start_date,\n",
    "            \"end\": start_date\n",
    "        }\n",
    "\n",
    "        if type == 'buy':\n",
    "            base_url = config['coinbase']['buyprice_endpoint']\n",
    "            api_url = base_url.format(symbol)\n",
    "            response = requests.get(api_url)\n",
    "\n",
    "        elif type == 'sell':\n",
    "            base_url = config['coinbase']['sellprice_endpoint']\n",
    "            api_url = base_url.format(symbol)\n",
    "            response = requests.get(api_url)\n",
    "\n",
    "        elif type == 'exchange':\n",
    "            api_url = config['coinbase']['exchangeprice_endpoint']\n",
    "            response = requests.get(api_url, params=params_exchange)\n",
    "\n",
    "        elif type == 'spot':\n",
    "            base_url = config['coinbase']['spotprice_endpoint']\n",
    "            api_url = base_url.format(symbol)\n",
    "            response = requests.get(api_url, params=params_spot)\n",
    "\n",
    "        elif type == 'candles':\n",
    "            base_url = config['coinbase']['candles_endpoint']\n",
    "            api_url = base_url.format(symbol)\n",
    "            response = requests.get(api_url, params=params_candles)\n",
    "        else:\n",
    "            print(f\"Unsupported type: {type}\")\n",
    "            return False\n",
    "\n",
    "        # Process the response data\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(\"Request failed:\", response.status_code)\n",
    "\n",
    "    \n",
    "    #Klines data Binance\n",
    "    \"\"\"[\n",
    "        [\n",
    "            1499040000000,      // Kline open time\n",
    "            \"0.01634790\",       // Open price\n",
    "            \"0.80000000\",       // High price\n",
    "            \"0.01575800\",       // Low price\n",
    "            \"0.01577100\",       // Close price\n",
    "            \"148976.11427815\",  // Volume\n",
    "            1499644799999,      // Kline Close time\n",
    "            \"2434.19055334\",    // Quote asset volume\n",
    "            308,                // Number of trades\n",
    "            \"1756.87402397\",    // Taker buy base asset volume\n",
    "            \"28.46694368\",      // Taker buy quote asset volume\n",
    "            \"0\"                 // Unused field, ignore.\n",
    "        ]\n",
    "        ]\"\"\"\n",
    "    def binance_data(self, type, symbol='', start_date=datetime.today().strftime('%Y-%m-%d'), end_date=datetime.today().strftime('%Y-%m-%d')):\n",
    "\n",
    "        # Convert start and end dates to Unix timestamps (in milliseconds)\n",
    "        start_timestamp = int(datetime.strptime(start_date, \"%Y-%m-%d\").timestamp()) * 1000\n",
    "        #end_timestamp = int(datetime.strptime(end_date, \"%Y-%m-%d\").timestamp()) * 1000\n",
    "\n",
    "        # Parameters for the API request Klines\n",
    "        params_klines = {\n",
    "            \"symbol\": symbol,\n",
    "            \"interval\": \"1d\",  # Daily interval\n",
    "            \"startTime\": start_timestamp\n",
    "            #\"endTime\": end_timestamp\n",
    "        }\n",
    "\n",
    "        # Parameters for the API request\n",
    "        params_general = {\n",
    "            \"symbol\": symbol,\n",
    "            #\"interval\": \"1d\",  # Daily interval\n",
    "            #\"startTime\": start_timestamp\n",
    "            #\"endTime\": end_timestamp\n",
    "        }\n",
    "\n",
    "        if type == 'avgprice':\n",
    "            api_url = config['binance']['avgprice_endpoint']\n",
    "            response = requests.get(api_url, params=params_general)\n",
    "        elif type == 'price':\n",
    "            api_url = config['binance']['price_endpoint']\n",
    "            response = requests.get(api_url, params=params_general)\n",
    "        elif type == 'exchange':\n",
    "            api_url = config['binance']['exchangeprice_endpoint']\n",
    "            if symbol == '':\n",
    "                response = requests.get(api_url)\n",
    "            else:\n",
    "                response = requests.get(api_url, params=params_general)\n",
    "        elif type == 'klines':\n",
    "            api_url = config['binance']['klines_endpoint']\n",
    "            response = requests.get(api_url, params=params_klines)\n",
    "        elif type == '24hrstats':\n",
    "            api_url = config['binance']['24hrstats_endpoint']\n",
    "            response = requests.get(api_url, params=params_general)\n",
    "        else:\n",
    "            print(f\"Unsupported type: {type}\")\n",
    "            return False\n",
    "        \n",
    "        # Process the response data\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(\"Request failed:\", response.status_code)\n",
    "        \n",
    "        \n",
    "    def binance_table(self, symbol, interval='4h', limit=500, start='01-01-2023'):\n",
    "\n",
    "        \"\"\"\n",
    "        interval: str tick interval - 4h/1h/1d ...\n",
    "        \"\"\"\n",
    "\n",
    "        columns = ['open_time','open', 'high', 'low', 'close', 'volume','close_time', 'qav','num_trades','taker_base_vol','taker_quote_vol', 'ignore']\n",
    "        start = int(datetime.timestamp(pd.to_datetime(start))*1000)\n",
    "        api_url = f'https://www.binance.com/api/v3/klines?symbol={symbol}&interval={interval}&limit={limit}&startTime={start}'\n",
    "\n",
    "        data = pd.DataFrame(requests.get(api_url).json(), columns=columns, dtype=float)\n",
    "        data.index = [pd.to_datetime(x, unit='ms').strftime('%Y-%m-%d %H:%M:%S') for x in data.open_time]\n",
    "        usecols=['open', 'high', 'low', 'close', 'volume', 'qav','num_trades','taker_base_vol','taker_quote_vol']\n",
    "        data = data[usecols]\n",
    "\n",
    "        return data\n",
    "    \n",
    "    \n",
    "    def check_profitloss(self, exchange, symbol, buy_date, sell_date, buy_amount, sell_amount, profit_or_loss):\n",
    "        \n",
    "        if exchange == 'coinbase':\n",
    "            \n",
    "            buy_price_data = self.coinbase_data('candles', buy_date)\n",
    "            sell_price_data = self.coinbase_data('candles', sell_date)\n",
    "\n",
    "            buy_price = float(buy_price_data[0][3])\n",
    "            sell_price = float(sell_price_data[0][3])\n",
    "\n",
    "            buy_total = buy_price * buy_amount\n",
    "            sell_total = sell_price * sell_amount\n",
    "            \n",
    "        elif exchange == 'binance':\n",
    "            \n",
    "            buy_price_data = self.binance_data('klines', buy_date, symbol)\n",
    "            sell_price_data = self.binance_data('klines', sell_date, symbol)\n",
    "\n",
    "            buy_price = float(buy_price_data[0][1])\n",
    "            sell_price = float(sell_price_data[0][1])\n",
    "\n",
    "            buy_total = buy_price * buy_amount\n",
    "            sell_total = sell_price * sell_amount\n",
    "\n",
    "        else:\n",
    "            print(f\"Unsupported exchange: {exchange}\")\n",
    "            return False\n",
    "\n",
    "        difference = abs((buy_total - sell_total) - abs(profit_or_loss))\n",
    "        actual_profit_or_loss = sell_total - buy_total\n",
    "        \n",
    "        if difference < 1e-6: #To account for floating point inaccuracies\n",
    "            print(\"Actual profit/loss: \" + str(actual_profit_or_loss))\n",
    "            print(\"Difference between reported profit/loss and actual profit/loss value: \" + str(difference))\n",
    "            return True\n",
    "        else:\n",
    "            print(\"Actual profit/loss: \" + str(actual_profit_or_loss))\n",
    "            print(\"Difference between reported profit/loss and actual profit/loss value: \" + str(difference))            \n",
    "            return False\n",
    "        \n",
    "\n",
    "    def get_address_txs(self, address, direction, pages=5):\n",
    "\n",
    "        # Enter a context with an instance of the API client\n",
    "        with graphsense.ApiClient(configuration) as api_client:\n",
    "            # Create an instance of the API class\n",
    "            api_instance = addresses_api.AddressesApi(api_client)\n",
    "            #direction = \"out\" # str | Incoming or outgoing transactions (optional)\n",
    "            #min_height = Height(1) # Height | Return transactions starting from given height (optional)\n",
    "            #max_height = Height(2) # Height | Return transactions up to (including) given height (optional)\n",
    "            #token_currency = \"WETH\" # str | Return transactions of given token currency (optional)\n",
    "            #page = \"page_example\" # str | Resumption token for retrieving the next page (optional)\n",
    "            #pagesize = 10 # int | Number of items returned in a single page (optional)\n",
    "\n",
    "            all_txs = []\n",
    "            next_page_token = ''\n",
    "\n",
    "            for i in range(0, pages):\n",
    "\n",
    "                try:\n",
    "                    \n",
    "                    if next_page_token == '':\n",
    "                        # Get all transactions an address has been involved in without a next page token\n",
    "                        api_response = api_instance.list_address_txs(self.currency, address, direction=direction)\n",
    "                        all_txs.extend(api_response['address_txs'])\n",
    "\n",
    "                    else:\n",
    "                        # Get all transactions an address has been involved in\n",
    "                        api_response = api_instance.list_address_txs(self.currency, address, direction=direction, page=next_page_token)\n",
    "                        all_txs.extend(api_response['address_txs'])\n",
    "\n",
    "                    if 'next_page' in api_response:\n",
    "                        next_page_token = api_response['next_page']\n",
    "\n",
    "                    else:\n",
    "                        print(f\"{i+1} pages found for transactions in direction: {direction}. Exiting after fetching all available pages.\")\n",
    "                        break\n",
    "\n",
    "                except graphsense.ApiException as e:\n",
    "                    print(\"Exception when calling AddressesApi->list_address_txs: %s\\n\" % e)\n",
    "            \n",
    "        return all_txs\n",
    "\n",
    "\n",
    "    def check_pass_through_wallet(self, address, pages=5):\n",
    "          \n",
    "        out_txs = self.get_address_txs(address, 'out', pages)\n",
    "        in_txs = self.get_address_txs(address, 'in', pages)\n",
    "\n",
    "        params = {\n",
    "            \"module\": \"account\",\n",
    "            \"action\": \"balance\",\n",
    "            \"address\": address,\n",
    "            \"tag\": \"latest\",\n",
    "            \"apikey\": config['etherscan']['api_key']\n",
    "        }\n",
    "        \n",
    "        response = requests.get(config['etherscan']['host'], params=params)\n",
    "        data = response.json()\n",
    "\n",
    "        if data['status'] != \"1\" or 'result' not in data:\n",
    "            print(f\"Error fetching transactions for address {address}: {data['message']}\")\n",
    "            return []\n",
    "        \n",
    "        balance_eth = float(data['result']) / (10 ** 18)  # Convert wei to ether\n",
    "\n",
    "        print(\"Number of incoming txs: \" + str(len(in_txs['address_txs'])))\n",
    "        print(\"Number of outgoing txs: \" + str(len(out_txs['address_txs'])))\n",
    "        print(balance_eth)\n",
    "\n",
    "\n",
    "    def activity_analysis(self, address, pages=5):\n",
    "\n",
    "        out_txs = self.get_address_txs(address, 'out', pages)\n",
    "        in_txs = self.get_address_txs(address, 'in', pages)\n",
    "        date_txcount = {}\n",
    "\n",
    "        for tx in out_txs:\n",
    "            tx_date = datetime.utcfromtimestamp(tx['timestamp']).strftime('%Y-%m-%d')\n",
    "            date_txcount[tx_date] = date_txcount.get(tx_date, 0) + 1\n",
    "\n",
    "        for tx in in_txs:\n",
    "            tx_date = datetime.utcfromtimestamp(tx['timestamp']).strftime('%Y-%m-%d')\n",
    "            date_txcount[tx_date] = date_txcount.get(tx_date, 0) + 1\n",
    "\n",
    "        dates = [datetime.strptime(date, '%Y-%m-%d') for date in date_txcount.keys()]\n",
    "        start_date = min(dates)\n",
    "        end_date = max(dates)\n",
    "\n",
    "        current_date = start_date\n",
    "        while current_date <= end_date:\n",
    "            str_date = current_date.strftime('%Y-%m-%d')\n",
    "            if str_date not in date_txcount:\n",
    "                date_txcount[str_date] = 0\n",
    "            current_date += timedelta(days=1)\n",
    "\n",
    "        df = pd.DataFrame(list(date_txcount.items()), columns=['Date', 'TxCount'])\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        df = df.sort_values('Date')\n",
    "        df['YearMonth'] = df['Date'].dt.to_period('M')\n",
    "        df['Day'] = df['Date'].dt.day\n",
    "        new_df = df.pivot(index=\"Day\", columns=\"YearMonth\", values=\"TxCount\")\n",
    "        new_df = new_df.iloc[::-1]\n",
    "\n",
    "        # Plot:\n",
    "        #width_per_tx = 0.25\n",
    "        #fig_width = len(date_txcount) * width_per_tx\n",
    "        fig_width = 30\n",
    "        plt.figure(figsize=(fig_width, 20))\n",
    "        sns.heatmap(new_df, cmap='Purples', linewidths=2, cbar_kws={'label': 'Transaction Count'}, annot=True)\n",
    "        plt.title('Transactions Heatmap')\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NFTs Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NFT():\n",
    "\n",
    "\n",
    "    def get_nft_transfers(self, address, page=1, offset=100):\n",
    "\n",
    "        params = {\n",
    "            \"module\": \"account\",\n",
    "            \"action\": \"tokennfttx\",\n",
    "            #\"contractaddress\": \"\",\n",
    "            \"address\": address,\n",
    "            \"page\": page,\n",
    "            \"offset\": offset,\n",
    "            #\"startblock\": \"\",\n",
    "            #\"endblock\": \"\",\n",
    "            \"sort\": \"asc\",\n",
    "            \"apikey\": config['etherscan']['api_key']\n",
    "         }\n",
    "        \n",
    "        response = requests.get(config['etherscan']['host'], params=params)\n",
    "        data = response.json()\n",
    "\n",
    "        if data['status'] != \"1\" or 'result' not in data:\n",
    "            print(f\"Error fetching transactions for address {address}: {data['message']}\")\n",
    "            return []\n",
    "\n",
    "        return data['result']\n",
    "    \n",
    "    \n",
    "    def get_held_nfts(self, address):\n",
    "        \n",
    "        transfers = self.get_nft_transfers(address)\n",
    "\n",
    "        incoming_nfts = {tx['tokenID']: tx for tx in transfers if tx['to'] == address.lower()}\n",
    "        outgoing_nfts = {tx['tokenID']: tx for tx in transfers if tx['from'] == address.lower()}\n",
    "\n",
    "        held_nfts = {tid: tx for tid, tx in incoming_nfts.items() if tid not in outgoing_nfts}\n",
    "\n",
    "        return list(held_nfts.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERC20 Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ERC20():\n",
    "\n",
    "\n",
    "    def get_erc20_transfers(self, address, page=3, offset=100):\n",
    "\n",
    "        params = {\n",
    "            \"module\": \"account\",\n",
    "            \"action\": \"tokentx\",\n",
    "            #\"contractaddress\": \"\",\n",
    "            \"address\": address,\n",
    "            \"page\": page,\n",
    "            \"offset\": offset,\n",
    "            #\"startblock\": \"\",\n",
    "            #\"endblock\": \"\",\n",
    "            \"sort\": \"asc\",\n",
    "            \"apikey\": config['etherscan']['api_key']\n",
    "         }\n",
    "        \n",
    "        response = requests.get(config['etherscan']['host'], params=params)\n",
    "        data = response.json()\n",
    "\n",
    "        if data['status'] != \"1\" or 'result' not in data:\n",
    "            print(f\"Error fetching transactions for address {address}: {data['message']}\")\n",
    "            return []\n",
    "\n",
    "        return data['result']\n",
    "    \n",
    "    \n",
    "    def get_erc20(self, address):\n",
    "        \n",
    "        transfers = self.get_erc20_transfers(address)\n",
    "\n",
    "        erc20_balances = {}\n",
    "        \n",
    "        # Sum up all the incoming and outgoing transfers for each token\n",
    "        for tx in transfers:\n",
    "\n",
    "            token_key = (tx['tokenSymbol'], tx['tokenName'])\n",
    "            value = float(tx['value']) / (10.0 ** float(tx['tokenDecimal']))\n",
    "            \n",
    "            if tx['to'] == address.lower():\n",
    "                erc20_balances[token_key] = erc20_balances.get(token_key, 0) + value\n",
    "            if tx['from'] == address.lower():\n",
    "                erc20_balances[token_key] = erc20_balances.get(token_key, 0) - value\n",
    "\n",
    "        # Filter out tokens with zero or negative balances\n",
    "        held_erc20 = {k: v for k, v in erc20_balances.items() if v > 0}\n",
    "\n",
    "        return dict(sorted(held_erc20.items()))\n",
    "\n",
    "    \n",
    "    def visualize(self, address):\n",
    "        \n",
    "        #create a chart of held erc20 tokens\n",
    "\n",
    "        held_erc20 = self.get_erc20(address)\n",
    "        pof = PoF()\n",
    "        pie_data = []\n",
    "        pie_labels = []\n",
    "        failed_erc20 = {}\n",
    "\n",
    "        if held_erc20:\n",
    "\n",
    "            for token, value in held_erc20.items():\n",
    "\n",
    "                symbol = token[0]\n",
    "\n",
    "                if symbol != 'USDT':\n",
    "                    trading_pair = symbol + 'USDT'\n",
    "                    binance_call = pof.binance_data('price', trading_pair)\n",
    "                    if binance_call:\n",
    "                        symbol_price = float(binance_call['price'])\n",
    "                        pie_data.append(symbol_price * value)\n",
    "                        pie_labels.append(symbol)\n",
    "                    else:\n",
    "                        failed_erc20[token] = value\n",
    "                elif symbol == 'USDT': \n",
    "                    symbol_price = 1.0\n",
    "                    pie_data.append(symbol_price * value)\n",
    "                    pie_labels.append(symbol)\n",
    "    \n",
    "        else:\n",
    "            print(f\"Error fetching transactions for address {address}\")\n",
    "\n",
    "        # Plot\n",
    "\n",
    "        colors = [\n",
    "            \"#1f77b4\",  # muted blue\n",
    "            \"#ff7f0e\",  # safety orange\n",
    "            \"#2ca02c\",  # cooked asparagus green\n",
    "            \"#d62728\",  # brick red\n",
    "            \"#9467bd\",  # muted purple\n",
    "            \"#8c564b\",  # chestnut brown\n",
    "            \"#e377c2\",  # raspberry yogurt pink\n",
    "            \"#7f7f7f\",  # middle gray\n",
    "            \"#bcbd22\",  # curry yellow-green\n",
    "            \"#17becf\",  # blue-teal\n",
    "            \"#1a55FF\",  # bright blue\n",
    "            \"#FF55A3\",  # bright pink\n",
    "            \"#669900\",  # olive green\n",
    "            \"#FFC400\",  # bright yellow\n",
    "            \"#004DFF\",  # royal blue\n",
    "            \"#FF5000\",  # bright red-orange\n",
    "            \"#009966\",  # teal green\n",
    "            \"#FF6600\",  # orange\n",
    "            \"#8000FF\",  # violet\n",
    "            \"#00FF80\"   # mint green\n",
    "        ]\n",
    "\n",
    "        if pie_data and len(pie_data) < 6:\n",
    "            plt.figure(figsize=(10, 8)) # 10 width, 8 height\n",
    "            plt.legend(pie_labels, title=\"Tokens\", loc=\"best\")\n",
    "            plt.title('ERC20 Tokens in USDT')\n",
    "            plt.pie(pie_data, colors=colors)\n",
    "            plt.show()\n",
    "        elif pie_data and len(pie_data) >= 6:\n",
    "            bar_positions = np.arange(len(pie_labels))\n",
    "            plt.figure(figsize=(30, 24)) # 10 width, 8 height\n",
    "            plt.xticks(bar_positions, pie_labels, rotation=45)\n",
    "            plt.yscale('log')  # Set y-axis to logarithmic scale\n",
    "            plt.ylabel('Value in USDT')\n",
    "            plt.title('ERC20 Tokens in USDT')\n",
    "            plt.bar(bar_positions, pie_data, align='center', alpha=0.7)\n",
    "            plt.show()\n",
    "            \n",
    "        print(f\"The following ERC20 Tokens are being held by the client: {held_erc20}\")\n",
    "        print(f\"For following ERC20 Tokens there was no price data: {failed_erc20}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smart Contract Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SC():\n",
    "\n",
    "\n",
    "    def get_sc_data(self, contract_address, type):\n",
    "\n",
    "        params_sc = {\n",
    "            \"module\": \"contract\",\n",
    "            \"action\": \"getsourcecode\",\n",
    "            \"address\": contract_address,\n",
    "            \"apikey\": config['etherscan']['api_key']\n",
    "        }\n",
    "        response_sc = requests.get(config['etherscan']['host'], params=params_sc)\n",
    "        data_sc = response_sc.json()\n",
    "\n",
    "        params_creator = {\n",
    "            \"module\": \"contract\",\n",
    "            \"action\": \"getcontractcreation\",\n",
    "            \"address\": contract_address,\n",
    "            \"apikey\": config['etherscan']['api_key']\n",
    "        }\n",
    "        response_creator = requests.get(config['etherscan']['host'], params=params_creator)\n",
    "        data_creator = response_creator.json()\n",
    "\n",
    "        if data_sc[\"status\"] == \"1\":\n",
    "            source_code = data_sc[\"result\"][0][\"SourceCode\"]\n",
    "            with open(\"results/sc_\" + str(type) + \"_\" + data_sc[\"result\"][0][\"ContractName\"] + \".txt\", \"w\") as outfile:\n",
    "                outfile.write(str(source_code))\n",
    "        else:\n",
    "            print(f\"Error Smart Contract: {data_sc['message']}\")\n",
    "\n",
    "        if data_creator[\"status\"] == \"1\":\n",
    "            creator_data = data_creator[\"result\"]\n",
    "            with open(\"results/creator_\" + str(type) + \".txt\", \"w\") as outfile:\n",
    "                outfile.write(str(creator_data))\n",
    "        else:\n",
    "            print(f\"Error Creator: {data_creator['message']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixer and Bridges Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixBridge():\n",
    "\n",
    "\n",
    "    def process(self, mix_bridge, address, pages, pof):\n",
    "\n",
    "        print(f\"Processing mixer/bridge: {mix_bridge['address']}\")\n",
    "\n",
    "        Tx = namedtuple('Transaction', ['from_address', 'to_address', 'name_tag'])\n",
    "\n",
    "        out_txs = pof.get_address_txs(mix_bridge['address'], 'out', pages)\n",
    "        in_txs = pof.get_address_txs(mix_bridge['address'], 'in', pages)\n",
    "        #print(in_txs)\n",
    "\n",
    "        name_tag = mix_bridge['nameTag'] if mix_bridge['nameTag'] else 'Unknown Mixer/Bridge'\n",
    "\n",
    "        tx_from_mix_bridge = [Tx(tx['from_address'], tx['to_address'], name_tag) for tx in out_txs if tx['to_address'] == address]\n",
    "        tx_to_mix_bridge = [Tx(tx['from_address'], tx['to_address'], name_tag) for tx in in_txs if tx['from_address'] == address]\n",
    "        print(tx_to_mix_bridge)\n",
    "\n",
    "        return tx_from_mix_bridge, tx_to_mix_bridge\n",
    "\n",
    "\n",
    "    def check(self, address, path, pages=3):\n",
    "\n",
    "        pof = PoF('eth')\n",
    "        file_ext = os.path.splitext(path)[1].lower()\n",
    "        with open(path, \"r\") as file:\n",
    "            if file_ext in [\".json\"]:\n",
    "                mix_bridge_data = json.load(file)\n",
    "            elif file_ext in [\".yaml\", \".yml\"]:\n",
    "                mix_bridge_data = yaml.safe_load(file)\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported file format\")\n",
    "\n",
    "        print(mix_bridge_data)\n",
    "\n",
    "        tx_from_mix_bridge = []\n",
    "        tx_to_mix_bridge = []\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "\n",
    "            futures = [executor.submit(self.process, mix_bridge, address, pages, pof) for mix_bridge in mix_bridge_data[0]]\n",
    "\n",
    "            for future in as_completed(futures):\n",
    "                out, inn = future.result()\n",
    "                print(\"From:\", out)  # Debugging print\n",
    "                print(\"To:\", inn)    # Debugging print\n",
    "                tx_from_mix_bridge.extend(out)\n",
    "                tx_to_mix_bridge.extend(inn)\n",
    "\n",
    "        return tx_from_mix_bridge, tx_to_mix_bridge"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'address': '0x94A1B5CdB22c43faab4AbEb5c74999895464Ddaf', 'nameTag': 'Tornado Cash'}, {'address': '0x8589427373D6D84E98730D7795D8f6f8731FDA16', 'nameTag': 'Tornado Cash: Donate'}, {'address': '0xdd4c48c0b24039969fc16d1cdf626eab821d3384', 'nameTag': 'Gitcoin Grants: Tornado.cash'}, {'address': '0x77777feddddffc19ff86db637967013e6c6a116c', 'nameTag': 'TORN Token (TORN)'}, {'address': '0x3efa30704d2b8bbac821307230376556cf8cc39e', 'nameTag': 'Tornado.Cash Voucher (vTORN)'}, {'address': '0x12d66f87a04a9e220743712ce6d9bb1b5616b8fc', 'nameTag': 'Tornado.Cash: 0.1 ETH'}, {'address': '0x178169b423a011fff22b9e3f3abea13414ddd0f1', 'nameTag': 'Tornado.Cash: 0.1 WBTC'}, {'address': '0x47ce0c6ed5b0ce3d3a51fdb1c52dc66a7c3c2936', 'nameTag': 'Tornado.Cash: 1 ETH'}, {'address': '0x610b717796ad172b316836ac95a2ffad065ceab4', 'nameTag': 'Tornado.Cash: 1 WBTC'}, {'address': '0x4736dcf1b7a3d580672cce6e7c65cd5cc9cfba9d', 'nameTag': 'Tornado.Cash: 1,00 USDC'}, {'address': '0xfd8610d20aa15b7b2e3be39b396a1bc3516c7144', 'nameTag': 'Tornado.Cash: 1,000 DAI'}, {'address': '0xd96f2b1c14db8458374d9aca76e26c3d18364307', 'nameTag': 'Tornado.Cash: 1,000 USDC'}, {'address': '0x0836222f2b2b24a3f36f98668ed8f0b38d1a872f', 'nameTag': 'Tornado.Cash: 1,000 USDT'}, {'address': '0x910cbd523d972eb0a6f4cae4618ad62622b39dbf', 'nameTag': 'Tornado.Cash: 10 ETH'}, {'address': '0xbb93e510bbcd0b7beb5a853875f9ec60275cf498', 'nameTag': 'Tornado.Cash: 10 WBTC'}, {'address': '0xf60dd140cff0706bae9cd734ac3ae76ad9ebc32a', 'nameTag': 'Tornado.Cash: 10,000 DAI'}, {'address': '0x07687e702b410fa43f4cb4af7fa097918ffd2730', 'nameTag': 'Tornado.Cash: 10,000 DAI 2'}, {'address': '0xd691f27f38b395864ea86cfc7253969b409c362d', 'nameTag': 'Tornado.Cash: 10,000 USDC'}, {'address': '0xf67721a2d8f736e75a49fdd7fad2e31d8676542a', 'nameTag': 'Tornado.Cash: 10,000 USDT'}, {'address': '0xd4b88df4d29f5cedd6857912842cff3b20c8cfa3', 'nameTag': 'Tornado.Cash: 100 DAI'}, {'address': '0xa160cdab225685da1d56aa342ad8841c3b53f291', 'nameTag': 'Tornado.Cash: 100 ETH'}, {'address': '0x169ad27a470d064dede56a2d3ff727986b15d52b', 'nameTag': 'Tornado.Cash: 100 USDT'}, {'address': '0x23773e65ed146a459791799d01336db287f25334', 'nameTag': 'Tornado.Cash: 100,000 DAI'}, {'address': '0x9ad122c22b14202b4490edaf288fdb3c7cb3ff5e', 'nameTag': 'Tornado.Cash: 100,000 USDT'}, {'address': '0x22aaa7720ddd5388a3c0a3333430953c68f1849b', 'nameTag': 'Tornado.Cash: 5,000 cDAI'}, {'address': '0xaeaac358560e11f52454d997aaff2c5731b6f8a6', 'nameTag': 'Tornado.Cash: 5,000 cUSDC'}, {'address': '0xd21be7248e0197ee08e0c20d4a96debdac3d20af', 'nameTag': 'Tornado.Cash: 5,000,000 cDAI'}, {'address': '0xba214c1c1928a32bffe790263e38b4af9bfcd659', 'nameTag': 'Tornado.Cash: 50,000 cDAI'}, {'address': '0x1356c899d8c9467c7f71c195612f8a395abf2f0a', 'nameTag': 'Tornado.Cash: 50,000 cUSDC'}, {'address': '0xb1c8094b234dce6e03f10a5b673c1d8c69739a00', 'nameTag': 'Tornado.Cash: 500,000 cDAI'}, {'address': '0x2717c5e28cf931547b621a5dddb772ab6a35b701', 'nameTag': 'Tornado.Cash: 500,000 cDAI 2'}, {'address': '0xa60c772958a3ed56c1f15dd055ba37ac8e523a0d', 'nameTag': 'Tornado.Cash: 500,000 cUSDC'}, {'address': '0xb04e030140b30c27bcdfaafffa98c57d80eda7b4', 'nameTag': 'Tornado.Cash: Community Fund'}, {'address': '0x8589427373d6d84e98730d7795d8f6f8731fda16', 'nameTag': 'Tornado.Cash: Donate'}, {'address': '0x756c4628e57f7e7f8a459ec2752968360cf4d1aa', 'nameTag': 'Tornado.Cash: Echoer'}, {'address': '0x5f6c97c6ad7bdd0ae7e0dd4ca33a4ed3fdabd4d7', 'nameTag': 'Tornado.Cash: Fee Manager'}, {'address': '0xfa4c1f3f7d5dd7c12a9adb82cd7dda542e3d59ef', 'nameTag': 'Tornado.Cash: Gas Compensation Vault'}, {'address': '0x5efda50f22d34f262c29268506c5fa42cb56a1ce', 'nameTag': 'Tornado.Cash: Governance'}, {'address': '0xffbac21a641dcfe4552920138d90f3638b3c9fba', 'nameTag': 'Tornado.Cash: Governance Impl'}, {'address': '0x2fc93484614a34f26f7970cbb94615ba109bb4bf', 'nameTag': 'Tornado.Cash: Governance Staking'}, {'address': '0x2f50508a8a3d323b91336fa3ea6ae50e55f32185', 'nameTag': 'Tornado.Cash: Governance Vault'}, {'address': '0x179f48c78f57a3a78f0608cc9197b8972921d1d2', 'nameTag': 'Tornado.Cash: Governance Vesting'}, {'address': '0xb20c66c4de72433f3ce747b58b86830c459ca911', 'nameTag': 'Tornado.Cash: Instance Registry'}, {'address': '0xca0840578f57fe71599d29375e16783424023357', 'nameTag': 'Tornado.Cash: L1 Helper'}, {'address': '0x746aebc06d2ae31b71ac51429a19d54e797878e9', 'nameTag': 'Tornado.Cash: Mining v2'}, {'address': '0x94a1b5cdb22c43faab4abeb5c74999895464ddaf', 'nameTag': 'Tornado.Cash: Mixer 1'}, {'address': '0xb541fc07bc7619fd4062a54d96268525cbc6ffef', 'nameTag': 'Tornado.Cash: Mixer 2'}, {'address': '0x94c92f096437ab9958fc0a37f09348f30389ae79', 'nameTag': 'Tornado.Cash: Poseidon 2'}, {'address': '0xd82ed8786d7c69dc7e052f7a542ab047971e73d2', 'nameTag': 'Tornado.Cash: Poseidon 3'}, {'address': '0x722122df12d4e14e13ac3b6895a86e84145b6967', 'nameTag': 'Tornado.Cash: Proxy'}, {'address': '0x58e8dcc13be9780fc42e8723d8ead4cf46943df2', 'nameTag': 'Tornado.Cash: Relayer Registry'}, {'address': '0x5cab7692d4e94096462119ab7bf57319726eed2a', 'nameTag': 'Tornado.Cash: Reward Swap'}, {'address': '0x88fd245fedec4a936e700f9173454d1931b4c307', 'nameTag': 'Tornado.Cash: Reward Verifier'}, {'address': '0xd90e2f925da726b50c4ed8d0fb90ad053324f31b', 'nameTag': 'Tornado.Cash: Router'}, {'address': '0x77777feddddffc19ff86db637967013e6c6a116c', 'nameTag': 'Tornado.Cash: TORN Token'}, {'address': '0x5f48c2a71b2cc96e3f0ccae4e39318ff0dc375b2', 'nameTag': 'Tornado.Cash: Team 1 Vesting'}, {'address': '0x00d5ec4cdf59374b2a47e842b799027356eac02b', 'nameTag': 'Tornado.Cash: Team 2 Vesting'}, {'address': '0x77c08248c93ab53ff734ac555c932f8b9089d4c9', 'nameTag': 'Tornado.Cash: Team 3 Vesting'}, {'address': '0xc3877028655ebe90b9447dd33de391c955ead267', 'nameTag': 'Tornado.Cash: Team 4 Vesting'}, {'address': '0xb43432ec23e228fb7cb0fa52968949458b509f4f', 'nameTag': 'Tornado.Cash: Team 5 Vesting'}, {'address': '0x653477c392c16b0765603074f157314cc4f40c32', 'nameTag': 'Tornado.Cash: Tree Update Verifier'}, {'address': '0x09193888b3f38c82dedfda55259a82c0e7de875e', 'nameTag': 'Tornado.Cash: Withdraw Verifier'}, {'address': '0x3efa30704d2b8bbac821307230376556cf8cc39e', 'nameTag': 'Tornado.Cash: vTORN Token'}, {'address': '0xD7f0E24Bd353404752F61c16EFed0847998B1205', 'label': 'sideshift.ai', 'category': 'mixing_service', 'currency': 'ETH', 'actor': 'sideshift'}, {'address': '0x87ef9c733296fF2E6Aae8d1023C0C4a53909a40f', 'label': 'sideshift.ai', 'category': 'mixing_service', 'currency': 'ETH', 'actor': 'sideshift'}, {'address': '0xcDd37Ada79F589c15bD4f8fD2083dc88E34A2af2', 'label': 'sideshift.ai', 'category': 'mixing_service', 'currency': 'ETH', 'actor': 'sideshift'}]\n",
      "Processing mixer/bridge: 0x94A1B5CdB22c43faab4AbEb5c74999895464Ddaf\n",
      "Processing mixer/bridge: 0x8589427373D6D84E98730D7795D8f6f8731FDA16\n",
      "Processing mixer/bridge: 0xdd4c48c0b24039969fc16d1cdf626eab821d3384\n",
      "Processing mixer/bridge: 0x77777feddddffc19ff86db637967013e6c6a116c\n",
      "Processing mixer/bridge: 0x3efa30704d2b8bbac821307230376556cf8cc39e\n",
      "Processing mixer/bridge: 0x12d66f87a04a9e220743712ce6d9bb1b5616b8fc\n",
      "Processing mixer/bridge: 0x178169b423a011fff22b9e3f3abea13414ddd0f1\n",
      "Processing mixer/bridge: 0x47ce0c6ed5b0ce3d3a51fdb1c52dc66a7c3c2936\n",
      "1 pages found for transactions in direction: out. Exiting after fetching all available pages.\n",
      "1 pages found for transactions in direction: out. Exiting after fetching all available pages.\n",
      "1 pages found for transactions in direction: out. Exiting after fetching all available pages.\n",
      "1 pages found for transactions in direction: in. Exiting after fetching all available pages.\n",
      "[]\n",
      "Processing mixer/bridge: 0x610b717796ad172b316836ac95a2ffad065ceab4\n",
      "From: []\n",
      "To: []\n",
      "1 pages found for transactions in direction: in. Exiting after fetching all available pages.\n",
      "[]\n",
      "Processing mixer/bridge: 0x4736dcf1b7a3d580672cce6e7c65cd5cc9cfba9d\n",
      "From: []\n",
      "To: []\n",
      "2 pages found for transactions in direction: out. Exiting after fetching all available pages.\n",
      "2 pages found for transactions in direction: out. Exiting after fetching all available pages.\n",
      "1 pages found for transactions in direction: in. Exiting after fetching all available pages.\n",
      "[]\n",
      "Processing mixer/bridge: 0xfd8610d20aa15b7b2e3be39b396a1bc3516c7144\n",
      "From: []\n",
      "To: []\n",
      "4 pages found for transactions in direction: out. Exiting after fetching all available pages.\n",
      "1 pages found for transactions in direction: in. Exiting after fetching all available pages.\n",
      "[]\n",
      "Processing mixer/bridge: 0xd96f2b1c14db8458374d9aca76e26c3d18364307\n",
      "From: []\n",
      "To: []\n",
      "3 pages found for transactions in direction: in. Exiting after fetching all available pages.\n",
      "[]\n",
      "Processing mixer/bridge: 0x0836222f2b2b24a3f36f98668ed8f0b38d1a872f\n",
      "2 pages found for transactions in direction: out. Exiting after fetching all available pages.\n",
      "1 pages found for transactions in direction: in. Exiting after fetching all available pages.\n",
      "[]\n",
      "Processing mixer/bridge: 0x910cbd523d972eb0a6f4cae4618ad62622b39dbf\n",
      "[]\n",
      "Processing mixer/bridge: 0xbb93e510bbcd0b7beb5a853875f9ec60275cf498\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/sticky/Documents/Bachelor_Thesis/bachelor/aml.ipynb Cell 22\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sticky/Documents/Bachelor_Thesis/bachelor/aml.ipynb#X30sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m futures \u001b[39m=\u001b[39m [executor\u001b[39m.\u001b[39msubmit(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess, mix_bridge, address, pages, pof) \u001b[39mfor\u001b[39;00m mix_bridge \u001b[39min\u001b[39;00m mix_bridge_data]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sticky/Documents/Bachelor_Thesis/bachelor/aml.ipynb#X30sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39mfor\u001b[39;00m future \u001b[39min\u001b[39;00m as_completed(futures):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sticky/Documents/Bachelor_Thesis/bachelor/aml.ipynb#X30sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     out, inn \u001b[39m=\u001b[39m future\u001b[39m.\u001b[39mresult()\n",
      "File \u001b[0;32m~/anaconda3/envs/bachelor/lib/python3.11/concurrent/futures/_base.py:243\u001b[0m, in \u001b[0;36mas_completed\u001b[0;34m(fs, timeout)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m(\n\u001b[1;32m    240\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m (of \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m) futures unfinished\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (\n\u001b[1;32m    241\u001b[0m                 \u001b[39mlen\u001b[39m(pending), total_futures))\n\u001b[0;32m--> 243\u001b[0m waiter\u001b[39m.\u001b[39;49mevent\u001b[39m.\u001b[39;49mwait(wait_timeout)\n\u001b[1;32m    245\u001b[0m \u001b[39mwith\u001b[39;00m waiter\u001b[39m.\u001b[39mlock:\n",
      "File \u001b[0;32m~/anaconda3/envs/bachelor/lib/python3.11/threading.py:622\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 622\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    623\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/anaconda3/envs/bachelor/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m     gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/sticky/Documents/Bachelor_Thesis/bachelor/aml.ipynb Cell 22\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sticky/Documents/Bachelor_Thesis/bachelor/aml.ipynb#X30sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m#print(pof.coinbase_data('candles', '2018-01-01'))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sticky/Documents/Bachelor_Thesis/bachelor/aml.ipynb#X30sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m#print(pof.binance_data('price', 'AUTOUSDT'))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sticky/Documents/Bachelor_Thesis/bachelor/aml.ipynb#X30sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m#print(pof.coinbase_data('buy', 'AUTO-USD'))\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sticky/Documents/Bachelor_Thesis/bachelor/aml.ipynb#X30sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39m#sc = SC()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sticky/Documents/Bachelor_Thesis/bachelor/aml.ipynb#X30sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39m#sc.get_sc_data(exchanges_used[0]['address'], 'dex')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sticky/Documents/Bachelor_Thesis/bachelor/aml.ipynb#X30sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m mix_bridge \u001b[39m=\u001b[39m MixBridge()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sticky/Documents/Bachelor_Thesis/bachelor/aml.ipynb#X30sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39mprint\u001b[39m(mix_bridge\u001b[39m.\u001b[39;49mcheck(\u001b[39m'\u001b[39;49m\u001b[39m0xA43Ce8Cc89Eff3AA5593c742fC56A30Ef2427CB0\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mdata/mixers.json\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m5\u001b[39;49m))\n",
      "\u001b[1;32m/Users/sticky/Documents/Bachelor_Thesis/bachelor/aml.ipynb Cell 22\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sticky/Documents/Bachelor_Thesis/bachelor/aml.ipynb#X30sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m tx_from_mix_bridge \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sticky/Documents/Bachelor_Thesis/bachelor/aml.ipynb#X30sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m tx_to_mix_bridge \u001b[39m=\u001b[39m []\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sticky/Documents/Bachelor_Thesis/bachelor/aml.ipynb#X30sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mwith\u001b[39;49;00m ThreadPoolExecutor(max_workers\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m) \u001b[39mas\u001b[39;49;00m executor:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sticky/Documents/Bachelor_Thesis/bachelor/aml.ipynb#X30sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     futures \u001b[39m=\u001b[39;49m [executor\u001b[39m.\u001b[39;49msubmit(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess, mix_bridge, address, pages, pof) \u001b[39mfor\u001b[39;49;00m mix_bridge \u001b[39min\u001b[39;49;00m mix_bridge_data]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sticky/Documents/Bachelor_Thesis/bachelor/aml.ipynb#X30sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     \u001b[39mfor\u001b[39;49;00m future \u001b[39min\u001b[39;49;00m as_completed(futures):\n",
      "File \u001b[0;32m~/anaconda3/envs/bachelor/lib/python3.11/concurrent/futures/_base.py:647\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 647\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshutdown(wait\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    648\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/bachelor/lib/python3.11/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[39mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         t\u001b[39m.\u001b[39;49mjoin()\n",
      "File \u001b[0;32m~/anaconda3/envs/bachelor/lib/python3.11/threading.py:1112\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1109\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot join current thread\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1111\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1112\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_for_tstate_lock()\n\u001b[1;32m   1113\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1114\u001b[0m     \u001b[39m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m     \u001b[39m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1116\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(timeout, \u001b[39m0\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/bachelor/lib/python3.11/threading.py:1132\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m     \u001b[39mif\u001b[39;00m lock\u001b[39m.\u001b[39;49macquire(block, timeout):\n\u001b[1;32m   1133\u001b[0m         lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m   1134\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 pages found for transactions in direction: in. Exiting after fetching all available pages.\n",
      "[]\n",
      "Processing mixer/bridge: 0xf60dd140cff0706bae9cd734ac3ae76ad9ebc32a\n",
      "1 pages found for transactions in direction: out. Exiting after fetching all available pages.\n",
      "1 pages found for transactions in direction: in. Exiting after fetching all available pages.\n",
      "[]\n",
      "Processing mixer/bridge: 0x07687e702b410fa43f4cb4af7fa097918ffd2730\n",
      "1 pages found for transactions in direction: in. Exiting after fetching all available pages.\n",
      "[]\n",
      "Processing mixer/bridge: 0xd691f27f38b395864ea86cfc7253969b409c362d\n",
      "1 pages found for transactions in direction: out. Exiting after fetching all available pages.\n",
      "1 pages found for transactions in direction: in. Exiting after fetching all available pages.\n",
      "[]\n",
      "Processing mixer/bridge: 0xf67721a2d8f736e75a49fdd7fad2e31d8676542a\n",
      "1 pages found for transactions in direction: in. Exiting after fetching all available pages.\n",
      "[]\n",
      "Processing mixer/bridge: 0xd4b88df4d29f5cedd6857912842cff3b20c8cfa3\n",
      "1 pages found for transactions in direction: out. Exiting after fetching all available pages.\n",
      "1 pages found for transactions in direction: in. Exiting after fetching all available pages.\n",
      "[]\n",
      "Processing mixer/bridge: 0xa160cdab225685da1d56aa342ad8841c3b53f291\n",
      "[]\n",
      "Processing mixer/bridge: 0x169ad27a470d064dede56a2d3ff727986b15d52b\n"
     ]
    }
   ],
   "source": [
    "# Function calls\n",
    "\n",
    "#ass_wallets = AssociatedWallets(CURRENCY)\n",
    "\n",
    "#direction = 'out'\n",
    "\n",
    "#addr_neigh = ass_wallets.bfs_neighbors(ADDRESS, 4, 10, True, direction)\n",
    "#addr_simple_neigh = ass_wallets.simple_neighbors(ADDRESS, direction)\n",
    "\n",
    "#with open(\"results/addresses_\" + direction + \".txt\", \"w\") as outfile:\n",
    "    #outfile.write(str(addr_neigh))\n",
    "\n",
    "#blacklist = Blacklist()\n",
    "#blacklist.ofac()\n",
    "#print(blacklist.check_membership('ETH', ADDRESS, json_data))\n",
    "#blacklist.check_dark_web('1DcU28QbeUiJVcSS8sZCf4ixeYXG26zEWN', 'data/plain_cluster_outgoing_rel.parquet')\n",
    "#blacklist.check_etherscan('0x690B9A9E9aa1C9dB991C7721a92d351Db4FaC990', 'data/hack_addresses_etherscan.json')\n",
    "\n",
    "\n",
    "#ex = Exchange(ADDRESS, 'eth', 3, 'in')\n",
    "#exchanges_used = ex.get_ex_used('dex')\n",
    "#exchanges_used = ex.get_ex_tags('0x1d42064Fc4Beb5F8aAF85F4617AE8b3b5B8Bd801', 'dex')\n",
    "#pprint(exchanges_used)\n",
    "\n",
    "#pof = PoF('eth')\n",
    "#print(pof.coinbase_data('candles', '2018-01-01'))\n",
    "#print(pof.binance_data('price', 'AUTOUSDT'))\n",
    "#print(pof.coinbase_data('buy', 'AUTO-USD'))\n",
    "\n",
    "#pprint(pof.binance_table('ETHUSDT', '1h'))\n",
    "#pof.check_profitloss('coinbase', 'ETHUSDT', '2018-08-09', '2023-09-10', 1, 1, -300)\n",
    "#print(pof.get_address_txs(ADDRESS, 'in', 1))\n",
    "#pof.check_pass_through_wallet(ADDRESS, CURRENCY)\n",
    "#pof.activity_analysis()\n",
    "\n",
    "#nft = NFT()\n",
    "#nfts_dict = nft.get_held_nfts(ADDRESS)\n",
    "#print(nfts_dict)\n",
    "#for nft in nfts_dict:\n",
    "    #print(nft)\n",
    "\n",
    "#nft_sc = nft.get_nft_sc('0x25ed58c027921e14d86380ea2646e3a1b5c55a8b')\n",
    "#with open(\"results/nft_sc\" + \".txt\", \"w\") as outfile:\n",
    "    #outfile.write(str(nft_sc))\n",
    "\n",
    "#erc20 = ERC20(ADDRESS)\n",
    "#erc20_dict = erc20.get_erc20_transfers()\n",
    "#print(erc20_dict)\n",
    "#print(erc20.get_erc20())\n",
    "#erc20.visualize()\n",
    "\n",
    "#sc = SC()\n",
    "#sc.get_sc_data(exchanges_used[0]['address'], 'dex')\n",
    "\n",
    "mix_bridge = MixBridge()\n",
    "print(mix_bridge.check('0xA43Ce8Cc89Eff3AA5593c742fC56A30Ef2427CB0', 'data/mixers.json', 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iknaio-api-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
