{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Settings and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general stuff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pprint import pprint\n",
    "import datetime\n",
    "\n",
    "#bfs\n",
    "from collections import deque\n",
    "\n",
    "#ofac stuff\n",
    "import csv\n",
    "import requests\n",
    "#import json\n",
    "import xmltodict\n",
    "from collections import defaultdict\n",
    "\n",
    "#for graphsense tag data extraction\n",
    "#from fastparquet import ParquetFile\n",
    "#import snappy\n",
    "\n",
    "#for flipside.xyz (SQL Databse)\n",
    "#from flipside import Flipside\n",
    "\n",
    "#graphsense stuff\n",
    "import graphsense\n",
    "from graphsense.api import addresses_api, bulk_api, entities_api, general_api, tags_api\n",
    "from graphsense.model.neighbor_addresses import NeighborAddresses\n",
    "\n",
    "#coinbase stuff\n",
    "#import json, requests\n",
    "import hmac, hashlib, time\n",
    "from requests.auth import AuthBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('config.json')\n",
    "config = json.load(f)\n",
    "f.close()\n",
    "\n",
    "CURRENCY = 'eth'\n",
    "ADDRESS = '0x0Daa654baf0Caa38E89Bc675fFB591537E5D9840'\n",
    "\n",
    "configuration = graphsense.Configuration(\n",
    "    host = config['graphsense']['host'],\n",
    "    api_key = {'api_key': config['graphsense']['api_key']})\n",
    "\n",
    "#with graphsense.ApiClient(configuration) as api_client:\n",
    "    #api_instance = general_api.GeneralApi(api_client)\n",
    "    #api_response = api_instance.get_statistics()\n",
    "    #pprint(api_response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Associated Wallets Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssociatedWallets():\n",
    "    \n",
    "    def simple_neighbors(self, address, direction):\n",
    "        with graphsense.ApiClient(configuration) as api_client:\n",
    "            # Create an instance of the API class\n",
    "            api_instance = addresses_api.AddressesApi(api_client)\n",
    "            currency = CURRENCY # str | The cryptocurrency code (e.g., eth)\n",
    "            address = ADDRESS # str | The cryptocurrency address\n",
    "            direction = \"out\" # str | Incoming or outgoing neighbors\n",
    "            only_ids = [\n",
    "                \"only_ids_example\",\n",
    "            ] # [str] | Restrict result to given set of comma separated addresses (optional)\n",
    "            include_labels = False # bool | Whether to include labels of first page of address tags (optional) if omitted the server will use the default value of False\n",
    "            page = \"page_example\" # str | Resumption token for retrieving the next page (optional)\n",
    "            pagesize = 10 # int | Number of items returned in a single page (optional)\n",
    "\n",
    "            # example passing only required values which don't have defaults set\n",
    "            try:\n",
    "                # Get an address's neighbors in the address graph\n",
    "                api_response = api_instance.list_address_neighbors(currency, address, direction)\n",
    "                return api_response\n",
    "            except graphsense.ApiException as e:\n",
    "                print(\"Exception when calling AddressesApi->list_address_neighbors: %s\\n\" % e)\n",
    "\n",
    "            # example passing only required values which don't have defaults set\n",
    "            # and optional values\n",
    "            #try:\n",
    "                # Get an address's neighbors in the address graph\n",
    "                #api_response = api_instance.list_address_neighbors(currency, address, direction, only_ids=only_ids, include_labels=include_labels, page=page, pagesize=pagesize)\n",
    "                #pprint(api_response)\n",
    "            #except graphsense.ApiException as e:\n",
    "                #print(\"Exception when calling AddressesApi->list_address_neighbors: %s\\n\" % e)\n",
    "\n",
    "    #Utility function to get neighbors of address        \n",
    "    def get_addr_neighbors(self, address, direction):\n",
    "\n",
    "        if (direction == 'out'):\n",
    "            degree = 'out_degree'\n",
    "            address_degree = 'address_out_degree'\n",
    "        else:\n",
    "            degree = 'in_degree'\n",
    "            address_degree = 'address_in_degree'\n",
    "\n",
    "        with graphsense.ApiClient(configuration) as api_client:\n",
    "            try:\n",
    "                api_instance = bulk_api.BulkApi(api_client)\n",
    "                print(f\"get_addr_neighbors of {address}\")\n",
    "                operation = \"list_address_neighbors\"\n",
    "                body = {'address': [address], 'direction': direction}\n",
    "\n",
    "                df_address_neighbors = pd.read_csv(api_instance.bulk_csv(CURRENCY, operation, body=body,\n",
    "                                                                    num_pages=1, _preload_content=False))\n",
    "                \n",
    "                df_address_neighbors = df_address_neighbors \\\n",
    "                    .loc[(df_address_neighbors['_error'] != 'not found') &\n",
    "                        (df_address_neighbors['_info'] != 'no data')].reset_index(drop=True)\n",
    "                \n",
    "                if df_address_neighbors.empty:\n",
    "                    df_address_neighbors.columns = ['address', 'entity', degree]\n",
    "                    return df_address_neighbors\n",
    "                \n",
    "                print(df_address_neighbors.columns)  # Print column names\n",
    "\n",
    "                \n",
    "                df_address_neighbors = df_address_neighbors \\\n",
    "                    .rename(columns={'address_address': 'address', \n",
    "                                    'address_entity': 'entity',\n",
    "                                    address_degree: degree})\n",
    "\n",
    "                return df_address_neighbors[['address', 'entity', degree]]\n",
    "                \n",
    "            except graphsense.ApiException as e:\n",
    "                print(\"Exception when calling Bulk Api: %s\\n\" % e)\n",
    "\n",
    "    # The Breadth-First Search algorithm:\n",
    "    def bfs_neighbors(self, seed_address, max_depth, max_degree, verbose, direction):\n",
    "\n",
    "        if (direction == 'out'):\n",
    "            degree = 'out_degree'\n",
    "            #address_degree = 'address_out_degree'\n",
    "        else:\n",
    "            degree = 'in_degree'\n",
    "            #address_degree = 'address_in_degree'\n",
    "        \n",
    "        # collect neighbors\n",
    "        neighbors = []\n",
    "        for i in range (0, max_depth):\n",
    "            neighbors.insert(i, [])\n",
    "        neighbors[0].append(seed_address)\n",
    "\n",
    "        #keep track of depth\n",
    "        levels = {seed_address: 0}\n",
    "                \n",
    "        # record visited addresses and entities\n",
    "        visited_addresses = set([seed_address])\n",
    "        \n",
    "        # maintain a queue of addresses\n",
    "        queue = deque([(seed_address, 0)])\n",
    "\n",
    "        while(queue):\n",
    "\n",
    "            # get first address from the queue\n",
    "            addr, level = queue.popleft()            \n",
    "\n",
    "            # retrieve address neighbors\n",
    "            df_neighbors = self.get_addr_neighbors(addr, direction)\n",
    "\n",
    "            # continue with neighbors out_degree < max_outdegree\n",
    "            for index, neighbor in df_neighbors.iterrows():\n",
    "\n",
    "                 # stop if address has already been visited\n",
    "                if(neighbor['address'] in visited_addresses):\n",
    "                    if verbose:\n",
    "                        print(addr, end=' ') \n",
    "                        print(\"STOP | same address\")\n",
    "                    continue\n",
    "                                \n",
    "                # stop if max depth is reached\n",
    "                if level + 1 == max_depth:\n",
    "                    print(level)\n",
    "                    if verbose:\n",
    "                        print(addr, end=' ') \n",
    "                        print(\"STOP | max depth\")\n",
    "                    continue\n",
    "\n",
    "                neighbors[level+1].append(neighbor['address'])\n",
    "\n",
    "                # stop if address out_degree exceeds threshold\n",
    "                if(neighbor[degree] > max_degree):\n",
    "                    if verbose:\n",
    "                        print(addr, end=' ') \n",
    "                        print(\"STOP | max degree\")\n",
    "                    continue\n",
    "                \n",
    "                queue.append((neighbor['address'], level + 1))\n",
    "                visited_addresses.add(neighbor['address'])\n",
    "                levels[neighbor['address']] = level + 1\n",
    "                    \n",
    "            if len(queue) == 0:\n",
    "                return neighbors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blacklist Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Blacklist():\n",
    "\n",
    "    def ofac(self):\n",
    "\n",
    "        coins = []\n",
    "        myCoins = {}\n",
    "        sdn = defaultdict(list)\n",
    "        filename = 'sdn2.xml'\n",
    "        URL = \"https://www.treasury.gov/ofac/downloads/sanctions/1.0/sdn_advanced.xml\"\n",
    "\n",
    "        response = requests.get(URL)\n",
    "        with open(filename, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "\n",
    "        xml_data = open(filename, 'r').read()  # Read file\n",
    "        d = xmltodict.parse(xml_data)\n",
    "\n",
    "        for i in d['Sanctions']['ReferenceValueSets']['FeatureTypeValues']['FeatureType']:\n",
    "            if 'Digital Currency Address' in i['#text']:\n",
    "                coins.append(i['@ID'])\n",
    "                myCoins[i['@ID']] =  i['#text'].replace('Digital Currency Address - ','')\n",
    "            #   print(i['@ID'],'-',i['#text'])\n",
    "\n",
    "        for i in d['Sanctions']['DistinctParties']['DistinctParty']:\n",
    "            if 'Feature' in i['Profile'].keys():\n",
    "                for j in i['Profile']['Feature']:\n",
    "                    if '@FeatureTypeID' in j:\n",
    "                        if type(j) is not str:\n",
    "                            if str(j['@FeatureTypeID']) in coins:\n",
    "                            #   print(j)\n",
    "                            #   print(j['FeatureVersion']['VersionDetail']['#text'])\n",
    "                                sdn[myCoins[j['@FeatureTypeID']]].append(j['FeatureVersion']['VersionDetail']['#text'])            \n",
    "                            #    break\n",
    "            \n",
    "        with open('results/sdn.json', 'w') as fp:\n",
    "            json_data = json.dump(sdn, fp)\n",
    "        fp.close()\n",
    "\n",
    "    def check_membership(self, currency, address, json_data):\n",
    "\n",
    "        currency_set = set(json_data[currency])\n",
    "\n",
    "        return address in currency_set\n",
    "    \n",
    "    def dark_web(self):\n",
    "\n",
    "        filename = \"/Users/sticky/Documents/Bachelor_Thesis/data/address_cluster.parquet/address_id_group=2/part-00520-b3ffb0c8-9bc9-45d0-b89b-a8f63c16284b.c000.snappy.parquet\"\n",
    "        def snappy_decompress(data, uncompressed_size):\n",
    "            return snappy.decompress(data)\n",
    "        pf = ParquetFile('filename') # filename includes .snappy.parquet extension\n",
    "        df = pf.to_pandas()\n",
    "        print(df)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exchanges Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exchange():\n",
    "    \n",
    "    def __init__(self, depth, direction):\n",
    "        self.DEPTH = depth\n",
    "        self.DIRECTION = direction\n",
    "\n",
    "    def get_ex_tags(self, address, type):\n",
    "\n",
    "        # Enter a context with an instance of the API client\n",
    "        with graphsense.ApiClient(configuration) as api_client:\n",
    "            # Create an instance of the API class\n",
    "            api_instance = addresses_api.AddressesApi(api_client)\n",
    "\n",
    "            currency = CURRENCY # str | The cryptocurrency code (e.g., btc)\n",
    "            #address = ADDRESS # str | The cryptocurrency address\n",
    "            page = \"page_example\" # str | Resumption token for retrieving the next page (optional)\n",
    "            pagesize = 10 # int | Number of items returned in a single page (optional)\n",
    "            include_tags = True\n",
    "\n",
    "            # example passing only required values which don't have defaults set\n",
    "            try:\n",
    "                # Get attribution tags for a given address\n",
    "                api_response = api_instance.list_tags_by_address(currency, address.lower())\n",
    "                exchange_data = api_response\n",
    "                \n",
    "                exchange_tags = []\n",
    "\n",
    "                for entry in exchange_data['address_tags']:\n",
    "                    actor = entry.get('actor', '')\n",
    "                    category = entry.get('category', '')\n",
    "                    label = entry.get('label', '')\n",
    "                    if ((actor or label) and (type == 'cex' and (category == 'exchange' or category == 'market'))) or ((actor or label) and type == 'dex' and category == 'defi_dex'):\n",
    "                        exchange_tags.append({\n",
    "                            'actor': actor,\n",
    "                            'category': category,\n",
    "                            'currency': entry.get('currency', ''),\n",
    "                            'label': label\n",
    "                        })\n",
    "\n",
    "                return exchange_tags\n",
    "                \n",
    "            except graphsense.ApiException as e:\n",
    "               print(\"Exception when calling AddressesApi->list_tags_by_address: %s\\n\" % e)\n",
    "    \n",
    "    def get_ex_used(self, type):\n",
    "\n",
    "        #hier einfach neighbors von ADDRESS finden mit der self.depth dann jedes von denen in get_cex_tags und dann falls result nicht empty ist einf in einer liste alles speichern und dann printen\n",
    "        \n",
    "        ass_wallets = AssociatedWallets()\n",
    "        max_degree = 7\n",
    "        verbose = True\n",
    "        neighbors = ass_wallets.bfs_neighbors(ADDRESS, self.DEPTH, max_degree, verbose, self.DIRECTION)\n",
    "\n",
    "        exchanges_used = []\n",
    "\n",
    "        for arr_level in neighbors:\n",
    "            for address in arr_level:\n",
    "                temp_exchange_tags = self.get_ex_tags(address, type)\n",
    "                if temp_exchange_tags:\n",
    "                    exchanges_used.append(temp_exchange_tags)\n",
    "\n",
    "        return exchanges_used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proof of Funds Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom authentication for Coinbase API\n",
    "class CoinbaseWalletAuth(AuthBase):\n",
    "    def __init__(self, api_key, secret_key):\n",
    "        self.api_key = api_key\n",
    "        self.secret_key = secret_key\n",
    "\n",
    "    def __call__(self, request):\n",
    "        timestamp = str(int(time.time()))\n",
    "        message = timestamp + request.method + request.path_url + (request.body or '')\n",
    "        signature = hmac.new(self.secret_key, message, hashlib.sha256).hexdigest()\n",
    "\n",
    "        request.headers.update({\n",
    "            'CB-ACCESS-SIGN': signature,\n",
    "            'CB-ACCESS-TIMESTAMP': timestamp,\n",
    "            'CB-ACCESS-KEY': self.api_key,\n",
    "        })\n",
    "        return request\n",
    "\n",
    "class PoF():\n",
    "    \n",
    "    def coinbase_data(self, type, date):\n",
    "\n",
    "        # Before implementation, set environmental variables with the names API_KEY and API_SECRET\n",
    "\n",
    "        f = open('config.json')\n",
    "        config = json.load(f)\n",
    "        f.close()   \n",
    "\n",
    "        #API_KEY = config['coinbase']['api_key']\n",
    "        #API_SECRET = config['coinbase']['api_secret']\n",
    "        #auth = CoinbaseWalletAuth(API_KEY, API_SECRET)\n",
    "\n",
    "        if type == 'buy':\n",
    "            api_url = config['coinbase']['buyprice_endpoint']\n",
    "        elif type == 'sell':\n",
    "            api_url = config['coinbase']['sellprice_endpoint']\n",
    "        elif type == 'exchange':\n",
    "            api_url = config['coinbase']['exchangeprice_endpoint']\n",
    "        elif type == 'spot':\n",
    "            api_url = config['coinbase']['spotprice_endpoint'] + date\n",
    "\n",
    "        # Get current user\n",
    "        #r = requests.get(api_url + 'user', auth=auth)\n",
    "        #print(r.json())\n",
    "        # {u'data': {u'username': None, u'resource': u'user', u'name': u'User'...\n",
    "\n",
    "        # Send funds\n",
    "        \"\"\"tx = {\n",
    "            'type': 'send',\n",
    "            'to': 'user@example.com',\n",
    "            'amount': '10.0',\n",
    "            'currency': 'USD',\n",
    "        }\"\"\"\n",
    "\n",
    "        #r = requests.post(api_url + 'accounts/primary/transactions', json=tx, auth=auth)\n",
    "        #print(r.json())\n",
    "        # {u'data': {u'status': u'pending', u'amount': {u'currency': u'BTC'...\n",
    "\n",
    "        response = requests.get(api_url)\n",
    "\n",
    "        # Process the response data\n",
    "        #if response.status_code == 200:\n",
    "            #print(response.json())\n",
    "        #else:\n",
    "            #print(\"Request failed:\", response.status_code)\n",
    "\n",
    "        return response.json()\n",
    "    \n",
    "    def binance_data(self, type='avgprice', start_date=datetime.date.today(), end_date=datetime.datetime.today(), symbol='ETHUSDT'):\n",
    "\n",
    "        f = open('config.json')\n",
    "        config = json.load(f)\n",
    "        f.close()\n",
    "\n",
    "        if type == 'avgprice':\n",
    "            api_url = config['binance']['avgprice_endpoint']\n",
    "        elif type == 'exchange':\n",
    "            api_url = config['binance']['exchangeprice_endpoint']\n",
    "        elif type == 'klines':\n",
    "            api_url = config['binance']['klines_endpoint']\n",
    "        elif type == '24hrstats':\n",
    "            api_url = config['binance']['24hrstats_endpoint']\n",
    "        \n",
    "        # Convert start and end dates to Unix timestamps (in milliseconds)\n",
    "\n",
    "        start_timestamp = int(datetime.datetime.strptime(start_date, \"%Y-%m-%d\").timestamp()) * 1000\n",
    "        end_timestamp = int(datetime.datetime.strptime(end_date, \"%Y-%m-%d\").timestamp()) * 1000\n",
    "\n",
    "        # Parameters for the API request\n",
    "        params = {\n",
    "            \"symbol\": symbol,\n",
    "            \"interval\": \"1d\",  # Daily interval\n",
    "            \"startTime\": start_timestamp,\n",
    "            \"endTime\": end_timestamp\n",
    "        }\n",
    "\n",
    "        response = requests.get(api_url, params=params)\n",
    "\n",
    "        # Process the response data\n",
    "        #if response.status_code == 200:\n",
    "            #print(response.json())\n",
    "        #else:\n",
    "            #print(\"Request failed:\", response.status_code)\n",
    "        \n",
    "        return response.json()\n",
    "    \n",
    "    def binance_table(self, ticker, interval='4h', limit=500, start='01-01-2023'):\n",
    "\n",
    "        \"\"\"\n",
    "        interval: str tick interval - 4h/1h/1d ...\n",
    "        \"\"\"\n",
    "\n",
    "        columns = ['open_time','open', 'high', 'low', 'close', 'volume','close_time', 'qav','num_trades','taker_base_vol','taker_quote_vol', 'ignore']\n",
    "        start = int(datetime.datetime.timestamp(pd.to_datetime(start))*1000)\n",
    "        api_url = f'https://www.binance.com/api/v3/klines?symbol={ticker}&interval={interval}&limit={limit}&startTime={start}'\n",
    "\n",
    "        data = pd.DataFrame(requests.get(api_url).json(), columns=columns, dtype=float)\n",
    "\n",
    "        data.index = [pd.to_datetime(x, unit='ms').strftime('%Y-%m-%d %H:%M:%S') for x in data.open_time]\n",
    "\n",
    "        usecols=['open', 'high', 'low', 'close', 'volume', 'qav','num_trades','taker_base_vol','taker_quote_vol']\n",
    "        \n",
    "        data = data[usecols]\n",
    "\n",
    "        return data\n",
    "    \n",
    "    def check_price(self, exchange, symbol, buy_date, sell_date, profit_or_loss):\n",
    "        \n",
    "        if exchange == 'coinbase':\n",
    "            buy_price_data = self.coinbase_data('spot', buy_date)\n",
    "            sell_price_data = self.coinbase_data('spot', sell_date)\n",
    "\n",
    "            buy_price = float(buy_price_data['data']['amount'])\n",
    "            sell_price = float(sell_price_data['data']['amount'])\n",
    "            \n",
    "        elif exchange == 'binance':\n",
    "            buy_price_data = self.binance_data('klines', buy_date, buy_date, symbol) \n",
    "            sell_price_data = self.binance_data('klines', sell_date, sell_date, symbol)\n",
    "\n",
    "            buy_price = float(buy_price_data[1])\n",
    "            sell_price = float(sell_price_data[1])\n",
    "\n",
    "        difference = abs(float(buy_price) - float(sell_price)) - abs(profit_or_loss)\n",
    "        \n",
    "        if abs(float(buy_price) - float(sell_price)) == abs(profit_or_loss):\n",
    "            print(float(buy_price) - float(sell_price))\n",
    "            print(difference)\n",
    "            return True\n",
    "        else:\n",
    "            print(float(buy_price) - float(sell_price))\n",
    "            print(difference)\n",
    "            return False\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "-300.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function calls\n",
    "\n",
    "#ass_wallets = AssociatedWallets(CURRENCY)\n",
    "\n",
    "#direction = 'out'\n",
    "\n",
    "#addr_neigh = ass_wallets.bfs_neighbors(ADDRESS, 4, 10, True, direction)\n",
    "#addr_simple_neigh = ass_wallets.simple_neighbors(ADDRESS, direction)\n",
    "\n",
    "#with open(\"results/addresses_\" + direction + \".txt\", \"w\") as outfile:\n",
    "    #outfile.write(str(addr_neigh))\n",
    "\n",
    "#blacklist = Blacklist()\n",
    "#blacklist.ofac()\n",
    "#print(blacklist.check_membership('ETH', ADDRESS, json_data))\n",
    "#blacklist.dark_web()\n",
    "\n",
    " # Open the JSON file\n",
    "#with open('results/sdn.json', 'r') as file:\n",
    "    # Load the JSON data\n",
    "    #json_data = json.load(file)\n",
    "\n",
    "\n",
    "#ex = Exchange(2, 'out')\n",
    "#exchanges_used = ex.get_ex_used('dex')\n",
    "#exchanges_used = ex.get_ex_tags('0x12459C951127e0c374FF9105DdA097662A027093', 'dex')\n",
    "#pprint(exchanges_used)\n",
    "\n",
    "pof = PoF()\n",
    "\n",
    "#print(pof.coinbase_data('spot', '2020-01-01'))\n",
    "#pof.binance_data('klines', '2023-01-13', '2023-01-14', 'ETHUSDT')\n",
    "\n",
    "#pprint(pof.binance_table('ETHUSDT', '1h'))\n",
    "pof.check_price('coinbase', 'ETHUSDT', '2018-01-01', '2023-09-04', 300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iknaio-api-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
