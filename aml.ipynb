{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Settings and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general stuff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pprint import pprint\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "#bfs\n",
    "from collections import deque\n",
    "\n",
    "#ofac stuff\n",
    "import csv\n",
    "import requests\n",
    "#import json\n",
    "import xmltodict\n",
    "from collections import defaultdict\n",
    "\n",
    "#dark web stuff\n",
    "#import pyarrow.parquet as pq\n",
    "#from pybloom_live import ScalableBloomFilter\n",
    "import dask.dataframe as dd\n",
    "\n",
    "#for graphsense tag data extraction\n",
    "#from fastparquet import ParquetFile\n",
    "#import snappy\n",
    "\n",
    "#for flipside.xyz (SQL Databse)\n",
    "#from flipside import Flipside\n",
    "\n",
    "#graphsense stuff\n",
    "import graphsense\n",
    "from graphsense.api import addresses_api, bulk_api, entities_api, general_api, tags_api\n",
    "from graphsense.model.neighbor_addresses import NeighborAddresses\n",
    "\n",
    "#coinbase stuff\n",
    "#import json, requests\n",
    "import hmac, hashlib, time\n",
    "from requests.auth import AuthBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('config.json')\n",
    "config = json.load(f)\n",
    "f.close()\n",
    "\n",
    "CURRENCY = 'eth'\n",
    "ADDRESS = '0x49bd56B275395130B41D67E1304b2d49F8A88725'\n",
    "\n",
    "configuration = graphsense.Configuration(\n",
    "    host = config['graphsense']['host'],\n",
    "    api_key = {'api_key': config['graphsense']['api_key']})\n",
    "\n",
    "#with graphsense.ApiClient(configuration) as api_client:\n",
    "    #api_instance = general_api.GeneralApi(api_client)\n",
    "    #api_response = api_instance.get_statistics()\n",
    "    #pprint(api_response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Associated Wallets Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssociatedWallets():\n",
    "    \n",
    "    def simple_neighbors(self, address, direction):\n",
    "        with graphsense.ApiClient(configuration) as api_client:\n",
    "            # Create an instance of the API class\n",
    "            api_instance = addresses_api.AddressesApi(api_client)\n",
    "            currency = CURRENCY # str | The cryptocurrency code (e.g., eth)\n",
    "            address = ADDRESS # str | The cryptocurrency address\n",
    "            direction = \"out\" # str | Incoming or outgoing neighbors\n",
    "            only_ids = [\n",
    "                \"only_ids_example\",\n",
    "            ] # [str] | Restrict result to given set of comma separated addresses (optional)\n",
    "            include_labels = False # bool | Whether to include labels of first page of address tags (optional) if omitted the server will use the default value of False\n",
    "            page = \"page_example\" # str | Resumption token for retrieving the next page (optional)\n",
    "            pagesize = 10 # int | Number of items returned in a single page (optional)\n",
    "\n",
    "            # example passing only required values which don't have defaults set\n",
    "            try:\n",
    "                # Get an address's neighbors in the address graph\n",
    "                api_response = api_instance.list_address_neighbors(currency, address, direction)\n",
    "                return api_response\n",
    "            except graphsense.ApiException as e:\n",
    "                print(\"Exception when calling AddressesApi->list_address_neighbors: %s\\n\" % e)\n",
    "\n",
    "            # example passing only required values which don't have defaults set\n",
    "            # and optional values\n",
    "            #try:\n",
    "                # Get an address's neighbors in the address graph\n",
    "                #api_response = api_instance.list_address_neighbors(currency, address, direction, only_ids=only_ids, include_labels=include_labels, page=page, pagesize=pagesize)\n",
    "                #pprint(api_response)\n",
    "            #except graphsense.ApiException as e:\n",
    "                #print(\"Exception when calling AddressesApi->list_address_neighbors: %s\\n\" % e)\n",
    "\n",
    "    #Utility function to get neighbors of address        \n",
    "    def get_addr_neighbors(self, address, direction):\n",
    "\n",
    "        if (direction == 'out'):\n",
    "            degree = 'out_degree'\n",
    "            address_degree = 'address_out_degree'\n",
    "        else:\n",
    "            degree = 'in_degree'\n",
    "            address_degree = 'address_in_degree'\n",
    "\n",
    "        with graphsense.ApiClient(configuration) as api_client:\n",
    "            try:\n",
    "                api_instance = bulk_api.BulkApi(api_client)\n",
    "                print(f\"get_addr_neighbors of {address}\")\n",
    "                operation = \"list_address_neighbors\"\n",
    "                body = {'address': [address], 'direction': direction}\n",
    "\n",
    "                df_address_neighbors = pd.read_csv(api_instance.bulk_csv(CURRENCY, operation, body=body,\n",
    "                                                                    num_pages=1, _preload_content=False))\n",
    "                \n",
    "                df_address_neighbors = df_address_neighbors \\\n",
    "                    .loc[(df_address_neighbors['_error'] != 'not found') &\n",
    "                        (df_address_neighbors['_info'] != 'no data')].reset_index(drop=True)\n",
    "                \n",
    "                if df_address_neighbors.empty:\n",
    "                    df_address_neighbors.columns = ['address', 'entity', degree]\n",
    "                    return df_address_neighbors\n",
    "                \n",
    "                print(df_address_neighbors.columns)  # Print column names\n",
    "\n",
    "                \n",
    "                df_address_neighbors = df_address_neighbors \\\n",
    "                    .rename(columns={'address_address': 'address', \n",
    "                                    'address_entity': 'entity',\n",
    "                                    address_degree: degree})\n",
    "\n",
    "                return df_address_neighbors[['address', 'entity', degree]]\n",
    "                \n",
    "            except graphsense.ApiException as e:\n",
    "                print(\"Exception when calling Bulk Api: %s\\n\" % e)\n",
    "\n",
    "    # The Breadth-First Search algorithm:\n",
    "    def bfs_neighbors(self, seed_address, max_depth, max_degree, verbose, direction):\n",
    "\n",
    "        if (direction == 'out'):\n",
    "            degree = 'out_degree'\n",
    "            #address_degree = 'address_out_degree'\n",
    "        else:\n",
    "            degree = 'in_degree'\n",
    "            #address_degree = 'address_in_degree'\n",
    "        \n",
    "        # collect neighbors\n",
    "        neighbors = []\n",
    "        for i in range (0, max_depth):\n",
    "            neighbors.insert(i, [])\n",
    "        neighbors[0].append(seed_address)\n",
    "\n",
    "        #keep track of depth\n",
    "        levels = {seed_address: 0}\n",
    "                \n",
    "        # record visited addresses and entities\n",
    "        visited_addresses = set([seed_address])\n",
    "        \n",
    "        # maintain a queue of addresses\n",
    "        queue = deque([(seed_address, 0)])\n",
    "\n",
    "        while(queue):\n",
    "\n",
    "            # get first address from the queue\n",
    "            addr, level = queue.popleft()            \n",
    "\n",
    "            # retrieve address neighbors\n",
    "            df_neighbors = self.get_addr_neighbors(addr, direction)\n",
    "\n",
    "            # continue with neighbors out_degree < max_outdegree\n",
    "            for index, neighbor in df_neighbors.iterrows():\n",
    "\n",
    "                 # stop if address has already been visited\n",
    "                if(neighbor['address'] in visited_addresses):\n",
    "                    if verbose:\n",
    "                        print(addr, end=' ') \n",
    "                        print(\"STOP | same address\")\n",
    "                    continue\n",
    "                                \n",
    "                # stop if max depth is reached\n",
    "                if level + 1 == max_depth:\n",
    "                    print(level)\n",
    "                    if verbose:\n",
    "                        print(addr, end=' ') \n",
    "                        print(\"STOP | max depth\")\n",
    "                    continue\n",
    "\n",
    "                neighbors[level+1].append(neighbor['address'])\n",
    "\n",
    "                # stop if address out_degree exceeds threshold\n",
    "                if(neighbor[degree] > max_degree):\n",
    "                    if verbose:\n",
    "                        print(addr, end=' ') \n",
    "                        print(\"STOP | max degree\")\n",
    "                    continue\n",
    "                \n",
    "                queue.append((neighbor['address'], level + 1))\n",
    "                visited_addresses.add(neighbor['address'])\n",
    "                levels[neighbor['address']] = level + 1\n",
    "                    \n",
    "            if len(queue) == 0:\n",
    "                return neighbors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blacklist Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Blacklist():\n",
    "    \n",
    "    def scrape_ofac(self):\n",
    "\n",
    "        coins = []\n",
    "        myCoins = {}\n",
    "        sdn = defaultdict(list)\n",
    "        filename = 'sdn2.xml'\n",
    "        URL = \"https://www.treasury.gov/ofac/downloads/sanctions/1.0/sdn_advanced.xml\"\n",
    "\n",
    "        response = requests.get(URL)\n",
    "        with open(filename, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "\n",
    "        xml_data = open(filename, 'r').read()  # Read file\n",
    "        d = xmltodict.parse(xml_data)\n",
    "\n",
    "        for i in d['Sanctions']['ReferenceValueSets']['FeatureTypeValues']['FeatureType']:\n",
    "            if 'Digital Currency Address' in i['#text']:\n",
    "                coins.append(i['@ID'])\n",
    "                myCoins[i['@ID']] =  i['#text'].replace('Digital Currency Address - ','')\n",
    "            #   print(i['@ID'],'-',i['#text'])\n",
    "\n",
    "        for i in d['Sanctions']['DistinctParties']['DistinctParty']:\n",
    "            if 'Feature' in i['Profile'].keys():\n",
    "                for j in i['Profile']['Feature']:\n",
    "                    if '@FeatureTypeID' in j:\n",
    "                        if type(j) is not str:\n",
    "                            if str(j['@FeatureTypeID']) in coins:\n",
    "                            #   print(j)\n",
    "                            #   print(j['FeatureVersion']['VersionDetail']['#text'])\n",
    "                                sdn[myCoins[j['@FeatureTypeID']]].append(j['FeatureVersion']['VersionDetail']['#text'])            \n",
    "                            #    break\n",
    "            \n",
    "        with open('results/sdn.json', 'w') as fp:\n",
    "            json_data = json.dump(sdn, fp)\n",
    "        fp.close()\n",
    "\n",
    "    def check_membership_ofac(self, currency, address, json_data):\n",
    "\n",
    "        currency_set = set(json_data[currency])\n",
    "        return address in currency_set\n",
    "    \n",
    "    def check_dark_web(self, address, parent_directory):\n",
    "        \n",
    "        # Iterate through each folder in the parent directory\n",
    "        for folder in os.listdir(parent_directory):\n",
    "\n",
    "            folder_path = os.path.join(parent_directory, folder)\n",
    "\n",
    "            # Check if the item in the directory is a folder\n",
    "            if os.path.isdir(folder_path):\n",
    "\n",
    "                # Iterate through all Parquet files in the folder\n",
    "                for file_name in os.listdir(folder_path):\n",
    "\n",
    "                    if file_name.endswith(\".parquet\"):\n",
    "\n",
    "                        file_path = os.path.join(folder_path, file_name)\n",
    "                        # Read the Parquet file into a Dask DataFrame\n",
    "                        ddf = dd.read_parquet(file_path, blocksize=\"400mb\")\n",
    "                        print(ddf.head())\n",
    "\n",
    "                        # Check if the BTC address exists in the 'Address' column\n",
    "                        check = ddf['address'].isin([address]).compute()\n",
    "\n",
    "                        if check.any():\n",
    "                            return True\n",
    "                        \n",
    "        return False\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exchanges Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exchange():\n",
    "    \n",
    "    def __init__(self, depth, direction):\n",
    "        self.DEPTH = depth\n",
    "        self.DIRECTION = direction\n",
    "\n",
    "    def get_ex_tags(self, address, type):\n",
    "\n",
    "        # Enter a context with an instance of the API client\n",
    "        with graphsense.ApiClient(configuration) as api_client:\n",
    "            # Create an instance of the API class\n",
    "            api_instance = addresses_api.AddressesApi(api_client)\n",
    "\n",
    "            currency = CURRENCY # str | The cryptocurrency code (e.g., btc)\n",
    "            #address = ADDRESS # str | The cryptocurrency address\n",
    "            page = \"page_example\" # str | Resumption token for retrieving the next page (optional)\n",
    "            pagesize = 10 # int | Number of items returned in a single page (optional)\n",
    "            include_tags = True\n",
    "\n",
    "            # example passing only required values which don't have defaults set\n",
    "            try:\n",
    "                # Get attribution tags for a given address\n",
    "                api_response = api_instance.list_tags_by_address(currency, address.lower())\n",
    "                exchange_data = api_response\n",
    "                \n",
    "                exchange_tags = []\n",
    "\n",
    "                for entry in exchange_data['address_tags']:\n",
    "                    actor = entry.get('actor', '')\n",
    "                    category = entry.get('category', '')\n",
    "                    label = entry.get('label', '')\n",
    "                    if ((actor or label) and (type == 'cex' and (category == 'exchange' or category == 'market'))) or ((actor or label) and type == 'dex' and category == 'defi_dex'):\n",
    "                        exchange_tags.append({\n",
    "                            'actor': actor,\n",
    "                            'category': category,\n",
    "                            'currency': entry.get('currency', ''),\n",
    "                            'label': label\n",
    "                        })\n",
    "\n",
    "                return exchange_tags\n",
    "                \n",
    "            except graphsense.ApiException as e:\n",
    "               print(\"Exception when calling AddressesApi->list_tags_by_address: %s\\n\" % e)\n",
    "    \n",
    "    def get_ex_used(self, type):\n",
    "\n",
    "        #hier einfach neighbors von ADDRESS finden mit der self.depth dann jedes von denen in get_cex_tags und dann falls result nicht empty ist einf in einer liste alles speichern und dann printen\n",
    "        \n",
    "        ass_wallets = AssociatedWallets()\n",
    "        max_degree = 7\n",
    "        verbose = True\n",
    "        neighbors = ass_wallets.bfs_neighbors(ADDRESS, self.DEPTH, max_degree, verbose, self.DIRECTION)\n",
    "\n",
    "        exchanges_used = []\n",
    "\n",
    "        for arr_level in neighbors:\n",
    "            for address in arr_level:\n",
    "                temp_exchange_tags = self.get_ex_tags(address, type)\n",
    "                if temp_exchange_tags:\n",
    "                    exchanges_used.append(temp_exchange_tags)\n",
    "\n",
    "        return exchanges_used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proof of Funds Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom authentication for Coinbase API\n",
    "class CoinbaseWalletAuth(AuthBase):\n",
    "    def __init__(self, api_key, secret_key):\n",
    "        self.api_key = api_key\n",
    "        self.secret_key = secret_key\n",
    "\n",
    "    def __call__(self, request):\n",
    "        timestamp = str(int(time.time()))\n",
    "        message = timestamp + request.method + request.path_url + (request.body or '')\n",
    "        signature = hmac.new(self.secret_key, message, hashlib.sha256).hexdigest()\n",
    "\n",
    "        request.headers.update({\n",
    "            'CB-ACCESS-SIGN': signature,\n",
    "            'CB-ACCESS-TIMESTAMP': timestamp,\n",
    "            'CB-ACCESS-KEY': self.api_key,\n",
    "        })\n",
    "        return request\n",
    "\n",
    "class PoF():\n",
    "\n",
    "    #Candles data Coinbase\n",
    "\n",
    "    \"\"\"Each bucket is an array of the following information:\n",
    "\n",
    "    time: bucket start time\n",
    "    low: lowest price during the bucket interval\n",
    "    high: highest price during the bucket interval\n",
    "    open: opening price (first trade) in the bucket interval\n",
    "    close: closing price (last trade) in the bucket interval\n",
    "    volume: volume of trading activity during the bucket interval\"\"\"\n",
    "    \n",
    "    def coinbase_data(self, type, start_date=datetime.date.today()):\n",
    "\n",
    "        # Before implementation, set environmental variables with the names API_KEY and API_SECRET\n",
    "\n",
    "        f = open('config.json')\n",
    "        config = json.load(f)\n",
    "        f.close()   \n",
    "\n",
    "        #API_KEY = config['coinbase']['api_key']\n",
    "        #API_SECRET = config['coinbase']['api_secret']\n",
    "        #auth = CoinbaseWalletAuth(API_KEY, API_SECRET)\n",
    "\n",
    "        if type == 'buy':\n",
    "            api_url = config['coinbase']['buyprice_endpoint']\n",
    "        elif type == 'sell':\n",
    "            api_url = config['coinbase']['sellprice_endpoint']\n",
    "        elif type == 'exchange':\n",
    "            api_url = config['coinbase']['exchangeprice_endpoint']\n",
    "        elif type == 'spot':\n",
    "            api_url = config['coinbase']['spotprice_endpoint']\n",
    "        elif type == 'candles':\n",
    "            api_url = config['coinbase']['candles_endpoint']\n",
    "\n",
    "        # Convert the start date string to a datetime object\n",
    "        #start_date_datetime = datetime.datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "\n",
    "        # Calculate the end date by adding one day to the start date\n",
    "        #end_date_datetime = start_date_datetime + datetime.timedelta(days=1)\n",
    "\n",
    "        # Convert the end date to a string in the same format\n",
    "        #end_date = end_date_datetime.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        # Parameters for the API request\n",
    "        params_spot = {\n",
    "            \"date\": start_date\n",
    "        }\n",
    "\n",
    "        # Parameters for the API request\n",
    "        params_candles = {\n",
    "            \"granularity\": 86400,  # Daily interval\n",
    "            \"start\": start_date,\n",
    "            \"end\": start_date\n",
    "        }\n",
    "\n",
    "        # Get current user\n",
    "        #r = requests.get(api_url + 'user', auth=auth)\n",
    "        #print(r.json())\n",
    "        # {u'data': {u'username': None, u'resource': u'user', u'name': u'User'...\n",
    "\n",
    "        # Send funds\n",
    "        \"\"\"tx = {\n",
    "            'type': 'send',\n",
    "            'to': 'user@example.com',\n",
    "            'amount': '10.0',\n",
    "            'currency': 'USD',\n",
    "        }\"\"\"\n",
    "\n",
    "        #r = requests.post(api_url + 'accounts/primary/transactions', json=tx, auth=auth)\n",
    "        #print(r.json())\n",
    "        # {u'data': {u'status': u'pending', u'amount': {u'currency': u'BTC'...\n",
    "\n",
    "        if (len(start_date) == 0):\n",
    "            response = requests.get(api_url)\n",
    "        else:\n",
    "            if type == 'spot':\n",
    "                response = requests.get(api_url, params=params_spot)\n",
    "            elif type == 'candles':\n",
    "                response = requests.get(api_url, params=params_candles)\n",
    "\n",
    "        # Process the response data\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(\"Request failed:\", response.status_code)\n",
    "\n",
    "    \n",
    "    #Klines data Binance\n",
    "    \"\"\"[\n",
    "        [\n",
    "            1499040000000,      // Kline open time\n",
    "            \"0.01634790\",       // Open price\n",
    "            \"0.80000000\",       // High price\n",
    "            \"0.01575800\",       // Low price\n",
    "            \"0.01577100\",       // Close price\n",
    "            \"148976.11427815\",  // Volume\n",
    "            1499644799999,      // Kline Close time\n",
    "            \"2434.19055334\",    // Quote asset volume\n",
    "            308,                // Number of trades\n",
    "            \"1756.87402397\",    // Taker buy base asset volume\n",
    "            \"28.46694368\",      // Taker buy quote asset volume\n",
    "            \"0\"                 // Unused field, ignore.\n",
    "        ]\n",
    "        ]\"\"\"\n",
    "    \n",
    "    def binance_data(self, type='avgprice', start_date=datetime.date.today(), end_date=datetime.datetime.today(), symbol='ETHUSDT'):\n",
    "\n",
    "        f = open('config.json')\n",
    "        config = json.load(f)\n",
    "        f.close()\n",
    "\n",
    "        if type == 'avgprice':\n",
    "            api_url = config['binance']['avgprice_endpoint']\n",
    "        elif type == 'exchange':\n",
    "            api_url = config['binance']['exchangeprice_endpoint']\n",
    "        elif type == 'klines':\n",
    "            api_url = config['binance']['klines_endpoint']\n",
    "        elif type == '24hrstats':\n",
    "            api_url = config['binance']['24hrstats_endpoint']\n",
    "        \n",
    "        # Convert start and end dates to Unix timestamps (in milliseconds)\n",
    "\n",
    "        start_timestamp = int(datetime.datetime.strptime(start_date, \"%Y-%m-%d\").timestamp()) * 1000\n",
    "        #end_timestamp = int(datetime.datetime.strptime(end_date, \"%Y-%m-%d\").timestamp()) * 1000\n",
    "\n",
    "        # Parameters for the API request\n",
    "        params = {\n",
    "            \"symbol\": symbol,\n",
    "            \"interval\": \"1d\",  # Daily interval\n",
    "            \"startTime\": start_timestamp\n",
    "            #\"endTime\": end_timestamp\n",
    "        }\n",
    "\n",
    "        response = requests.get(api_url, params=params)\n",
    "\n",
    "        # Process the response data\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(\"Request failed:\", response.status_code)\n",
    "        \n",
    "        \n",
    "    def binance_table(self, ticker, interval='4h', limit=500, start='01-01-2023'):\n",
    "\n",
    "        \"\"\"\n",
    "        interval: str tick interval - 4h/1h/1d ...\n",
    "        \"\"\"\n",
    "\n",
    "        columns = ['open_time','open', 'high', 'low', 'close', 'volume','close_time', 'qav','num_trades','taker_base_vol','taker_quote_vol', 'ignore']\n",
    "        start = int(datetime.datetime.timestamp(pd.to_datetime(start))*1000)\n",
    "        api_url = f'https://www.binance.com/api/v3/klines?symbol={ticker}&interval={interval}&limit={limit}&startTime={start}'\n",
    "\n",
    "        data = pd.DataFrame(requests.get(api_url).json(), columns=columns, dtype=float)\n",
    "\n",
    "        data.index = [pd.to_datetime(x, unit='ms').strftime('%Y-%m-%d %H:%M:%S') for x in data.open_time]\n",
    "\n",
    "        usecols=['open', 'high', 'low', 'close', 'volume', 'qav','num_trades','taker_base_vol','taker_quote_vol']\n",
    "        \n",
    "        data = data[usecols]\n",
    "\n",
    "        return data\n",
    "    \n",
    "    \n",
    "    def check_price(self, exchange, symbol, buy_date, sell_date, buy_amount, sell_amount, profit_or_loss):\n",
    "        \n",
    "        if exchange == 'coinbase':\n",
    "            buy_price_data = self.coinbase_data('candles', buy_date)\n",
    "            sell_price_data = self.coinbase_data('candles', sell_date)\n",
    "\n",
    "            buy_price = float(buy_price_data[0][3])\n",
    "            sell_price = float(sell_price_data[0][3])\n",
    "\n",
    "            buy_total = buy_price * buy_amount\n",
    "            sell_total = sell_price * sell_amount\n",
    "            \n",
    "        elif exchange == 'binance':\n",
    "            \n",
    "            buy_price_data = self.binance_data('klines', buy_date, symbol)\n",
    "            sell_price_data = self.binance_data('klines', sell_date, symbol)\n",
    "\n",
    "            buy_price = float(buy_price_data[0][1])\n",
    "            sell_price = float(sell_price_data[0][1])\n",
    "\n",
    "            buy_total = buy_price * buy_amount\n",
    "            sell_total = sell_price * sell_amount\n",
    "\n",
    "        difference = abs(abs(float(buy_price) - float(sell_price)) - abs(profit_or_loss))\n",
    "        \n",
    "        if abs(float(buy_total) - float(sell_total)) == abs(profit_or_loss):\n",
    "            print(\"Actual profit/loss: \" + str(float(sell_total) - float(buy_total)))\n",
    "            print(\"Difference between reported profit/loss and actual profit/loss value: \" + str(difference))\n",
    "            return True\n",
    "        else:\n",
    "            print(\"Actual profit/loss: \" + str(float(sell_total) - float(buy_total)))\n",
    "            print(\"Difference between reported profit/loss and actual profit/loss value: \" + str(difference))            \n",
    "            return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NFTs Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NFT():\n",
    "\n",
    "    def get_nft_transfers(self, address, page=1, offset=100):\n",
    "\n",
    "        f = open('config.json')\n",
    "        config = json.load(f)\n",
    "        f.close()\n",
    "\n",
    "        params = {\n",
    "            \"module\": \"account\",\n",
    "            \"action\": \"tokennfttx\",\n",
    "            \"address\": address,\n",
    "            \"page\": page,\n",
    "            \"offset\": offset,\n",
    "            \"sort\": \"asc\",\n",
    "            \"apikey\": config['etherscan']['api_key']\n",
    "         }\n",
    "        \n",
    "        response = requests.get(config['etherscan']['host'], params=params)\n",
    "        data = response.json()\n",
    "\n",
    "        if data['status'] != \"1\" or 'result' not in data:\n",
    "            print(f\"Error fetching transactions for address {address}: {data['message']}\")\n",
    "            return []\n",
    "\n",
    "        return data['result']\n",
    "    \n",
    "    def get_held_nfts(self, address):\n",
    "        \n",
    "        transfers = self.get_nft_transfers(address)\n",
    "\n",
    "        incoming_nfts = {tx['tokenID']: tx for tx in transfers if tx['to'] == address.lower()}\n",
    "        outgoing_nfts = {tx['tokenID']: tx for tx in transfers if tx['from'] == address.lower()}\n",
    "\n",
    "        held_nfts = {tid: tx for tid, tx in incoming_nfts.items() if tid not in outgoing_nfts}\n",
    "\n",
    "        return list(held_nfts.values())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'blockNumber': '14710242', 'timeStamp': '1651658186', 'hash': '0x78c490ed3bba9b6fd9ec5e1636365e904a78869966274b67bb58aa2d66979d92', 'nonce': '0', 'blockHash': '0x12bfae624d6022ef6a88bfe51ec17984ff87f9385bde9100c50815eb9e9eb213', 'from': '0x981b749a0ddca1c8f2ddc44a52b57d89e2d51344', 'contractAddress': '0x25ed58c027921e14d86380ea2646e3a1b5c55a8b', 'to': '0x49bd56b275395130b41d67e1304b2d49f8a88725', 'tokenID': '3876', 'tokenName': 'Devs for Revolution', 'tokenSymbol': 'DEVS', 'tokenDecimal': '0', 'transactionIndex': '191', 'gas': '355560', 'gasPrice': '30228736586', 'gasUsed': '256124', 'cumulativeGasUsed': '23328673', 'input': 'deprecated', 'confirmations': '3369022'}\n",
      "{'blockNumber': '15062025', 'timeStamp': '1656750548', 'hash': '0x818df6759851c4dac83ed2f47d0290b5f6e56b7d0d346ea0a8b766cda67b460c', 'nonce': '2', 'blockHash': '0x2e574e6b7a72768880c559027c3b4cdaea13503c28e509a3a33d91a9f88cc9d7', 'from': '0x283af0b28c62c092c9727f1ee09c02ca627eb7f5', 'contractAddress': '0x57f1887a8bf19b14fc0df6fd9b2acc9af147ea85', 'to': '0x49bd56b275395130b41d67e1304b2d49f8a88725', 'tokenID': '50756846049717319812805029593973488824275925303711106963511783477073325272197', 'tokenName': 'Ethereum Name Service', 'tokenSymbol': 'ENS', 'tokenDecimal': '0', 'transactionIndex': '103', 'gas': '305947', 'gasPrice': '23297943042', 'gasUsed': '275272', 'cumulativeGasUsed': '24347037', 'input': 'deprecated', 'confirmations': '3017239'}\n",
      "{'blockNumber': '16413629', 'timeStamp': '1673802959', 'hash': '0xaa69630182443484fd5b99d1d3c3889657f3367b205d216b3870c6050c96cb5e', 'nonce': '12', 'blockHash': '0x90f7a28e11c46a1e0c388d77d5b9d5e762f0c59abd800ae0d8d937772ee96e3c', 'from': '0x7a70536c4d695b1ec9df972e91461e834bfb00e8', 'contractAddress': '0x6234bce6a6cb2d3fcf24804224df182a68ce284a', 'to': '0x49bd56b275395130b41d67e1304b2d49f8a88725', 'tokenID': '1261', 'tokenName': '1928 Apes', 'tokenSymbol': 'NTEA', 'tokenDecimal': '0', 'transactionIndex': '101', 'gas': '222704', 'gasPrice': '19110987100', 'gasUsed': '166340', 'cumulativeGasUsed': '7867885', 'input': 'deprecated', 'confirmations': '1665635'}\n"
     ]
    }
   ],
   "source": [
    "# Function calls\n",
    "\n",
    "#ass_wallets = AssociatedWallets(CURRENCY)\n",
    "\n",
    "#direction = 'out'\n",
    "\n",
    "#addr_neigh = ass_wallets.bfs_neighbors(ADDRESS, 4, 10, True, direction)\n",
    "#addr_simple_neigh = ass_wallets.simple_neighbors(ADDRESS, direction)\n",
    "\n",
    "#with open(\"results/addresses_\" + direction + \".txt\", \"w\") as outfile:\n",
    "    #outfile.write(str(addr_neigh))\n",
    "\n",
    "#blacklist = Blacklist()\n",
    "#blacklist.ofac()\n",
    "#print(blacklist.check_membership('ETH', ADDRESS, json_data))\n",
    "#blacklist.check_dark_web('1DcU28QbeUiJVcSS8sZCf4ixeYXG26zEWN', 'blacklist_data/address_cluster.parquet')\n",
    "\n",
    " # Open the JSON file\n",
    "#with open('results/sdn.json', 'r') as file:\n",
    "    # Load the JSON data\n",
    "    #json_data = json.load(file)\n",
    "\n",
    "\n",
    "#ex = Exchange(3, 'in')\n",
    "#exchanges_used = ex.get_ex_used('dex')\n",
    "#exchanges_used = ex.get_ex_tags('0x12459C951127e0c374FF9105DdA097662A027093', 'dex')\n",
    "#pprint(exchanges_used)\n",
    "\n",
    "#pof = PoF()\n",
    "\n",
    "#print(pof.coinbase_data('candles', '2018-01-01'))\n",
    "#pof.binance_data('klines', '2023-01-13', 'ETHUSDT')\n",
    "\n",
    "#pprint(pof.binance_table('ETHUSDT', '1h'))\n",
    "#pof.check_price('coinbase', 'ETHUSDT', '2020-01-01', '2023-09-04', 1, 1, 1507.1100000000001)\n",
    "\n",
    "nft = NFT()\n",
    "nfts_list = nft.get_held_nfts(ADDRESS)\n",
    "for nft in nfts_list:\n",
    "    print(nft)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iknaio-api-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
