{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Settings and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pprint import pprint\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "#Associated Wallets imports\n",
    "from collections import deque\n",
    "\n",
    "#Ofac imports\n",
    "import csv\n",
    "import requests\n",
    "import xmltodict\n",
    "from collections import defaultdict\n",
    "\n",
    "#Dark Web imports\n",
    "import dask.dataframe as dd\n",
    "import yaml\n",
    "\n",
    "#Flipside imports\n",
    "#for flipside.xyz (SQL Databse)\n",
    "#from flipside import Flipside\n",
    "\n",
    "#Graphsense imports\n",
    "import graphsense\n",
    "from graphsense.api import addresses_api, bulk_api, entities_api, general_api, tags_api\n",
    "from graphsense.model.neighbor_addresses import NeighborAddresses\n",
    "\n",
    "#Coinbase imports\n",
    "import hmac, hashlib, time\n",
    "from requests.auth import AuthBase\n",
    "\n",
    "#Visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import calendar\n",
    "\n",
    "#Mixer/Bridges imports\n",
    "from collections import namedtuple\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('config.json')\n",
    "config = json.load(f)\n",
    "f.close()\n",
    "\n",
    "CURRENCY = 'eth'\n",
    "ADDRESS = '0x690B9A9E9aa1C9dB991C7721a92d351Db4FaC990'\n",
    "\n",
    "configuration = graphsense.Configuration(\n",
    "    host = config['graphsense']['host'],\n",
    "    api_key = {'api_key': config['graphsense']['api_key']})\n",
    "\n",
    "#with graphsense.ApiClient(configuration) as api_client:\n",
    "    #api_instance = general_api.GeneralApi(api_client)\n",
    "    #api_response = api_instance.get_statistics()\n",
    "    #pprint(api_response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Associated Wallets Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssociatedWallets():\n",
    "\n",
    "\n",
    "    def __init__(self, currency, depth):\n",
    "        self.currency = currency\n",
    "\n",
    "    \n",
    "    def simple_neighbors(self, address, direction):\n",
    "        with graphsense.ApiClient(configuration) as api_client:\n",
    "            # Create an instance of the API class\n",
    "            api_instance = addresses_api.AddressesApi(api_client)\n",
    "            #currency = CURRENCY # str | The cryptocurrency code (e.g., eth)\n",
    "            #address = ADDRESS # str | The cryptocurrency address\n",
    "            #direction = \"out\" # str | Incoming or outgoing neighbors\n",
    "            #only_ids = [\n",
    "                #\"only_ids_example\",\n",
    "            #] # [str] | Restrict result to given set of comma separated addresses (optional)\n",
    "            #include_labels = False # bool | Whether to include labels of first page of address tags (optional) if omitted the server will use the default value of False\n",
    "            #page = \"page_example\" # str | Resumption token for retrieving the next page (optional)\n",
    "            #pagesize = 10 # int | Number of items returned in a single page (optional)\n",
    "\n",
    "            # example passing only required values which don't have defaults set\n",
    "            try:\n",
    "                # Get an address's neighbors in the address graph\n",
    "                api_response = api_instance.list_address_neighbors(self.currency, address, direction)\n",
    "                return api_response\n",
    "            except graphsense.ApiException as e:\n",
    "                print(\"Exception when calling AddressesApi->list_address_neighbors: %s\\n\" % e)\n",
    "                \n",
    "\n",
    "    #Utility function to get neighbors of address        \n",
    "    def get_addr_neighbors(self, address, direction):\n",
    "\n",
    "        if (direction == 'out'):\n",
    "            degree = 'out_degree'\n",
    "            address_degree = 'address_out_degree'\n",
    "        else:\n",
    "            degree = 'in_degree'\n",
    "            address_degree = 'address_in_degree'\n",
    "\n",
    "        with graphsense.ApiClient(configuration) as api_client:\n",
    "            try:\n",
    "                api_instance = bulk_api.BulkApi(api_client)\n",
    "                print(f\"get_addr_neighbors of {address}\")\n",
    "                operation = \"list_address_neighbors\"\n",
    "                body = {'address': [address], 'direction': direction}\n",
    "\n",
    "                df_address_neighbors = pd.read_csv(api_instance.bulk_csv(self.currency, operation, body=body,\n",
    "                                                                    num_pages=1, _preload_content=False))\n",
    "                \n",
    "                df_address_neighbors = df_address_neighbors \\\n",
    "                    .loc[(df_address_neighbors['_error'] != 'not found') &\n",
    "                        (df_address_neighbors['_info'] != 'no data')].reset_index(drop=True)\n",
    "                \n",
    "                if df_address_neighbors.empty:\n",
    "                    df_address_neighbors.columns = ['address', 'entity', degree]\n",
    "                    return df_address_neighbors\n",
    "                \n",
    "                print(df_address_neighbors.columns)  # Print column names\n",
    "                \n",
    "                df_address_neighbors = df_address_neighbors \\\n",
    "                    .rename(columns={'address_address': 'address', \n",
    "                                    'address_entity': 'entity',\n",
    "                                    address_degree: degree})\n",
    "\n",
    "                return df_address_neighbors[['address', 'entity', degree]]\n",
    "                \n",
    "            except graphsense.ApiException as e:\n",
    "                print(\"Exception when calling Bulk Api: %s\\n\" % e)\n",
    "\n",
    "\n",
    "    # The Breadth-First Search algorithm:\n",
    "    def bfs_neighbors(self, seed_address, max_depth, max_degree, verbose, direction):\n",
    "\n",
    "        if (direction == 'out'):\n",
    "            degree = 'out_degree'\n",
    "        else:\n",
    "            degree = 'in_degree'\n",
    "        \n",
    "        # collect neighbors\n",
    "        neighbors = []\n",
    "        for i in range (0, max_depth):\n",
    "            neighbors.insert(i, [])\n",
    "        neighbors[0].append(seed_address)\n",
    "\n",
    "        #keep track of depth\n",
    "        levels = {seed_address: 0}\n",
    "                \n",
    "        # record visited addresses and entities\n",
    "        visited_addresses = set([seed_address])\n",
    "        \n",
    "        # maintain a queue of addresses\n",
    "        queue = deque([(seed_address, 0)])\n",
    "\n",
    "        while(queue):\n",
    "\n",
    "            # get first address from the queue\n",
    "            address, level = queue.popleft()            \n",
    "\n",
    "            # retrieve address neighbors\n",
    "            df_neighbors = self.get_addr_neighbors(address, direction)\n",
    "\n",
    "            # continue with neighbors out_degree < max_outdegree\n",
    "            for index, neighbor in df_neighbors.iterrows():\n",
    "\n",
    "                 # stop if address has already been visited\n",
    "                if(neighbor['address'] in visited_addresses):\n",
    "                    if verbose:\n",
    "                        print(address, end=' ') \n",
    "                        print(\"STOP | same address\")\n",
    "                    continue\n",
    "                                \n",
    "                # stop if max depth is reached\n",
    "                if level + 1 == max_depth:\n",
    "                    print(level)\n",
    "                    if verbose:\n",
    "                        print(address, end=' ') \n",
    "                        print(\"STOP | max depth\")\n",
    "                    continue\n",
    "\n",
    "                neighbors[level+1].append(neighbor['address'])\n",
    "\n",
    "                # stop if address out_degree exceeds threshold\n",
    "                if(neighbor[degree] > max_degree):\n",
    "                    if verbose:\n",
    "                        print(address, end=' ') \n",
    "                        print(\"STOP | max degree\")\n",
    "                    continue\n",
    "                \n",
    "                queue.append((neighbor['address'], level + 1))\n",
    "                visited_addresses.add(neighbor['address'])\n",
    "                levels[neighbor['address']] = level + 1\n",
    "                    \n",
    "            if len(queue) == 0:\n",
    "                return neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blacklist Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Blacklist():\n",
    "    \n",
    "\n",
    "    def scrape_ofac(self):\n",
    "\n",
    "        coins = []\n",
    "        myCoins = {}\n",
    "        sdn = defaultdict(list)\n",
    "        filename = 'sdn2.xml'\n",
    "        URL = \"https://www.treasury.gov/ofac/downloads/sanctions/1.0/sdn_advanced.xml\"\n",
    "\n",
    "        response = requests.get(URL)\n",
    "        with open(filename, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "\n",
    "        xml_data = open(filename, 'r').read()  # Read file\n",
    "        d = xmltodict.parse(xml_data)\n",
    "\n",
    "        for i in d['Sanctions']['ReferenceValueSets']['FeatureTypeValues']['FeatureType']:\n",
    "            if 'Digital Currency Address' in i['#text']:\n",
    "                coins.append(i['@ID'])\n",
    "                myCoins[i['@ID']] =  i['#text'].replace('Digital Currency Address - ','')\n",
    "            #   print(i['@ID'],'-',i['#text'])\n",
    "\n",
    "        for i in d['Sanctions']['DistinctParties']['DistinctParty']:\n",
    "            if 'Feature' in i['Profile'].keys():\n",
    "                for j in i['Profile']['Feature']:\n",
    "                    if '@FeatureTypeID' in j:\n",
    "                        if type(j) is not str:\n",
    "                            if str(j['@FeatureTypeID']) in coins:\n",
    "                            #   print(j)\n",
    "                            #   print(j['FeatureVersion']['VersionDetail']['#text'])\n",
    "                                sdn[myCoins[j['@FeatureTypeID']]].append(j['FeatureVersion']['VersionDetail']['#text'])            \n",
    "                            #    break\n",
    "            \n",
    "        with open('results/sdn.json', 'w') as fp:\n",
    "            json.dump(sdn, fp)\n",
    "        fp.close()\n",
    "\n",
    "\n",
    "    def check_ofac(self, currency, address, path):\n",
    "        \n",
    "        file_ext = os.path.splitext(path)[1].lower()\n",
    "        with open(path, \"r\") as file:\n",
    "            if file_ext in [\".json\"]:\n",
    "                data = json.load(file)\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported file format\")\n",
    "\n",
    "        currency_set = set(data[currency])\n",
    "        \n",
    "        return address in currency_set\n",
    "    \n",
    "\n",
    "    def check_dark_web(self, address, parent_directory):\n",
    "\n",
    "        #pd.set_option('display.max_colwidth', None)\n",
    "    \n",
    "        def scan_directory(directory):\n",
    "\n",
    "            #Recursively scans a directory for Parquet files and checks them\n",
    "\n",
    "            for item in os.listdir(directory):\n",
    "\n",
    "                item_path = os.path.join(directory, item)\n",
    "                \n",
    "                # If item is a directory, recursively scan it\n",
    "                if os.path.isdir(item_path):\n",
    "                    if scan_directory(item_path):\n",
    "                        return True\n",
    "\n",
    "                # If item is a parquet file, read and check it\n",
    "                elif item.endswith(\".parquet\"):\n",
    "                    ddf = dd.read_parquet(item_path, blocksize=\"400mb\")\n",
    "                    print(ddf.head())\n",
    "\n",
    "                    check = ddf['address'].isin([address]).compute()\n",
    "                    if check.any():\n",
    "                        return True\n",
    "                    \n",
    "            return False\n",
    "\n",
    "        return scan_directory(parent_directory)\n",
    "    \n",
    "    \n",
    "    def check_phishing_hack(self, address, path):\n",
    "\n",
    "        file_ext = os.path.splitext(path)[1].lower()\n",
    "        with open(path, \"r\") as file:\n",
    "            if file_ext in [\".json\"]:\n",
    "                data = json.load(file)\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported file format\")\n",
    "        \n",
    "        phishing_hack_addresses = [entry['address'] for entry in data]\n",
    "\n",
    "        return address in phishing_hack_addresses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exchanges Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exchange():\n",
    "    \n",
    "\n",
    "    def __init__(self, currency, depth):\n",
    "        self.currency = currency\n",
    "        self.depth = depth\n",
    "\n",
    "\n",
    "    def get_ex_tags(self, address, type):\n",
    "\n",
    "        # Enter a context with an instance of the API client\n",
    "        with graphsense.ApiClient(configuration) as api_client:\n",
    "            # Create an instance of the API class\n",
    "            api_instance = addresses_api.AddressesApi(api_client)\n",
    "\n",
    "            #currency = CURRENCY # str | The cryptocurrency code (e.g., btc)\n",
    "            #address = ADDRESS # str | The cryptocurrency address\n",
    "            #page = \"page_example\" # str | Resumption token for retrieving the next page (optional)\n",
    "            #pagesize = 10 # int | Number of items returned in a single page (optional)\n",
    "            #include_tags = True\n",
    "\n",
    "            try:\n",
    "                # Get attribution tags for a given address\n",
    "                api_response = api_instance.list_tags_by_address(self.currency, address.lower())\n",
    "                exchange_data = api_response\n",
    "                \n",
    "                exchange_tags = []\n",
    "\n",
    "                for entry in exchange_data['address_tags']:\n",
    "                    actor = entry.get('actor', '')\n",
    "                    category = entry.get('category', '')\n",
    "                    label = entry.get('label', '')\n",
    "                    if ((actor or label) and (type == 'cex' and (category == 'exchange' or category == 'market'))) or ((actor or label) and type == 'dex' and category == 'defi_dex'):\n",
    "                        exchange_tags.append({\n",
    "                            'actor': actor,\n",
    "                            'category': category,\n",
    "                            'currency': entry.get('currency', ''),\n",
    "                            'label': label,\n",
    "                            'address': entry.get('address', '')\n",
    "                        })\n",
    "\n",
    "                return exchange_tags\n",
    "                \n",
    "            except graphsense.ApiException as e:\n",
    "               print(\"Exception when calling AddressesApi->list_tags_by_address: %s\\n\" % e)\n",
    "    \n",
    "    \n",
    "    def get_ex_used(self, address, type, direction, max_degree=7, verbose=True):\n",
    "        \n",
    "        ass_wallets = AssociatedWallets()\n",
    "        neighbors = ass_wallets.bfs_neighbors(address, self.depth, max_degree, verbose, direction)\n",
    "\n",
    "        exchanges_used = []\n",
    "\n",
    "        for arr_level in neighbors:\n",
    "            for address in arr_level:\n",
    "                temp_exchange_tags = self.get_ex_tags(address, type)\n",
    "                if temp_exchange_tags:\n",
    "                    exchanges_used.append(temp_exchange_tags)\n",
    "\n",
    "        return exchanges_used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proof of Funds Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom authentication for Coinbase API\n",
    "class CoinbaseWalletAuth(AuthBase):\n",
    "    def __init__(self, api_key, secret_key):\n",
    "        self.api_key = api_key\n",
    "        self.secret_key = secret_key\n",
    "\n",
    "    def __call__(self, request):\n",
    "        timestamp = str(int(time.time()))\n",
    "        message = timestamp + request.method + request.path_url + (request.body or '')\n",
    "        signature = hmac.new(self.secret_key, message, hashlib.sha256).hexdigest()\n",
    "\n",
    "        request.headers.update({\n",
    "            'CB-ACCESS-SIGN': signature,\n",
    "            'CB-ACCESS-TIMESTAMP': timestamp,\n",
    "            'CB-ACCESS-KEY': self.api_key,\n",
    "        })\n",
    "        return request\n",
    "\n",
    "\n",
    "class PoF():\n",
    "    \n",
    "\n",
    "    def __init__(self, currency):\n",
    "        self.currency = currency\n",
    "\n",
    "    #Candles data Coinbase\n",
    "\n",
    "    \"\"\"Each bucket is an array of the following information:\n",
    "\n",
    "    time: bucket start time\n",
    "    low: lowest price during the bucket interval\n",
    "    high: highest price during the bucket interval\n",
    "    open: opening price (first trade) in the bucket interval\n",
    "    close: closing price (last trade) in the bucket interval\n",
    "    volume: volume of trading activity during the bucket interval\"\"\"\n",
    "    def coinbase_data(self, type, symbol='ETH-USD', start_date=datetime.today().strftime('%Y-%m-%d'), end_date=datetime.today().strftime('%Y-%m-%d')):\n",
    "\n",
    "        # Before implementation, set environmental variables with the names API_KEY and API_SECRET\n",
    "        #API_KEY = config['coinbase']['api_key']\n",
    "        #API_SECRET = config['coinbase']['api_secret']\n",
    "        #auth = CoinbaseWalletAuth(API_KEY, API_SECRET)\n",
    "\n",
    "        # Convert the start date string to a datetime object\n",
    "        #start_date_datetime = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "\n",
    "        # Calculate the end date by adding one day to the start date\n",
    "        #end_date_datetime = start_date_datetime + datetime.timedelta(days=1)\n",
    "\n",
    "        # Convert the end date to a string in the same format\n",
    "        #end_date = end_date_datetime.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        # Parameters for the API request Exchange\n",
    "        params_exchange = {\n",
    "            \"currency\": symbol\n",
    "        }\n",
    "\n",
    "        # Parameters for the API request Spot\n",
    "        params_spot = {\n",
    "            \"date\": start_date\n",
    "        }\n",
    "\n",
    "        # Parameters for the API request Candles\n",
    "        params_candles = {\n",
    "            \"granularity\": 86400,  # Daily interval\n",
    "            \"start\": start_date,\n",
    "            \"end\": start_date\n",
    "        }\n",
    "\n",
    "        if type == 'buy':\n",
    "            base_url = config['coinbase']['buyprice_endpoint']\n",
    "            api_url = base_url.format(symbol)\n",
    "            response = requests.get(api_url)\n",
    "\n",
    "        elif type == 'sell':\n",
    "            base_url = config['coinbase']['sellprice_endpoint']\n",
    "            api_url = base_url.format(symbol)\n",
    "            response = requests.get(api_url)\n",
    "\n",
    "        elif type == 'exchange':\n",
    "            api_url = config['coinbase']['exchangeprice_endpoint']\n",
    "            response = requests.get(api_url, params=params_exchange)\n",
    "\n",
    "        elif type == 'spot':\n",
    "            base_url = config['coinbase']['spotprice_endpoint']\n",
    "            api_url = base_url.format(symbol)\n",
    "            response = requests.get(api_url, params=params_spot)\n",
    "\n",
    "        elif type == 'candles':\n",
    "            base_url = config['coinbase']['candles_endpoint']\n",
    "            api_url = base_url.format(symbol)\n",
    "            response = requests.get(api_url, params=params_candles)\n",
    "        else:\n",
    "            print(f\"Unsupported type: {type}\")\n",
    "            return False\n",
    "\n",
    "        # Process the response data\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(\"Request failed:\", response.status_code)\n",
    "\n",
    "    \n",
    "    #Klines data Binance\n",
    "    \"\"\"[\n",
    "        [\n",
    "            1499040000000,      // Kline open time\n",
    "            \"0.01634790\",       // Open price\n",
    "            \"0.80000000\",       // High price\n",
    "            \"0.01575800\",       // Low price\n",
    "            \"0.01577100\",       // Close price\n",
    "            \"148976.11427815\",  // Volume\n",
    "            1499644799999,      // Kline Close time\n",
    "            \"2434.19055334\",    // Quote asset volume\n",
    "            308,                // Number of trades\n",
    "            \"1756.87402397\",    // Taker buy base asset volume\n",
    "            \"28.46694368\",      // Taker buy quote asset volume\n",
    "            \"0\"                 // Unused field, ignore.\n",
    "        ]\n",
    "        ]\"\"\"\n",
    "    def binance_data(self, type, symbol='', start_date=datetime.today().strftime('%Y-%m-%d'), end_date=datetime.today().strftime('%Y-%m-%d')):\n",
    "\n",
    "        # Convert start and end dates to Unix timestamps (in milliseconds)\n",
    "        start_timestamp = int(datetime.strptime(start_date, \"%Y-%m-%d\").timestamp()) * 1000\n",
    "        #end_timestamp = int(datetime.strptime(end_date, \"%Y-%m-%d\").timestamp()) * 1000\n",
    "\n",
    "        # Parameters for the API request Klines\n",
    "        params_klines = {\n",
    "            \"symbol\": symbol,\n",
    "            \"interval\": \"1d\",  # Daily interval\n",
    "            \"startTime\": start_timestamp\n",
    "            #\"endTime\": end_timestamp\n",
    "        }\n",
    "\n",
    "        # Parameters for the API request\n",
    "        params_general = {\n",
    "            \"symbol\": symbol,\n",
    "            #\"interval\": \"1d\",  # Daily interval\n",
    "            #\"startTime\": start_timestamp\n",
    "            #\"endTime\": end_timestamp\n",
    "        }\n",
    "\n",
    "        if type == 'avgprice':\n",
    "            api_url = config['binance']['avgprice_endpoint']\n",
    "            response = requests.get(api_url, params=params_general)\n",
    "        elif type == 'price':\n",
    "            api_url = config['binance']['price_endpoint']\n",
    "            response = requests.get(api_url, params=params_general)\n",
    "        elif type == 'exchange':\n",
    "            api_url = config['binance']['exchangeprice_endpoint']\n",
    "            if symbol == '':\n",
    "                response = requests.get(api_url)\n",
    "            else:\n",
    "                response = requests.get(api_url, params=params_general)\n",
    "        elif type == 'klines':\n",
    "            api_url = config['binance']['klines_endpoint']\n",
    "            response = requests.get(api_url, params=params_klines)\n",
    "        elif type == '24hrstats':\n",
    "            api_url = config['binance']['24hrstats_endpoint']\n",
    "            response = requests.get(api_url, params=params_general)\n",
    "        else:\n",
    "            print(f\"Unsupported type: {type}\")\n",
    "            return False\n",
    "        \n",
    "        # Process the response data\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(\"Request failed:\", response.status_code)\n",
    "        \n",
    "        \n",
    "    def binance_table(self, symbol, interval='4h', limit=500, start='01-01-2023'):\n",
    "\n",
    "        \"\"\"\n",
    "        interval: str tick interval - 4h/1h/1d ...\n",
    "        \"\"\"\n",
    "\n",
    "        columns = ['open_time','open', 'high', 'low', 'close', 'volume','close_time', 'qav','num_trades','taker_base_vol','taker_quote_vol', 'ignore']\n",
    "        start = int(datetime.timestamp(pd.to_datetime(start))*1000)\n",
    "        api_url = f'https://www.binance.com/api/v3/klines?symbol={symbol}&interval={interval}&limit={limit}&startTime={start}'\n",
    "\n",
    "        data = pd.DataFrame(requests.get(api_url).json(), columns=columns, dtype=float)\n",
    "        data.index = [pd.to_datetime(x, unit='ms').strftime('%Y-%m-%d %H:%M:%S') for x in data.open_time]\n",
    "        usecols=['open', 'high', 'low', 'close', 'volume', 'qav','num_trades','taker_base_vol','taker_quote_vol']\n",
    "        data = data[usecols]\n",
    "\n",
    "        return data\n",
    "    \n",
    "    \n",
    "    def check_profitloss(self, exchange, symbol, buy_date, sell_date, buy_amount, sell_amount, profit_or_loss):\n",
    "        \n",
    "        if exchange == 'coinbase':\n",
    "            \n",
    "            buy_price_data = self.coinbase_data('candles', buy_date)\n",
    "            sell_price_data = self.coinbase_data('candles', sell_date)\n",
    "\n",
    "            buy_price = float(buy_price_data[0][3])\n",
    "            sell_price = float(sell_price_data[0][3])\n",
    "\n",
    "            buy_total = buy_price * buy_amount\n",
    "            sell_total = sell_price * sell_amount\n",
    "            \n",
    "        elif exchange == 'binance':\n",
    "            \n",
    "            buy_price_data = self.binance_data('klines', buy_date, symbol)\n",
    "            sell_price_data = self.binance_data('klines', sell_date, symbol)\n",
    "\n",
    "            buy_price = float(buy_price_data[0][1])\n",
    "            sell_price = float(sell_price_data[0][1])\n",
    "\n",
    "            buy_total = buy_price * buy_amount\n",
    "            sell_total = sell_price * sell_amount\n",
    "\n",
    "        else:\n",
    "            print(f\"Unsupported exchange: {exchange}\")\n",
    "            return False\n",
    "\n",
    "        difference = abs((buy_total - sell_total) - abs(profit_or_loss))\n",
    "        actual_profit_or_loss = sell_total - buy_total\n",
    "        \n",
    "        if difference < 1e-6: #To account for floating point inaccuracies\n",
    "            print(\"Actual profit/loss: \" + str(actual_profit_or_loss))\n",
    "            print(\"Difference between reported profit/loss and actual profit/loss value: \" + str(difference))\n",
    "            return True\n",
    "        else:\n",
    "            print(\"Actual profit/loss: \" + str(actual_profit_or_loss))\n",
    "            print(\"Difference between reported profit/loss and actual profit/loss value: \" + str(difference))            \n",
    "            return False\n",
    "        \n",
    "\n",
    "    def get_address_txs(self, address, direction, pages=5):\n",
    "\n",
    "        # Enter a context with an instance of the API client\n",
    "        with graphsense.ApiClient(configuration) as api_client:\n",
    "            # Create an instance of the API class\n",
    "            api_instance = addresses_api.AddressesApi(api_client)\n",
    "            #direction = \"out\" # str | Incoming or outgoing transactions (optional)\n",
    "            #min_height = Height(1) # Height | Return transactions starting from given height (optional)\n",
    "            #max_height = Height(2) # Height | Return transactions up to (including) given height (optional)\n",
    "            #token_currency = \"WETH\" # str | Return transactions of given token currency (optional)\n",
    "            #page = \"page_example\" # str | Resumption token for retrieving the next page (optional)\n",
    "            #pagesize = 10 # int | Number of items returned in a single page (optional)\n",
    "\n",
    "            all_txs = []\n",
    "            next_page_token = ''\n",
    "\n",
    "            for i in range(0, pages):\n",
    "\n",
    "                try:\n",
    "                    \n",
    "                    if next_page_token == '':\n",
    "                        # Get all transactions an address has been involved in without a next page token\n",
    "                        api_response = api_instance.list_address_txs(self.currency, address, direction=direction)\n",
    "                        all_txs.extend(api_response['address_txs'])\n",
    "\n",
    "                    else:\n",
    "                        # Get all transactions an address has been involved in\n",
    "                        api_response = api_instance.list_address_txs(self.currency, address, direction=direction, page=next_page_token)\n",
    "                        all_txs.extend(api_response['address_txs'])\n",
    "\n",
    "                    if 'next_page' in api_response:\n",
    "                        next_page_token = api_response['next_page']\n",
    "\n",
    "                    else:\n",
    "                        print(f\"{i+1} pages found for transactions in direction: {direction}. Exiting after fetching all available pages.\")\n",
    "                        break\n",
    "\n",
    "                except graphsense.ApiException as e:\n",
    "                    print(\"Exception when calling AddressesApi->list_address_txs: %s\\n\" % e)\n",
    "            \n",
    "        return all_txs\n",
    "\n",
    "\n",
    "    def check_pass_through_wallet(self, address, pages=5):\n",
    "          \n",
    "        out_txs = self.get_address_txs(address, 'out', pages)\n",
    "        in_txs = self.get_address_txs(address, 'in', pages)\n",
    "\n",
    "        params = {\n",
    "            \"module\": \"account\",\n",
    "            \"action\": \"balance\",\n",
    "            \"address\": address,\n",
    "            \"tag\": \"latest\",\n",
    "            \"apikey\": config['etherscan']['api_key']\n",
    "        }\n",
    "        \n",
    "        response = requests.get(config['etherscan']['host'], params=params)\n",
    "        data = response.json()\n",
    "\n",
    "        if data['status'] != \"1\" or 'result' not in data:\n",
    "            print(f\"Error fetching transactions for address {address}: {data['message']}\")\n",
    "            return []\n",
    "        \n",
    "        balance_eth = float(data['result']) / (10 ** 18)  # Convert wei to ether\n",
    "\n",
    "        print(\"Number of incoming txs: \" + str(len(in_txs['address_txs'])))\n",
    "        print(\"Number of outgoing txs: \" + str(len(out_txs['address_txs'])))\n",
    "        print(balance_eth)\n",
    "\n",
    "\n",
    "    def activity_analysis(self, address, pages=5):\n",
    "\n",
    "        out_txs = self.get_address_txs(address, 'out', pages)\n",
    "        in_txs = self.get_address_txs(address, 'in', pages)\n",
    "        date_txcount = {}\n",
    "\n",
    "        for tx in out_txs:\n",
    "            tx_date = datetime.utcfromtimestamp(tx['timestamp']).strftime('%Y-%m-%d')\n",
    "            date_txcount[tx_date] = date_txcount.get(tx_date, 0) + 1\n",
    "\n",
    "        for tx in in_txs:\n",
    "            tx_date = datetime.utcfromtimestamp(tx['timestamp']).strftime('%Y-%m-%d')\n",
    "            date_txcount[tx_date] = date_txcount.get(tx_date, 0) + 1\n",
    "\n",
    "        dates = [datetime.strptime(date, '%Y-%m-%d') for date in date_txcount.keys()]\n",
    "        start_date = min(dates)\n",
    "        end_date = max(dates)\n",
    "\n",
    "        current_date = start_date\n",
    "        while current_date <= end_date:\n",
    "            str_date = current_date.strftime('%Y-%m-%d')\n",
    "            if str_date not in date_txcount:\n",
    "                date_txcount[str_date] = 0\n",
    "            current_date += timedelta(days=1)\n",
    "\n",
    "        df = pd.DataFrame(list(date_txcount.items()), columns=['Date', 'TxCount'])\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        df = df.sort_values('Date')\n",
    "        df['YearMonth'] = df['Date'].dt.to_period('M')\n",
    "        df['Day'] = df['Date'].dt.day\n",
    "        new_df = df.pivot(index=\"Day\", columns=\"YearMonth\", values=\"TxCount\")\n",
    "        new_df = new_df.iloc[::-1]\n",
    "\n",
    "        # Plot:\n",
    "        #width_per_tx = 0.25\n",
    "        #fig_width = len(date_txcount) * width_per_tx\n",
    "        fig_width = 30\n",
    "        plt.figure(figsize=(fig_width, 20))\n",
    "        sns.heatmap(new_df, cmap='Purples', linewidths=2, cbar_kws={'label': 'Transaction Count'}, annot=True)\n",
    "        plt.title('Transactions Heatmap')\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NFTs Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NFT():\n",
    "\n",
    "\n",
    "    def get_nft_transfers(self, address, page=1, offset=100):\n",
    "\n",
    "        params = {\n",
    "            \"module\": \"account\",\n",
    "            \"action\": \"tokennfttx\",\n",
    "            #\"contractaddress\": \"\",\n",
    "            \"address\": address,\n",
    "            \"page\": page,\n",
    "            \"offset\": offset,\n",
    "            #\"startblock\": \"\",\n",
    "            #\"endblock\": \"\",\n",
    "            \"sort\": \"asc\",\n",
    "            \"apikey\": config['etherscan']['api_key']\n",
    "         }\n",
    "        \n",
    "        response = requests.get(config['etherscan']['host'], params=params)\n",
    "        data = response.json()\n",
    "\n",
    "        if data['status'] != \"1\" or 'result' not in data:\n",
    "            print(f\"Error fetching transactions for address {address}: {data['message']}\")\n",
    "            return []\n",
    "\n",
    "        return data['result']\n",
    "    \n",
    "    \n",
    "    def get_held_nfts(self, address):\n",
    "        \n",
    "        transfers = self.get_nft_transfers(address)\n",
    "\n",
    "        incoming_nfts = {tx['tokenID']: tx for tx in transfers if tx['to'] == address.lower()}\n",
    "        outgoing_nfts = {tx['tokenID']: tx for tx in transfers if tx['from'] == address.lower()}\n",
    "\n",
    "        held_nfts = {tid: tx for tid, tx in incoming_nfts.items() if tid not in outgoing_nfts}\n",
    "\n",
    "        return list(held_nfts.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERC20 Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ERC20():\n",
    "\n",
    "\n",
    "    def get_erc20_transfers(self, address, page=3, offset=100):\n",
    "\n",
    "        params = {\n",
    "            \"module\": \"account\",\n",
    "            \"action\": \"tokentx\",\n",
    "            #\"contractaddress\": \"\",\n",
    "            \"address\": address,\n",
    "            \"page\": page,\n",
    "            \"offset\": offset,\n",
    "            #\"startblock\": \"\",\n",
    "            #\"endblock\": \"\",\n",
    "            \"sort\": \"asc\",\n",
    "            \"apikey\": config['etherscan']['api_key']\n",
    "         }\n",
    "        \n",
    "        response = requests.get(config['etherscan']['host'], params=params)\n",
    "        data = response.json()\n",
    "\n",
    "        if data['status'] != \"1\" or 'result' not in data:\n",
    "            print(f\"Error fetching transactions for address {address}: {data['message']}\")\n",
    "            return []\n",
    "\n",
    "        return data['result']\n",
    "    \n",
    "    \n",
    "    def get_erc20(self, address):\n",
    "        \n",
    "        transfers = self.get_erc20_transfers(address)\n",
    "\n",
    "        erc20_balances = {}\n",
    "        \n",
    "        # Sum up all the incoming and outgoing transfers for each token\n",
    "        for tx in transfers:\n",
    "\n",
    "            token_key = (tx['tokenSymbol'], tx['tokenName'])\n",
    "            value = float(tx['value']) / (10.0 ** float(tx['tokenDecimal']))\n",
    "            \n",
    "            if tx['to'] == address.lower():\n",
    "                erc20_balances[token_key] = erc20_balances.get(token_key, 0) + value\n",
    "            if tx['from'] == address.lower():\n",
    "                erc20_balances[token_key] = erc20_balances.get(token_key, 0) - value\n",
    "\n",
    "        # Filter out tokens with zero or negative balances\n",
    "        held_erc20 = {k: v for k, v in erc20_balances.items() if v > 0}\n",
    "\n",
    "        return dict(sorted(held_erc20.items()))\n",
    "\n",
    "    \n",
    "    def visualize(self, address):\n",
    "        \n",
    "        #create a chart of held erc20 tokens\n",
    "\n",
    "        held_erc20 = self.get_erc20(address)\n",
    "        pof = PoF()\n",
    "        pie_data = []\n",
    "        pie_labels = []\n",
    "        failed_erc20 = {}\n",
    "\n",
    "        if held_erc20:\n",
    "\n",
    "            for token, value in held_erc20.items():\n",
    "\n",
    "                symbol = token[0]\n",
    "\n",
    "                if symbol != 'USDT':\n",
    "                    trading_pair = symbol + 'USDT'\n",
    "                    binance_call = pof.binance_data('price', trading_pair)\n",
    "                    if binance_call:\n",
    "                        symbol_price = float(binance_call['price'])\n",
    "                        pie_data.append(symbol_price * value)\n",
    "                        pie_labels.append(symbol)\n",
    "                    else:\n",
    "                        failed_erc20[token] = value\n",
    "                elif symbol == 'USDT': \n",
    "                    symbol_price = 1.0\n",
    "                    pie_data.append(symbol_price * value)\n",
    "                    pie_labels.append(symbol)\n",
    "    \n",
    "        else:\n",
    "            print(f\"Error fetching transactions for address {address}\")\n",
    "\n",
    "        # Plot\n",
    "\n",
    "        colors = [\n",
    "            \"#1f77b4\",  # muted blue\n",
    "            \"#ff7f0e\",  # safety orange\n",
    "            \"#2ca02c\",  # cooked asparagus green\n",
    "            \"#d62728\",  # brick red\n",
    "            \"#9467bd\",  # muted purple\n",
    "            \"#8c564b\",  # chestnut brown\n",
    "            \"#e377c2\",  # raspberry yogurt pink\n",
    "            \"#7f7f7f\",  # middle gray\n",
    "            \"#bcbd22\",  # curry yellow-green\n",
    "            \"#17becf\",  # blue-teal\n",
    "            \"#1a55FF\",  # bright blue\n",
    "            \"#FF55A3\",  # bright pink\n",
    "            \"#669900\",  # olive green\n",
    "            \"#FFC400\",  # bright yellow\n",
    "            \"#004DFF\",  # royal blue\n",
    "            \"#FF5000\",  # bright red-orange\n",
    "            \"#009966\",  # teal green\n",
    "            \"#FF6600\",  # orange\n",
    "            \"#8000FF\",  # violet\n",
    "            \"#00FF80\"   # mint green\n",
    "        ]\n",
    "\n",
    "        if pie_data and len(pie_data) < 6:\n",
    "            plt.figure(figsize=(10, 8)) # 10 width, 8 height\n",
    "            plt.legend(pie_labels, title=\"Tokens\", loc=\"best\")\n",
    "            plt.title('ERC20 Tokens in USDT')\n",
    "            plt.pie(pie_data, colors=colors)\n",
    "            plt.show()\n",
    "        elif pie_data and len(pie_data) >= 6:\n",
    "            bar_positions = np.arange(len(pie_labels))\n",
    "            plt.figure(figsize=(30, 24)) # 10 width, 8 height\n",
    "            plt.xticks(bar_positions, pie_labels, rotation=45)\n",
    "            plt.yscale('log')  # Set y-axis to logarithmic scale\n",
    "            plt.ylabel('Value in USDT')\n",
    "            plt.title('ERC20 Tokens in USDT')\n",
    "            plt.bar(bar_positions, pie_data, align='center', alpha=0.7)\n",
    "            plt.show()\n",
    "            \n",
    "        print(f\"The following ERC20 Tokens are being held by the client: {held_erc20}\")\n",
    "        print(f\"For following ERC20 Tokens there was no price data: {failed_erc20}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smart Contract Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SC():\n",
    "\n",
    "\n",
    "    def get_sc_data(self, contract_address, type):\n",
    "\n",
    "        params_sc = {\n",
    "            \"module\": \"contract\",\n",
    "            \"action\": \"getsourcecode\",\n",
    "            \"address\": contract_address,\n",
    "            \"apikey\": config['etherscan']['api_key']\n",
    "        }\n",
    "        response_sc = requests.get(config['etherscan']['host'], params=params_sc)\n",
    "        data_sc = response_sc.json()\n",
    "\n",
    "        params_creator = {\n",
    "            \"module\": \"contract\",\n",
    "            \"action\": \"getcontractcreation\",\n",
    "            \"address\": contract_address,\n",
    "            \"apikey\": config['etherscan']['api_key']\n",
    "        }\n",
    "        response_creator = requests.get(config['etherscan']['host'], params=params_creator)\n",
    "        data_creator = response_creator.json()\n",
    "\n",
    "        if data_sc[\"status\"] == \"1\":\n",
    "            source_code = data_sc[\"result\"][0][\"SourceCode\"]\n",
    "            with open(\"results/sc_\" + str(type) + \"_\" + data_sc[\"result\"][0][\"ContractName\"] + \".txt\", \"w\") as outfile:\n",
    "                outfile.write(str(source_code))\n",
    "        else:\n",
    "            print(f\"Error Smart Contract: {data_sc['message']}\")\n",
    "\n",
    "        if data_creator[\"status\"] == \"1\":\n",
    "            creator_data = data_creator[\"result\"]\n",
    "            with open(\"results/creator_\" + str(type) + \".txt\", \"w\") as outfile:\n",
    "                outfile.write(str(creator_data))\n",
    "        else:\n",
    "            print(f\"Error Creator: {data_creator['message']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixer and Bridges Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixBridge():\n",
    "\n",
    "\n",
    "    def process(self, mix_bridge, address, pages, pof):\n",
    "\n",
    "        print(f\"Processing mixer/bridge: {mix_bridge['address']}\")\n",
    "\n",
    "        Tx = namedtuple('Transaction', ['from_address', 'to_address', 'name_tag'])\n",
    "\n",
    "        out_txs = pof.get_address_txs(mix_bridge['address'], 'out', pages)\n",
    "        in_txs = pof.get_address_txs(mix_bridge['address'], 'in', pages)\n",
    "        #print(in_txs)\n",
    "\n",
    "        name_tag = mix_bridge['nameTag'] if mix_bridge['nameTag'] else 'Unknown Mixer/Bridge'\n",
    "\n",
    "        tx_from_mix_bridge = [Tx(tx['from_address'], tx['to_address'], name_tag) for tx in out_txs if tx['to_address'] == address]\n",
    "        tx_to_mix_bridge = [Tx(tx['from_address'], tx['to_address'], name_tag) for tx in in_txs if tx['from_address'] == address]\n",
    "        print(tx_to_mix_bridge)\n",
    "\n",
    "        return tx_from_mix_bridge, tx_to_mix_bridge\n",
    "\n",
    "\n",
    "    def check(self, address, path, pages=3):\n",
    "\n",
    "        pof = PoF('eth')\n",
    "        file_ext = os.path.splitext(path)[1].lower()\n",
    "        with open(path, \"r\") as file:\n",
    "            if file_ext in [\".json\"]:\n",
    "                mix_bridge_data = json.load(file)\n",
    "            elif file_ext in [\".yaml\", \".yml\"]:\n",
    "                mix_bridge_data = yaml.safe_load(file)\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported file format\")\n",
    "\n",
    "        print(mix_bridge_data)\n",
    "\n",
    "        tx_from_mix_bridge = []\n",
    "        tx_to_mix_bridge = []\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "\n",
    "            futures = [executor.submit(self.process, mix_bridge, address, pages, pof) for mix_bridge in mix_bridge_data]\n",
    "\n",
    "            for future in as_completed(futures):\n",
    "                out, inn = future.result()\n",
    "                print(\"From:\", out)  # Debugging print\n",
    "                print(\"To:\", inn)    # Debugging print\n",
    "                tx_from_mix_bridge.extend(out)\n",
    "                tx_to_mix_bridge.extend(inn)\n",
    "\n",
    "        return tx_from_mix_bridge, tx_to_mix_bridge"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'address': '0x94A1B5CdB22c43faab4AbEb5c74999895464Ddaf', 'nameTag': 'Tornado Cash'}, {'address': '0x8589427373D6D84E98730D7795D8f6f8731FDA16', 'nameTag': 'Tornado Cash: Donate'}]\n",
      "Processing mixer/bridge: 0x94A1B5CdB22c43faab4AbEb5c74999895464Ddaf\n",
      "Processing mixer/bridge: 0x8589427373D6D84E98730D7795D8f6f8731FDA16\n",
      "1 pages found for transactions in direction: out. Exiting after fetching all available pages.\n",
      "1 pages found for transactions in direction: in. Exiting after fetching all available pages.\n",
      "[]\n",
      "From: []\n",
      "To: []\n",
      "4 pages found for transactions in direction: out. Exiting after fetching all available pages.\n",
      "1 pages found for transactions in direction: in. Exiting after fetching all available pages.\n",
      "[]\n",
      "From: []\n",
      "To: []\n",
      "([], [])\n"
     ]
    }
   ],
   "source": [
    "# Function calls\n",
    "\n",
    "#ass_wallets = AssociatedWallets(CURRENCY)\n",
    "\n",
    "#direction = 'out'\n",
    "\n",
    "#addr_neigh = ass_wallets.bfs_neighbors(ADDRESS, 4, 10, True, direction)\n",
    "#addr_simple_neigh = ass_wallets.simple_neighbors(ADDRESS, direction)\n",
    "\n",
    "#with open(\"results/addresses_\" + direction + \".txt\", \"w\") as outfile:\n",
    "    #outfile.write(str(addr_neigh))\n",
    "\n",
    "#blacklist = Blacklist()\n",
    "#blacklist.ofac()\n",
    "#print(blacklist.check_membership('ETH', ADDRESS, json_data))\n",
    "#blacklist.check_dark_web('1DcU28QbeUiJVcSS8sZCf4ixeYXG26zEWN', 'blacklist_data/plain_cluster_outgoing_rel.parquet')\n",
    "#blacklist.check_etherscan('0x690B9A9E9aa1C9dB991C7721a92d351Db4FaC990', 'blacklist_data/hack_addresses_etherscan.json')\n",
    "\n",
    "\n",
    "#ex = Exchange(ADDRESS, 'eth', 3, 'in')\n",
    "#exchanges_used = ex.get_ex_used('dex')\n",
    "#exchanges_used = ex.get_ex_tags('0x1d42064Fc4Beb5F8aAF85F4617AE8b3b5B8Bd801', 'dex')\n",
    "#pprint(exchanges_used)\n",
    "\n",
    "#pof = PoF(ADDRESS, 'eth')\n",
    "#print(pof.coinbase_data('candles', '2018-01-01'))\n",
    "#print(pof.binance_data('price', 'AUTOUSDT'))\n",
    "#print(pof.coinbase_data('buy', 'AUTO-USD'))\n",
    "\n",
    "#pprint(pof.binance_table('ETHUSDT', '1h'))\n",
    "#pof.check_profitloss('coinbase', 'ETHUSDT', '2018-08-09', '2023-09-10', 1, 1, -300)\n",
    "#print(pof.get_address_txs(ADDRESS, 'in', 1))\n",
    "#pof.check_pass_through_wallet(ADDRESS, CURRENCY)\n",
    "#pof.activity_analysis()\n",
    "\n",
    "#nft = NFT()\n",
    "#nfts_dict = nft.get_held_nfts(ADDRESS)\n",
    "#print(nfts_dict)\n",
    "#for nft in nfts_dict:\n",
    "    #print(nft)\n",
    "\n",
    "#nft_sc = nft.get_nft_sc('0x25ed58c027921e14d86380ea2646e3a1b5c55a8b')\n",
    "#with open(\"results/nft_sc\" + \".txt\", \"w\") as outfile:\n",
    "    #outfile.write(str(nft_sc))\n",
    "\n",
    "#erc20 = ERC20(ADDRESS)\n",
    "#erc20_dict = erc20.get_erc20_transfers()\n",
    "#print(erc20_dict)\n",
    "#print(erc20.get_erc20())\n",
    "#erc20.visualize()\n",
    "\n",
    "#sc = SC()\n",
    "#sc.get_sc_data(exchanges_used[0]['address'], 'dex')\n",
    "\n",
    "mix_bridge = MixBridge()\n",
    "print(mix_bridge.check('0xA43Ce8Cc89Eff3AA5593c742fC56A30Ef2427CB0', 'data/mixers.json', 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iknaio-api-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
