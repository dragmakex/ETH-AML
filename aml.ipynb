{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Settings and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pprint import pprint\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "#Associated Wallets imports\n",
    "from collections import deque\n",
    "\n",
    "#Ofac imports\n",
    "import csv\n",
    "import requests\n",
    "import xmltodict\n",
    "from collections import defaultdict\n",
    "\n",
    "#Dark Web imports\n",
    "import dask.dataframe as dd\n",
    "import yaml\n",
    "\n",
    "#Flipside imports\n",
    "#for flipside.xyz (SQL Databse)\n",
    "#from flipside import Flipside\n",
    "\n",
    "#Graphsense imports\n",
    "import graphsense\n",
    "from graphsense.api import addresses_api, bulk_api, entities_api, general_api, tags_api\n",
    "from graphsense.model.neighbor_addresses import NeighborAddresses\n",
    "\n",
    "#Coinbase imports\n",
    "import hmac, hashlib, time\n",
    "from requests.auth import AuthBase\n",
    "\n",
    "#Visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import calendar\n",
    "\n",
    "#Mixer/Bridges imports\n",
    "from collections import namedtuple\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('config.json')\n",
    "config = json.load(f)\n",
    "f.close()\n",
    "\n",
    "CURRENCY = 'eth'\n",
    "ADDRESS = ''\n",
    "\n",
    "configuration = graphsense.Configuration(\n",
    "    host = config['graphsense']['host'],\n",
    "    api_key = {'api_key': config['graphsense']['api_key']})\n",
    "\n",
    "#with graphsense.ApiClient(configuration) as api_client:\n",
    "    #api_instance = general_api.GeneralApi(api_client)\n",
    "    #api_response = api_instance.get_statistics()\n",
    "    #pprint(api_response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Associated Wallets Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssociatedWallets():\n",
    "\n",
    "\n",
    "    def __init__(self, currency):\n",
    "        self.currency = currency\n",
    "                \n",
    "\n",
    "    #Utility function to get neighbors of address        \n",
    "    def get_addr_neighbors(self, address, direction):\n",
    "\n",
    "        if (direction == 'out'):\n",
    "            degree = 'out_degree'\n",
    "            address_degree = 'address_out_degree'\n",
    "        else:\n",
    "            degree = 'in_degree'\n",
    "            address_degree = 'address_in_degree'\n",
    "\n",
    "        with graphsense.ApiClient(configuration) as api_client:\n",
    "            try:\n",
    "                api_instance = bulk_api.BulkApi(api_client)\n",
    "                print(f\"get_addr_neighbors of {address.lower()}\")\n",
    "                operation = \"list_address_neighbors\"\n",
    "                body = {'address': [address.lower()], 'direction': direction}\n",
    "\n",
    "                df_address_neighbors = pd.read_csv(api_instance.bulk_csv(self.currency, operation, body=body,\n",
    "                                                                    num_pages=1, _preload_content=False))\n",
    "                \n",
    "                df_address_neighbors = df_address_neighbors \\\n",
    "                    .loc[(df_address_neighbors['_error'] != 'not found') &\n",
    "                        (df_address_neighbors['_info'] != 'no data')].reset_index(drop=True)\n",
    "                \n",
    "                if df_address_neighbors.empty:\n",
    "                    df_address_neighbors.columns = ['address', 'entity', degree]\n",
    "                    return df_address_neighbors\n",
    "                \n",
    "                print(df_address_neighbors.columns)  # Print column names\n",
    "                \n",
    "                df_address_neighbors = df_address_neighbors \\\n",
    "                    .rename(columns={'address_address': 'address', \n",
    "                                    'address_entity': 'entity',\n",
    "                                    address_degree: degree})\n",
    "\n",
    "                return df_address_neighbors[['address', 'entity', degree]]\n",
    "                \n",
    "            except graphsense.ApiException as e:\n",
    "                print(\"Exception when calling Bulk Api: %s\\n\" % e)\n",
    "\n",
    "\n",
    "    # BFS neighbor algorithm\n",
    "    def bfs_neighbors(self, seed_address, max_depth, max_degree, verbose, direction):\n",
    "\n",
    "        if (direction == 'out'):\n",
    "            degree = 'out_degree'\n",
    "        else:\n",
    "            degree = 'in_degree'\n",
    "        \n",
    "        # collect neighbors\n",
    "        neighbors = []\n",
    "        for i in range (0, max_depth):\n",
    "            neighbors.insert(i, [])\n",
    "        neighbors[0].append(seed_address)\n",
    "\n",
    "        #keep track of depth\n",
    "        levels = {seed_address: 0}\n",
    "                \n",
    "        # record visited addresses and entities\n",
    "        visited_addresses = set([seed_address])\n",
    "        \n",
    "        # maintain a queue of addresses\n",
    "        queue = deque([(seed_address, 0)])\n",
    "\n",
    "        while(queue):\n",
    "\n",
    "            # get first address from the queue\n",
    "            address, level = queue.popleft()            \n",
    "\n",
    "            # retrieve address neighbors\n",
    "            df_neighbors = self.get_addr_neighbors(address.lower(), direction)\n",
    "\n",
    "            # continue with neighbors out_degree < max_outdegree\n",
    "            for index, neighbor in df_neighbors.iterrows():\n",
    "\n",
    "                 # stop if address has already been visited\n",
    "                if(neighbor['address'] in visited_addresses):\n",
    "                    if verbose:\n",
    "                        print(address.lower(), end=' ') \n",
    "                        print(\"STOP | same address\")\n",
    "                    continue\n",
    "                                \n",
    "                # stop if max depth is reached\n",
    "                if level + 1 == max_depth:\n",
    "                    print(level)\n",
    "                    if verbose:\n",
    "                        print(address.lower(), end=' ') \n",
    "                        print(\"STOP | max depth\")\n",
    "                    continue\n",
    "\n",
    "                neighbors[level+1].append(neighbor['address'])\n",
    "\n",
    "                # stop if address out_degree exceeds threshold\n",
    "                if(neighbor[degree] > max_degree):\n",
    "                    if verbose:\n",
    "                        print(address.lower(), end=' ') \n",
    "                        print(\"STOP | max degree\")\n",
    "                    continue\n",
    "                \n",
    "                queue.append((neighbor['address'], level + 1))\n",
    "                visited_addresses.add(neighbor['address'])\n",
    "                levels[neighbor['address']] = level + 1\n",
    "                    \n",
    "            if len(queue) == 0:\n",
    "                return neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blacklist Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Blacklist():\n",
    "\n",
    "    \n",
    "    def __init__(self, currency):\n",
    "        self.currency = currency\n",
    "\n",
    "\n",
    "    def scrape_ofac(self):\n",
    "        #Made by Raffaele Cristodaro\n",
    "        coins = []\n",
    "        myCoins = {}\n",
    "        sdn = defaultdict(list)\n",
    "        filename = 'sdn2.xml'\n",
    "        URL = \"https://www.treasury.gov/ofac/downloads/sanctions/1.0/sdn_advanced.xml\"\n",
    "\n",
    "        response = requests.get(URL)\n",
    "        with open(filename, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "\n",
    "        xml_data = open(filename, 'r').read()  # Read file\n",
    "        d = xmltodict.parse(xml_data)\n",
    "\n",
    "        for i in d['Sanctions']['ReferenceValueSets']['FeatureTypeValues']['FeatureType']:\n",
    "            if 'Digital Currency Address' in i['#text']:\n",
    "                coins.append(i['@ID'])\n",
    "                myCoins[i['@ID']] =  i['#text'].replace('Digital Currency Address - ','')\n",
    "            #   print(i['@ID'],'-',i['#text'])\n",
    "\n",
    "        for i in d['Sanctions']['DistinctParties']['DistinctParty']:\n",
    "            if 'Feature' in i['Profile'].keys():\n",
    "                for j in i['Profile']['Feature']:\n",
    "                    if '@FeatureTypeID' in j:\n",
    "                        if type(j) is not str:\n",
    "                            if str(j['@FeatureTypeID']) in coins:\n",
    "                            #   print(j)\n",
    "                            #   print(j['FeatureVersion']['VersionDetail']['#text'])\n",
    "                                sdn[myCoins[j['@FeatureTypeID']]].append(j['FeatureVersion']['VersionDetail']['#text'])            \n",
    "                            #    break\n",
    "            \n",
    "        with open('results/sdn.json', 'w') as fp:\n",
    "            json.dump(sdn, fp)\n",
    "        fp.close()\n",
    "\n",
    "\n",
    "    def check_ofac(self, address, path):\n",
    "        \n",
    "        file_ext = os.path.splitext(path)[1].lower()\n",
    "        with open(path, \"r\") as file:\n",
    "            if file_ext in [\".json\"]:\n",
    "                data = json.load(file)\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported file format\")\n",
    "\n",
    "        currency_set = set(data[self.currency])\n",
    "        \n",
    "        return address in currency_set\n",
    "\n",
    "\n",
    "    def check_dark_web(self, address, path):\n",
    "\n",
    "        #pd.set_option('display.max_colwidth', None)\n",
    "        \n",
    "        def scan_directory(directory):\n",
    "\n",
    "            for item in os.listdir(directory):\n",
    "                item_path = os.path.join(directory, item)\n",
    "                \n",
    "                # If item is a directory, recursively scan it\n",
    "                if os.path.isdir(item_path):\n",
    "                    if scan_directory(item_path):\n",
    "                        return True\n",
    "\n",
    "                # If item is a parquet file, read and check it\n",
    "                elif item.endswith(\".parquet\"):\n",
    "                    if check_parquet_file(item_path):\n",
    "                        return True\n",
    "            return False\n",
    "\n",
    "        def check_parquet_file(file_path):\n",
    "\n",
    "            ddf = dd.read_parquet(file_path, blocksize=\"400mb\")\n",
    "            print(ddf.head())\n",
    "\n",
    "            # Check if the target address is in any of the lists in the DataFrame\n",
    "            check = ddf.apply(lambda row: address.lower() in row[2], axis=1, meta=pd.Series(dtype=bool)).compute()\n",
    "\n",
    "            if check.any():\n",
    "                return True\n",
    "            return False\n",
    "\n",
    "        if path.endswith(\".parquet\"):\n",
    "            return check_parquet_file(path)\n",
    "        elif os.path.isdir(path):\n",
    "            return scan_directory(path)\n",
    "        else:\n",
    "            print(f\"'{path}' is neither a directory nor a parquet file.\")\n",
    "            return False\n",
    "\n",
    "\n",
    "    def check_phishing_hack(self, address, path):\n",
    "\n",
    "        file_ext = os.path.splitext(path)[1].lower()\n",
    "        with open(path, \"r\") as file:\n",
    "            if file_ext in [\".json\"]:\n",
    "                data = json.load(file)\n",
    "            elif file_ext in [\".yaml\", \".yml\"]:\n",
    "                data = yaml.safe_load(file)['tags']\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported file format\")\n",
    "        \n",
    "        phishing_hack_addresses = [entry['address'] for entry in data]\n",
    "\n",
    "        return address in phishing_hack_addresses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exchange Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exchange():\n",
    "    \n",
    "\n",
    "    def __init__(self, currency):\n",
    "        self.currency = currency\n",
    "\n",
    "\n",
    "    def get_ex_tags(self, address, type):\n",
    "\n",
    "        # Enter a context with an instance of the API client\n",
    "        with graphsense.ApiClient(configuration) as api_client:\n",
    "            # Create an instance of the API class\n",
    "            api_instance = addresses_api.AddressesApi(api_client)\n",
    "\n",
    "            #currency = CURRENCY # str | The cryptocurrency code (e.g., btc)\n",
    "            #address = ADDRESS # str | The cryptocurrency address\n",
    "            #page = \"page_example\" # str | Resumption token for retrieving the next page (optional)\n",
    "            #pagesize = 10 # int | Number of items returned in a single page (optional)\n",
    "            #include_tags = True\n",
    "\n",
    "            try:\n",
    "                # Get attribution tags for a given address\n",
    "                api_response = api_instance.list_tags_by_address(self.currency, address.lower())\n",
    "                exchange_data = api_response\n",
    "                \n",
    "                exchange_tags = []\n",
    "\n",
    "                for entry in exchange_data['address_tags']:\n",
    "                    actor = entry.get('actor', '')\n",
    "                    category = entry.get('category', '')\n",
    "                    label = entry.get('label', '')\n",
    "                    if ((actor or label) and (type == 'cex' and (category == 'exchange' or category == 'market'))) or ((actor or label) and type == 'dex' and category == 'defi_dex'):\n",
    "                        exchange_tags.append({\n",
    "                            'actor': actor,\n",
    "                            'category': category,\n",
    "                            'currency': entry.get('currency', ''),\n",
    "                            'label': label,\n",
    "                            'address': entry.get('address', '')\n",
    "                        })\n",
    "\n",
    "                return exchange_tags\n",
    "                \n",
    "            except graphsense.ApiException as e:\n",
    "               print(\"Exception when calling AddressesApi->list_tags_by_address: %s\\n\" % e)\n",
    "    \n",
    "    \n",
    "    def get_ex_used(self, address, type, direction, depth=3, max_degree=7, verbose=True):\n",
    "        \n",
    "        ass_wallets = AssociatedWallets(self.currency)\n",
    "        neighbors = ass_wallets.bfs_neighbors(address.lower(), depth, max_degree, verbose, direction)\n",
    "\n",
    "        exchanges_used = []\n",
    "\n",
    "        for arr_level in neighbors:\n",
    "            for address in arr_level:\n",
    "                temp_exchange_tags = self.get_ex_tags(address.lower(), type)\n",
    "                if temp_exchange_tags:\n",
    "                    exchanges_used.append(temp_exchange_tags)\n",
    "\n",
    "        return exchanges_used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proof of Funds Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoinbaseWalletAuth(AuthBase):\n",
    "    def __init__(self, api_key, secret_key):\n",
    "        self.api_key = api_key\n",
    "        self.secret_key = secret_key\n",
    "\n",
    "    def __call__(self, request):\n",
    "        timestamp = str(int(time.time()))\n",
    "        message = timestamp + request.method + request.path_url + (request.body or '')\n",
    "        signature = hmac.new(self.secret_key, message, hashlib.sha256).hexdigest()\n",
    "\n",
    "        request.headers.update({\n",
    "            'CB-ACCESS-SIGN': signature,\n",
    "            'CB-ACCESS-TIMESTAMP': timestamp,\n",
    "            'CB-ACCESS-KEY': self.api_key,\n",
    "        })\n",
    "        return request\n",
    "\n",
    "\n",
    "class PoF():\n",
    "    \n",
    "\n",
    "    def __init__(self, currency):\n",
    "        self.currency = currency\n",
    "\n",
    "\n",
    "    \"\"\"Coinbase candles data, each bucket is an array of the following information:\n",
    "    time: bucket start time\n",
    "    low: lowest price during the bucket interval\n",
    "    high: highest price during the bucket interval\n",
    "    open: opening price (first trade) in the bucket interval\n",
    "    close: closing price (last trade) in the bucket interval\n",
    "    volume: volume of trading activity during the bucket interval\"\"\"\n",
    "\n",
    "    def coinbase_data(self, type, symbol='ETH-USD', start_date=datetime.today().strftime('%Y-%m-%d'), end_date=datetime.today().strftime('%Y-%m-%d')):\n",
    "\n",
    "        # Before implementation, set environmental variables with the names API_KEY and API_SECRET\n",
    "        #API_KEY = config['coinbase']['api_key']\n",
    "        #API_SECRET = config['coinbase']['api_secret']\n",
    "        #auth = CoinbaseWalletAuth(API_KEY, API_SECRET)\n",
    "\n",
    "        # Convert the start date string to a datetime object\n",
    "        #start_date_datetime = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "\n",
    "        # Calculate the end date by adding one day to the start date\n",
    "        #end_date_datetime = start_date_datetime + datetime.timedelta(days=1)\n",
    "\n",
    "        # Convert the end date to a string in the same format\n",
    "        #end_date = end_date_datetime.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        # Parameters for the API request Exchange\n",
    "        params_exchange = {\n",
    "            \"currency\": symbol\n",
    "        }\n",
    "\n",
    "        # Parameters for the API request Spot\n",
    "        params_spot = {\n",
    "            \"date\": start_date\n",
    "        }\n",
    "\n",
    "        # Parameters for the API request Candles\n",
    "        params_candles = {\n",
    "            \"granularity\": 86400,  # Daily interval\n",
    "            \"start\": start_date,\n",
    "            \"end\": start_date\n",
    "        }\n",
    "\n",
    "        if type == 'buy':\n",
    "            base_url = config['coinbase']['buyprice_endpoint']\n",
    "            api_url = base_url.format(symbol)\n",
    "            response = requests.get(api_url)\n",
    "\n",
    "        elif type == 'sell':\n",
    "            base_url = config['coinbase']['sellprice_endpoint']\n",
    "            api_url = base_url.format(symbol)\n",
    "            response = requests.get(api_url)\n",
    "\n",
    "        elif type == 'exchange':\n",
    "            api_url = config['coinbase']['exchangeprice_endpoint']\n",
    "            response = requests.get(api_url, params=params_exchange)\n",
    "\n",
    "        elif type == 'spot':\n",
    "            base_url = config['coinbase']['spotprice_endpoint']\n",
    "            api_url = base_url.format(symbol)\n",
    "            response = requests.get(api_url, params=params_spot)\n",
    "\n",
    "        elif type == 'candles':\n",
    "            base_url = config['coinbase']['candles_endpoint']\n",
    "            api_url = base_url.format(symbol)\n",
    "            response = requests.get(api_url, params=params_candles)\n",
    "        else:\n",
    "            print(f\"Unsupported type: {type}\")\n",
    "            return False\n",
    "\n",
    "        # Process the response data\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(\"Request failed:\", response.status_code)\n",
    "\n",
    "    \n",
    "    \"\"\"Klines data Binance:[\n",
    "        [\n",
    "            1499040000000,      // Kline open time\n",
    "            \"0.01634790\",       // Open price\n",
    "            \"0.80000000\",       // High price\n",
    "            \"0.01575800\",       // Low price\n",
    "            \"0.01577100\",       // Close price\n",
    "            \"148976.11427815\",  // Volume\n",
    "            1499644799999,      // Kline Close time\n",
    "            \"2434.19055334\",    // Quote asset volume\n",
    "            308,                // Number of trades\n",
    "            \"1756.87402397\",    // Taker buy base asset volume\n",
    "            \"28.46694368\",      // Taker buy quote asset volume\n",
    "            \"0\"                 // Unused field, ignore.\n",
    "        ]\n",
    "        ]\"\"\"\n",
    "    \n",
    "    def binance_data(self, type, symbol='', start_date=datetime.today().strftime('%Y-%m-%d'), end_date=datetime.today().strftime('%Y-%m-%d')):\n",
    "\n",
    "        # Convert start and end dates to Unix timestamps (in milliseconds)\n",
    "        start_timestamp = int(datetime.strptime(start_date, \"%Y-%m-%d\").timestamp()) * 1000\n",
    "        #end_timestamp = int(datetime.strptime(end_date, \"%Y-%m-%d\").timestamp()) * 1000\n",
    "\n",
    "        # Parameters for the API request Klines\n",
    "        params_klines = {\n",
    "            \"symbol\": symbol,\n",
    "            \"interval\": \"1d\",  # Daily interval\n",
    "            \"startTime\": start_timestamp\n",
    "            #\"endTime\": end_timestamp\n",
    "        }\n",
    "\n",
    "        # Parameters for the API request\n",
    "        params_general = {\n",
    "            \"symbol\": symbol,\n",
    "            #\"interval\": \"1d\",  # Daily interval\n",
    "            #\"startTime\": start_timestamp\n",
    "            #\"endTime\": end_timestamp\n",
    "        }\n",
    "\n",
    "        if type == 'avgprice':\n",
    "            api_url = config['binance']['avgprice_endpoint']\n",
    "            response = requests.get(api_url, params=params_general)\n",
    "        elif type == 'price':\n",
    "            api_url = config['binance']['price_endpoint']\n",
    "            response = requests.get(api_url, params=params_general)\n",
    "        elif type == 'exchange':\n",
    "            api_url = config['binance']['exchangeprice_endpoint']\n",
    "            if symbol == '':\n",
    "                response = requests.get(api_url)\n",
    "            else:\n",
    "                response = requests.get(api_url, params=params_general)\n",
    "        elif type == 'klines':\n",
    "            api_url = config['binance']['klines_endpoint']\n",
    "            response = requests.get(api_url, params=params_klines)\n",
    "        elif type == '24hrstats':\n",
    "            api_url = config['binance']['24hrstats_endpoint']\n",
    "            response = requests.get(api_url, params=params_general)\n",
    "        else:\n",
    "            print(f\"Unsupported type: {type}\")\n",
    "            return False\n",
    "        \n",
    "        # Process the response data\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(\"Request failed:\", response.status_code)\n",
    "         \n",
    "        \n",
    "    def binance_table(self, symbol, interval='4h', limit=500, start='01-01-2023'):\n",
    "\n",
    "        \"\"\"\n",
    "        interval: str tick interval - 4h/1h/1d ...\n",
    "        \"\"\"\n",
    "\n",
    "        columns = ['open_time','open', 'high', 'low', 'close', 'volume','close_time', 'qav','num_trades','taker_base_vol','taker_quote_vol', 'ignore']\n",
    "        start = int(datetime.timestamp(pd.to_datetime(start))*1000)\n",
    "        api_url = f'https://www.binance.com/api/v3/klines?symbol={symbol}&interval={interval}&limit={limit}&startTime={start}'\n",
    "\n",
    "        data = pd.DataFrame(requests.get(api_url).json(), columns=columns, dtype=float)\n",
    "        data.index = [pd.to_datetime(x, unit='ms').strftime('%Y-%m-%d %H:%M:%S') for x in data.open_time]\n",
    "        usecols=['open', 'high', 'low', 'close', 'volume', 'qav','num_trades','taker_base_vol','taker_quote_vol']\n",
    "        data = data[usecols]\n",
    "\n",
    "        return data\n",
    "    \n",
    "    \n",
    "    def check_profitloss(self, exchange, symbol, buy_date, sell_date, buy_amount, sell_amount, profit_or_loss):\n",
    "        \n",
    "        if exchange == 'coinbase':\n",
    "            \n",
    "            buy_price_data = self.coinbase_data('candles', symbol, buy_date)\n",
    "            sell_price_data = self.coinbase_data('candles', symbol, sell_date)\n",
    "\n",
    "            buy_price = float(buy_price_data[0][3])\n",
    "            sell_price = float(sell_price_data[0][3])\n",
    "\n",
    "            buy_total = buy_price * buy_amount\n",
    "            sell_total = sell_price * sell_amount\n",
    "            \n",
    "        elif exchange == 'binance':\n",
    "            \n",
    "            buy_price_data = self.binance_data('klines', symbol, buy_date)\n",
    "            sell_price_data = self.binance_data('klines', symbol, sell_date)\n",
    "\n",
    "            buy_price = float(buy_price_data[0][1])\n",
    "            sell_price = float(sell_price_data[0][1])\n",
    "\n",
    "            buy_total = buy_price * buy_amount\n",
    "            sell_total = sell_price * sell_amount\n",
    "\n",
    "        else:\n",
    "            print(f\"Unsupported exchange: {exchange}\")\n",
    "            return False\n",
    "        \n",
    "        actual_profit_or_loss =  sell_total - buy_total\n",
    "        difference = abs(actual_profit_or_loss - profit_or_loss)\n",
    "        \n",
    "        if difference < 1e-6: #To account for floating point inaccuracies\n",
    "            print(\"Actual profit/loss: \" + str(actual_profit_or_loss))\n",
    "            print(\"Difference between reported profit/loss and actual profit/loss value: \" + str(difference))\n",
    "            return True\n",
    "        else:\n",
    "            print(\"Actual profit/loss: \" + str(actual_profit_or_loss))\n",
    "            print(\"Difference between reported profit/loss and actual profit/loss value: \" + str(difference))            \n",
    "            return False\n",
    "        \n",
    "\n",
    "    def fetch_page(self, address, direction, page_token=None):\n",
    "\n",
    "        with graphsense.ApiClient(configuration) as api_client:\n",
    "            api_instance = addresses_api.AddressesApi(api_client)\n",
    "            try:\n",
    "                if page_token:\n",
    "                    api_response = api_instance.list_address_txs(self.currency, address.lower(), direction=direction, page=page_token)\n",
    "                else:\n",
    "                    api_response = api_instance.list_address_txs(self.currency, address.lower(), direction=direction)\n",
    "                return api_response\n",
    "            except graphsense.ApiException as e:\n",
    "                print(\"Exception when calling AddressesApi->list_address_txs: %s\\n\" % e)\n",
    "                return None\n",
    "\n",
    "\n",
    "    def get_address_txs(self, address, direction, pages=2, parallel=False):\n",
    "\n",
    "        all_txs = []\n",
    "        seen_txs = set()\n",
    "\n",
    "        def add_unique_transactions(transactions):\n",
    "            for tx in transactions:\n",
    "                tx_hash = tx.get('tx_hash')\n",
    "                if tx_hash not in seen_txs:\n",
    "                    seen_txs.add(tx_hash)\n",
    "                    all_txs.append(tx)\n",
    "\n",
    "        if not parallel:\n",
    "\n",
    "            next_page_token = ''\n",
    "            for i in range(pages):\n",
    "                api_response = self.fetch_page(address, direction, next_page_token)\n",
    "                if api_response:\n",
    "                    add_unique_transactions(api_response['address_txs'])\n",
    "                    next_page_token = api_response.get('next_page', '')\n",
    "                    if not next_page_token:\n",
    "                        print(f\"{i+1} pages found for transactions in direction: {direction}. Exiting after fetching all available pages.\")\n",
    "                        break\n",
    "        else:\n",
    "\n",
    "            page_tokens = [''] + [None] * (pages - 1)\n",
    "            with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "                future_to_page = {executor.submit(self.fetch_page, address, direction, token): token for token in page_tokens}\n",
    "                for future in as_completed(future_to_page):\n",
    "                    page_token = future_to_page[future]\n",
    "                    try:\n",
    "                        api_response = future.result()\n",
    "                        if api_response:\n",
    "                            add_unique_transactions(api_response['address_txs'])\n",
    "                            if 'next_page' in api_response:\n",
    "                                page_tokens.append(api_response['next_page'])\n",
    "                    except Exception as e:\n",
    "                        print(f\"Failed to fetch page with token {page_token}. Error: {e}\")\n",
    "\n",
    "        return all_txs\n",
    "\n",
    "\n",
    "    def get_wallet_overview(self, address, pages=2):\n",
    "          \n",
    "        out_txs = self.get_address_txs(address.lower(), 'out', pages)\n",
    "        in_txs = self.get_address_txs(address.lower(), 'in', pages)\n",
    "\n",
    "        params = {\n",
    "            \"module\": \"account\",\n",
    "            \"action\": \"balance\",\n",
    "            \"address\": address.lower(),\n",
    "            \"tag\": \"latest\",\n",
    "            \"apikey\": config['etherscan']['api_key']\n",
    "        }\n",
    "        \n",
    "        response = requests.get(config['etherscan']['host'], params=params)\n",
    "        data = response.json()\n",
    "\n",
    "        if data['status'] != \"1\" or 'result' not in data:\n",
    "            print(f\"Error fetching transactions for address {address.lower()}: {data['message']}\")\n",
    "            return []\n",
    "        \n",
    "        balance_eth = float(data['result']) / (10 ** 18)  # Convert wei to ether\n",
    "\n",
    "        print(\"Number of incoming txs: \" + str(len(in_txs)))\n",
    "        print(\"Number of outgoing txs: \" + str(len(out_txs)))\n",
    "        print(balance_eth)\n",
    "\n",
    "\n",
    "    def activity_analysis(self, address, pages=2):\n",
    "\n",
    "        out_txs = self.get_address_txs(address.lower(), 'out', pages, True)\n",
    "        in_txs = self.get_address_txs(address.lower(), 'in', pages, True)\n",
    "        date_txcount = {}\n",
    "\n",
    "        for tx in out_txs:\n",
    "            tx_date = datetime.utcfromtimestamp(tx['timestamp']).strftime('%Y-%m-%d')\n",
    "            date_txcount[tx_date] = date_txcount.get(tx_date, 0) + 1\n",
    "\n",
    "        for tx in in_txs:\n",
    "            tx_date = datetime.utcfromtimestamp(tx['timestamp']).strftime('%Y-%m-%d')\n",
    "            date_txcount[tx_date] = date_txcount.get(tx_date, 0) + 1\n",
    "\n",
    "        dates = [datetime.strptime(date, '%Y-%m-%d') for date in date_txcount.keys()]\n",
    "        start_date = min(dates)\n",
    "        end_date = max(dates)\n",
    "\n",
    "        current_date = start_date\n",
    "        while current_date <= end_date:\n",
    "            str_date = current_date.strftime('%Y-%m-%d')\n",
    "            if str_date not in date_txcount:\n",
    "                date_txcount[str_date] = 0\n",
    "            current_date += timedelta(days=1)\n",
    "\n",
    "        df = pd.DataFrame(list(date_txcount.items()), columns=['Date', 'TxCount'])\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        df = df.sort_values('Date')\n",
    "        df['YearMonth'] = df['Date'].dt.to_period('M')\n",
    "        df['Day'] = df['Date'].dt.day\n",
    "        new_df = df.pivot(index=\"YearMonth\", columns=\"Day\", values=\"TxCount\")\n",
    "        new_df = new_df.iloc[::-1]  # Reverse the row order to have the earliest month at the bottom\n",
    "\n",
    "        # Adjusted fig_width and fig_height for the new orientation\n",
    "        fig_width = 40\n",
    "        fig_height = 20\n",
    "\n",
    "        plt.figure(figsize=(fig_width, fig_height))\n",
    "        ax = sns.heatmap(new_df, cmap='Purples', linewidths=2, cbar_kws={'label': 'Transaction Count'}, annot=True, annot_kws={\"size\": 40, \"rotation\": 90})        \n",
    "\n",
    "        cbar = ax.collections[0].colorbar\n",
    "        cbar.ax.tick_params(labelsize=40)\n",
    "        cbar.set_label('Transaction Count', size=50)\n",
    "        cbar.ax.yaxis.labelpad = 40\n",
    "        \n",
    "        xticks = ax.get_xticks()\n",
    "        ax.set_xticks(xticks[::2])\n",
    "\n",
    "        plt.title('Transactions Heatmap', fontsize=50, y=1.05)\n",
    "\n",
    "        plt.xticks(rotation=45, fontsize=40)  # Slightly reduced rotation to 45 for better clarity\n",
    "        plt.yticks(fontsize=40)\n",
    "        plt.xlabel('Day', fontsize=40, labelpad=40)  \n",
    "        plt.ylabel('Year-Month', fontsize=40, labelpad=40)\n",
    "\n",
    "        plt.tight_layout()  # This ensures that all the elements of the plot fit within the figure dimensions.\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NFTs Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NFT():\n",
    "\n",
    "\n",
    "    def get_nft_transfers(self, address, pages=1, offset=100):\n",
    "\n",
    "        all_results = []\n",
    "\n",
    "        for page in range(1, pages + 1):\n",
    "            params = {\n",
    "                \"module\": \"account\",\n",
    "                \"action\": \"tokennfttx\",\n",
    "                \"address\": address.lower(),\n",
    "                \"page\": page,\n",
    "                \"offset\": offset,\n",
    "                \"sort\": \"asc\",\n",
    "                \"apikey\": config['etherscan']['api_key']\n",
    "            }\n",
    "\n",
    "            response = requests.get(config['etherscan']['host'], params=params)\n",
    "            data = response.json()\n",
    "\n",
    "            if data['status'] == \"1\" and 'result' in data:\n",
    "                all_results.extend(data['result'])\n",
    "            else:\n",
    "                print(f\"Error fetching transactions for address {address.lower()} on page {page}: {data['message']}\")\n",
    "\n",
    "        return all_results\n",
    "    \n",
    "    \n",
    "    def get_held_nfts(self, address):\n",
    "        \n",
    "        transfers = self.get_nft_transfers(address.lower())\n",
    "\n",
    "        incoming_nfts = {tx['tokenID']: tx for tx in transfers if tx['to'] == address.lower()}\n",
    "        outgoing_nfts = {tx['tokenID']: tx for tx in transfers if tx['from'] == address.lower()}\n",
    "\n",
    "        held_nfts = {tid: tx for tid, tx in incoming_nfts.items() if tid not in outgoing_nfts}\n",
    "\n",
    "        return list(held_nfts.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERC20 Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ERC20():\n",
    "    \n",
    "\n",
    "    def __init__(self, currency):\n",
    "        self.currency = currency\n",
    "\n",
    "\n",
    "    def get_erc20_transfers(self, address, pages=1, offset=100):\n",
    "\n",
    "        all_results = []  # List to store results from all pages\n",
    "\n",
    "        for page in range(1, pages + 1):  # Start from page 1 up to the specified number of pages\n",
    "            params = {\n",
    "                \"module\": \"account\",\n",
    "                \"action\": \"tokentx\",\n",
    "                \"address\": address.lower(),\n",
    "                \"page\": page,\n",
    "                \"offset\": offset,\n",
    "                \"sort\": \"asc\",\n",
    "                \"apikey\": config['etherscan']['api_key']\n",
    "            }\n",
    "\n",
    "            response = requests.get(config['etherscan']['host'], params=params)\n",
    "            data = response.json()\n",
    "\n",
    "            if data['status'] == \"1\" and 'result' in data:\n",
    "                all_results.extend(data['result'])\n",
    "            else:\n",
    "                print(f\"Error fetching transactions for address {address.lower()} on page {page}: {data['message']}\")\n",
    "\n",
    "        return all_results\n",
    "\n",
    "    \n",
    "    def get_erc20(self, address):\n",
    "        \n",
    "        transfers = self.get_erc20_transfers(address.lower())\n",
    "\n",
    "        erc20_balances = {}\n",
    "        \n",
    "        # Sum up all the incoming and outgoing transfers for each token\n",
    "        for tx in transfers:\n",
    "\n",
    "            token_key = (tx['tokenSymbol'], tx['tokenName'])\n",
    "            value = float(tx['value']) / (10.0 ** float(tx['tokenDecimal']))\n",
    "            \n",
    "            if tx['to'] == address.lower():\n",
    "                erc20_balances[token_key] = erc20_balances.get(token_key, 0) + value\n",
    "            if tx['from'] == address.lower():\n",
    "                erc20_balances[token_key] = erc20_balances.get(token_key, 0) - value\n",
    "\n",
    "        # Filter out tokens with zero or negative balances\n",
    "        held_erc20 = {k: v for k, v in erc20_balances.items() if v > 0}\n",
    "\n",
    "        return dict(sorted(held_erc20.items()))\n",
    "\n",
    "    \n",
    "    def visualize(self, address):\n",
    "        \n",
    "        held_erc20 = self.get_erc20(address.lower())\n",
    "        pof = PoF(self.currency)\n",
    "        pie_data = []\n",
    "        pie_labels = []\n",
    "        failed_erc20 = {}\n",
    "\n",
    "        if held_erc20:\n",
    "\n",
    "            for token, value in held_erc20.items():\n",
    "\n",
    "                symbol = token[0]\n",
    "\n",
    "                if symbol != 'USDT':\n",
    "                    trading_pair = symbol + 'USDT'\n",
    "                    binance_call = pof.binance_data('price', trading_pair)\n",
    "                    if binance_call:\n",
    "                        symbol_price = float(binance_call['price'])\n",
    "                        pie_data.append(symbol_price * value)\n",
    "                        pie_labels.append(symbol)\n",
    "                    else:\n",
    "                        failed_erc20[token] = value\n",
    "                elif symbol == 'USDT': \n",
    "                    symbol_price = 1.0\n",
    "                    pie_data.append(symbol_price * value)\n",
    "                    pie_labels.append(symbol)\n",
    "    \n",
    "        else:\n",
    "            print(f\"Error fetching transactions for address {address.lower()}\")\n",
    "\n",
    "        colors = [\n",
    "            \"#1f77b4\",  # muted blue\n",
    "            \"#ff7f0e\",  # safety orange\n",
    "            \"#2ca02c\",  # cooked asparagus green\n",
    "            \"#d62728\",  # brick red\n",
    "            \"#9467bd\",  # muted purple\n",
    "            \"#8c564b\",  # chestnut brown\n",
    "            \"#e377c2\",  # raspberry yogurt pink\n",
    "            \"#7f7f7f\",  # middle gray\n",
    "            \"#bcbd22\",  # curry yellow-green\n",
    "            \"#17becf\",  # blue-teal\n",
    "            \"#1a55FF\",  # bright blue\n",
    "            \"#FF55A3\",  # bright pink\n",
    "            \"#669900\",  # olive green\n",
    "            \"#FFC400\",  # bright yellow\n",
    "            \"#004DFF\",  # royal blue\n",
    "            \"#FF5000\",  # bright red-orange\n",
    "            \"#009966\",  # teal green\n",
    "            \"#FF6600\",  # orange\n",
    "            \"#8000FF\",  # violet\n",
    "            \"#00FF80\"   # mint green\n",
    "        ]\n",
    "\n",
    "        if pie_data and len(pie_data) < 6:\n",
    "            plt.figure(figsize=(16, 12))\n",
    "            plt.title('ERC20 Tokens in USDT', fontsize=30)            \n",
    "            plt.pie(pie_data, colors=colors, autopct='%0.1f%%', textprops={'fontsize': 32})\n",
    "            \n",
    "            plt.legend(pie_labels, title=\"Tokens\", loc=\"upper center\", bbox_to_anchor=(0.5, -0.02), fontsize=25, title_fontsize=27, ncol=len(pie_labels))\n",
    "            plt.show()\n",
    "            \n",
    "        elif pie_data and len(pie_data) >= 6:\n",
    "            bar_positions = np.arange(len(pie_labels))\n",
    "            \n",
    "            plt.figure(figsize=(50, 30))\n",
    "            \n",
    "            plt.xticks(bar_positions, pie_labels, rotation=45, fontsize=85)\n",
    "            plt.yticks(fontsize=85)\n",
    "            \n",
    "            plt.yscale('log')\n",
    "            \n",
    "            plt.ylabel('Value in USDT', fontsize=85, labelpad=30)\n",
    "            \n",
    "            plt.title('ERC20 Tokens in USDT', fontsize=100, y=1.05)\n",
    "            \n",
    "            plt.bar(bar_positions, pie_data, align='center', alpha=0.7, color='purple')\n",
    "            plt.show()\n",
    "            \n",
    "        print(f\"The following ERC20 Tokens are being held by the client: {held_erc20}\")\n",
    "        print(f\"For following ERC20 Tokens there was no price data: {failed_erc20}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smart Contract Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SC():\n",
    "\n",
    "\n",
    "    def get_sc_data(self, contract_address, type):\n",
    "\n",
    "        params_sc = {\n",
    "            \"module\": \"contract\",\n",
    "            \"action\": \"getsourcecode\",\n",
    "            \"address\": contract_address,\n",
    "            \"apikey\": config['etherscan']['api_key']\n",
    "        }\n",
    "        response_sc = requests.get(config['etherscan']['host'], params=params_sc)\n",
    "        data_sc = response_sc.json()\n",
    "\n",
    "        params_creator = {\n",
    "            \"module\": \"contract\",\n",
    "            \"action\": \"getcontractcreation\",\n",
    "            \"address\": contract_address,\n",
    "            \"apikey\": config['etherscan']['api_key']\n",
    "        }\n",
    "        response_creator = requests.get(config['etherscan']['host'], params=params_creator)\n",
    "        data_creator = response_creator.json()\n",
    "\n",
    "        if data_sc[\"status\"] == \"1\":\n",
    "            source_code = data_sc[\"result\"][0][\"SourceCode\"]\n",
    "            with open(\"results/sc_\" + str(type) + \"_\" + data_sc[\"result\"][0][\"ContractName\"] + \".txt\", \"w\") as outfile:\n",
    "                outfile.write(str(source_code))\n",
    "        else:\n",
    "            print(f\"Error Smart Contract: {data_sc['message']}\")\n",
    "\n",
    "        if data_creator[\"status\"] == \"1\":\n",
    "            creator_data = data_creator[\"result\"]\n",
    "            with open(\"results/creator_\" + str(type) + \".txt\", \"w\") as outfile:\n",
    "                outfile.write(str(creator_data))\n",
    "        else:\n",
    "            print(f\"Error Creator: {data_creator['message']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixers and Bridges Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixBridge():\n",
    "\n",
    "\n",
    "    def process(self, mix_bridge, address, pages, pof, file_type):\n",
    "\n",
    "        print(f\"Processing mixer/bridge: {mix_bridge['address']}\")\n",
    "\n",
    "        out_txs = pof.get_address_txs(mix_bridge['address'], 'out', pages)\n",
    "        in_txs = pof.get_address_txs(mix_bridge['address'], 'in', pages)\n",
    "\n",
    "        if file_type == 'json':\n",
    "\n",
    "            Tx = namedtuple('Tx', ['from_address', 'to_address', 'name_tag'])\n",
    "            name_tag = mix_bridge['nameTag'] if mix_bridge['nameTag'] else 'Unknown Mixer/Bridge'\n",
    "\n",
    "            tx_from_mix_bridge = [Tx(tx['from_address'], tx['to_address'], name_tag) for tx in out_txs if tx['to_address'] == address.lower()]\n",
    "            tx_to_mix_bridge = [Tx(tx['from_address'], tx['to_address'], name_tag) for tx in in_txs if tx['from_address'] == address.lower()]\n",
    "\n",
    "        elif file_type == 'yaml':\n",
    "\n",
    "            Tx = namedtuple('Tx', ['from_address', 'to_address', 'name_tag'])\n",
    "\n",
    "            tags = []\n",
    "\n",
    "            if 'abuse' in mix_bridge:\n",
    "                tags.append(mix_bridge['abuse'])\n",
    "            if 'label' in mix_bridge:\n",
    "                tags.append(mix_bridge['label'])\n",
    "            if 'context' in mix_bridge:\n",
    "                tags.append(mix_bridge['context'])\n",
    "\n",
    "            name_tag = '/'.join(tags)\n",
    "\n",
    "            tx_from_mix_bridge = [Tx(tx['from_address'], tx['to_address'], name_tag) for tx in out_txs if tx['to_address'] == address.lower()]\n",
    "            tx_to_mix_bridge = [Tx(tx['from_address'], tx['to_address'], name_tag) for tx in in_txs if tx['from_address'] == address.lower()]\n",
    "\n",
    "        return tx_from_mix_bridge, tx_to_mix_bridge\n",
    "\n",
    "\n",
    "    def check(self, address, path, pages=3):\n",
    "\n",
    "        pof = PoF('eth')\n",
    "        file_ext = os.path.splitext(path)[1].lower()\n",
    "        with open(path, \"r\") as file:\n",
    "            if file_ext in [\".json\"]:\n",
    "                mix_bridge_data = json.load(file)\n",
    "                file_type = 'json'\n",
    "            elif file_ext in [\".yaml\", \".yml\"]:\n",
    "                mix_bridge_data = yaml.safe_load(file)['tags']\n",
    "                file_type = 'yaml'\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported file format\")\n",
    "\n",
    "        tx_from_mix_bridge = []\n",
    "        tx_to_mix_bridge = []\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "\n",
    "            futures = [executor.submit(self.process, mix_bridge, address.lower(), pages, pof, file_type) for mix_bridge in mix_bridge_data]\n",
    "\n",
    "            for future in as_completed(futures):\n",
    "                out, inn = future.result()\n",
    "                print(\"From:\", out)\n",
    "                print(\"To:\", inn)\n",
    "                tx_from_mix_bridge.extend(out)\n",
    "                tx_to_mix_bridge.extend(inn)\n",
    "\n",
    "        return tx_from_mix_bridge, tx_to_mix_bridge"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function calls\n",
    "\n",
    "#ass_wallets = AssociatedWallets(CURRENCY)\n",
    "\n",
    "#direction = 'out'\n",
    "\n",
    "#addr_neigh = ass_wallets.bfs_neighbors(ADDRESS, 4, 10, True, direction)\n",
    "\n",
    "#with open(\"results/addresses_\" + direction + \".txt\", \"w\") as outfile:\n",
    "    #outfile.write(str(addr_neigh))\n",
    "\n",
    "#blacklist = Blacklist(CURRENCY)\n",
    "#blacklist.ofac()\n",
    "#print(blacklist.check_membership('ETH', ADDRESS, json_data))\n",
    "#blacklist.check_dark_web('', 'data/wasabi_txs.parquet')\n",
    "#blacklist.check_phishing_hack('', 'data/defi_fraud.yaml')\n",
    "\n",
    "\n",
    "#ex = Exchange('eth')\n",
    "#exchanges_used = ex.get_ex_used('', 'cex', 'out', 3)\n",
    "#exchanges_used = ex.get_ex_tags('', 'cex')\n",
    "#pprint(exchanges_used)\n",
    "\n",
    "#pof = PoF('eth')\n",
    "#print(pof.coinbase_data('candles', 'ETH-USD', '2023-01-01'))\n",
    "#print(pof.binance_data('klines', 'ETHUSDT', '2020-08-09'))\n",
    "#print(pof.binance_data('klines', 'ETHUSDT', '2023-09-10'))\n",
    "#print(pof.coinbase_data('candles', 'ETH-USD', '2023-01-01'))\n",
    "#pprint(pof.binance_table('ETHUSDT', '1h'))\n",
    "#pof.check_profitloss('binance', 'ETHUSDT', '2020-08-09', '2023-09-10', 2, 1, 1000)\n",
    "#print(pof.get_address_txs(ADDRESS, 'in', 1))\n",
    "#pof.get_wallet_overview('')\n",
    "#pof.activity_analysis('', 1)\n",
    "\n",
    "#nft = NFT()\n",
    "#nfts_dict = nft.get_held_nfts(ADDRESS)\n",
    "#print(nfts_dict)\n",
    "#for nft in nfts_dict:\n",
    "    #print(nft)\n",
    "\n",
    "#erc20 = ERC20('eth')\n",
    "#erc20_dict = erc20.get_erc20_transfers(ADDRESS)\n",
    "#print(erc20_dict)\n",
    "#print(erc20.get_erc20(ADDRESS))\n",
    "#erc20.visualize('')\n",
    "\n",
    "#sc = SC()\n",
    "#sc.get_sc_data('', 'nft')\n",
    "\n",
    "#mix_bridge = MixBridge()\n",
    "#print(mix_bridge.check(''.lower(), 'data/defi_fraud.yaml', 1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iknaio-api-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
